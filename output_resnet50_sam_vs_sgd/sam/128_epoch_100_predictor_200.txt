C:\Users\kimJuhwan\anaconda3\envs\pytorch\python.exe E:\github\simclrExe\main_sam.py 
Files already downloaded and verified
Files already downloaded and verified
===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
SimCLR                                        [128, 512]                --
├─ResNet: 1-1                                 [128, 512]                --
│    └─Conv2d: 2-1                            [128, 64, 32, 32]         1,728
│    └─BatchNorm2d: 2-2                       [128, 64, 32, 32]         128
│    └─ReLU: 2-3                              [128, 64, 32, 32]         --
│    └─Identity: 2-4                          [128, 64, 32, 32]         --
│    └─Sequential: 2-5                        [128, 64, 32, 32]         --
│    │    └─BasicBlock: 3-1                   [128, 64, 32, 32]         73,984
│    │    └─BasicBlock: 3-2                   [128, 64, 32, 32]         73,984
│    └─Sequential: 2-6                        [128, 128, 16, 16]        --
│    │    └─BasicBlock: 3-3                   [128, 128, 16, 16]        230,144
│    │    └─BasicBlock: 3-4                   [128, 128, 16, 16]        295,424
│    └─Sequential: 2-7                        [128, 256, 8, 8]          --
│    │    └─BasicBlock: 3-5                   [128, 256, 8, 8]          919,040
│    │    └─BasicBlock: 3-6                   [128, 256, 8, 8]          1,180,672
│    └─Sequential: 2-8                        [128, 512, 4, 4]          --
│    │    └─BasicBlock: 3-7                   [128, 512, 4, 4]          3,673,088
│    │    └─BasicBlock: 3-8                   [128, 512, 4, 4]          4,720,640
│    └─AdaptiveAvgPool2d: 2-9                 [128, 512, 1, 1]          --
│    └─Identity: 2-10                         [128, 512]                --
├─Sequential: 1-2                             [128, 128]                --
│    └─Linear: 2-11                           [128, 512]                262,144
│    └─ReLU: 2-12                             [128, 512]                --
│    └─Linear: 2-13                           [128, 128]                65,536
===============================================================================================
Total params: 11,496,512
Trainable params: 11,496,512
Non-trainable params: 0
Total mult-adds (Units.GIGABYTES): 71.14
===============================================================================================
Input size (MB): 1.57
Forward/backward pass size (MB): 1258.95
Params size (MB): 45.99
Estimated Total Size (MB): 1306.51
===============================================================================================
Epoch 1: 100%|██████████| 391/391 [06:02<00:00,  1.08batch/s]
Avg Loss : 4.9527 Validation Loss : 4.8584 Learning Late: 0.8485
Epoch 2: 100%|██████████| 391/391 [11:35<00:00,  1.78s/batch]
Avg Loss : 4.7702 Validation Loss : 4.7293 Learning Late: 0.8485
Epoch 3: 100%|██████████| 391/391 [12:37<00:00,  1.94s/batch]
Avg Loss : 4.6830 Validation Loss : 4.4202 Learning Late: 0.8485
Epoch 4: 100%|██████████| 391/391 [06:55<00:00,  1.06s/batch]
Avg Loss : 4.1098 Validation Loss : 3.9463 Learning Late: 0.8485
Epoch 5: 100%|██████████| 391/391 [06:41<00:00,  1.03s/batch]
Avg Loss : 3.7730 Validation Loss : 3.5247 Learning Late: 0.8485
Epoch 6: 100%|██████████| 391/391 [06:04<00:00,  1.07batch/s]
Avg Loss : 3.3543 Validation Loss : 2.9722 Learning Late: 0.8485
Epoch 7: 100%|██████████| 391/391 [06:04<00:00,  1.07batch/s]
Avg Loss : 2.6948 Validation Loss : 2.2180 Learning Late: 0.8485
Epoch 8: 100%|██████████| 391/391 [05:56<00:00,  1.10batch/s]
Avg Loss : 2.1399 Validation Loss : 2.0802 Learning Late: 0.8485
Epoch 9: 100%|██████████| 391/391 [05:57<00:00,  1.09batch/s]
Avg Loss : 1.7697 Validation Loss : 1.5295 Learning Late: 0.8485
Epoch 10: 100%|██████████| 391/391 [05:56<00:00,  1.10batch/s]
Avg Loss : 1.3695 Validation Loss : 1.3666 Learning Late: 0.8485
Epoch 11: 100%|██████████| 391/391 [06:04<00:00,  1.07batch/s]
Avg Loss : 1.1713 Validation Loss : 0.9328 Learning Late: 0.8483
Epoch 12: 100%|██████████| 391/391 [05:59<00:00,  1.09batch/s]
Avg Loss : 0.9005 Validation Loss : 0.8927 Learning Late: 0.8475
Epoch 13: 100%|██████████| 391/391 [06:16<00:00,  1.04batch/s]
Avg Loss : 0.8270 Validation Loss : 0.6374 Learning Late: 0.8462
Epoch 14: 100%|██████████| 391/391 [06:14<00:00,  1.04batch/s]
Avg Loss : 0.6596 Validation Loss : 0.6365 Learning Late: 0.8444
Epoch 15: 100%|██████████| 391/391 [06:08<00:00,  1.06batch/s]
Avg Loss : 0.5863 Validation Loss : 0.5432 Learning Late: 0.8421
Epoch 16: 100%|██████████| 391/391 [06:20<00:00,  1.03batch/s]
Avg Loss : 0.6028 Validation Loss : 0.5793 Learning Late: 0.8393
Epoch 17: 100%|██████████| 391/391 [06:17<00:00,  1.03batch/s]
Avg Loss : 0.4666 Validation Loss : 0.4559 Learning Late: 0.8359
Epoch 18: 100%|██████████| 391/391 [06:10<00:00,  1.05batch/s]
Avg Loss : 0.5164 Validation Loss : 0.4111 Learning Late: 0.8321
Epoch 19: 100%|██████████| 391/391 [06:10<00:00,  1.06batch/s]
Avg Loss : 0.3944 Validation Loss : 0.3918 Learning Late: 0.8278
Epoch 20: 100%|██████████| 391/391 [06:10<00:00,  1.05batch/s]
Avg Loss : 0.3862 Validation Loss : 0.3411 Learning Late: 0.8229
Epoch 21: 100%|██████████| 391/391 [06:06<00:00,  1.07batch/s]
Avg Loss : 0.3608 Validation Loss : 0.3875 Learning Late: 0.8176
Epoch 22: 100%|██████████| 391/391 [06:03<00:00,  1.07batch/s]
Avg Loss : 0.3277 Validation Loss : 0.3270 Learning Late: 0.8118
Epoch 23: 100%|██████████| 391/391 [06:05<00:00,  1.07batch/s]
Avg Loss : 0.3926 Validation Loss : 0.3968 Learning Late: 0.8056
Epoch 24: 100%|██████████| 391/391 [06:01<00:00,  1.08batch/s]
Avg Loss : 0.3607 Validation Loss : 0.2861 Learning Late: 0.7989
Epoch 25: 100%|██████████| 391/391 [05:57<00:00,  1.09batch/s]
Avg Loss : 0.3160 Validation Loss : 0.3157 Learning Late: 0.7917
Epoch 26: 100%|██████████| 391/391 [05:57<00:00,  1.09batch/s]
Avg Loss : 0.2601 Validation Loss : 0.2794 Learning Late: 0.7841
Epoch 27: 100%|██████████| 391/391 [05:57<00:00,  1.09batch/s]
Avg Loss : 0.3411 Validation Loss : 0.3135 Learning Late: 0.7760
Epoch 28: 100%|██████████| 391/391 [06:18<00:00,  1.03batch/s]
Avg Loss : 0.2559 Validation Loss : 0.2582 Learning Late: 0.7675
Epoch 29: 100%|██████████| 391/391 [06:10<00:00,  1.06batch/s]
Avg Loss : 0.2545 Validation Loss : 0.3004 Learning Late: 0.7586
Epoch 30: 100%|██████████| 391/391 [06:05<00:00,  1.07batch/s]
Avg Loss : 0.2356 Validation Loss : 0.2479 Learning Late: 0.7493
Epoch 31: 100%|██████████| 391/391 [06:02<00:00,  1.08batch/s]
Avg Loss : 0.2756 Validation Loss : 0.3373 Learning Late: 0.7396
Epoch 32: 100%|██████████| 391/391 [06:03<00:00,  1.07batch/s]
Avg Loss : 0.2968 Validation Loss : 0.2776 Learning Late: 0.7295
Epoch 33: 100%|██████████| 391/391 [06:03<00:00,  1.08batch/s]
Avg Loss : 0.2546 Validation Loss : 0.2407 Learning Late: 0.7190
Epoch 34: 100%|██████████| 391/391 [06:01<00:00,  1.08batch/s]
Avg Loss : 0.2299 Validation Loss : 0.2270 Learning Late: 0.7082
Epoch 35: 100%|██████████| 391/391 [06:00<00:00,  1.08batch/s]
Avg Loss : 0.2108 Validation Loss : 0.2259 Learning Late: 0.6970
Epoch 36: 100%|██████████| 391/391 [06:05<00:00,  1.07batch/s]
Avg Loss : 0.1977 Validation Loss : 0.1900 Learning Late: 0.6855
Epoch 37: 100%|██████████| 391/391 [06:01<00:00,  1.08batch/s]
Avg Loss : 0.1926 Validation Loss : 0.2135 Learning Late: 0.6736
Epoch 38: 100%|██████████| 391/391 [06:02<00:00,  1.08batch/s]
Avg Loss : 0.1813 Validation Loss : 0.1932 Learning Late: 0.6615
Epoch 39: 100%|██████████| 391/391 [06:01<00:00,  1.08batch/s]
Avg Loss : 0.1916 Validation Loss : 0.1879 Learning Late: 0.6491
Epoch 40: 100%|██████████| 391/391 [06:02<00:00,  1.08batch/s]
Avg Loss : 0.1821 Validation Loss : 0.1752 Learning Late: 0.6364
Epoch 41: 100%|██████████| 391/391 [06:03<00:00,  1.08batch/s]
Avg Loss : 0.1822 Validation Loss : 0.2069 Learning Late: 0.6234
Epoch 42: 100%|██████████| 391/391 [06:00<00:00,  1.08batch/s]
Avg Loss : 0.1737 Validation Loss : 0.2711 Learning Late: 0.6102
Epoch 43: 100%|██████████| 391/391 [06:01<00:00,  1.08batch/s]
Avg Loss : 0.1859 Validation Loss : 0.1684 Learning Late: 0.5968
Epoch 44: 100%|██████████| 391/391 [06:03<00:00,  1.07batch/s]
Avg Loss : 0.1672 Validation Loss : 0.1388 Learning Late: 0.5832
Epoch 45: 100%|██████████| 391/391 [06:02<00:00,  1.08batch/s]
Avg Loss : 0.1842 Validation Loss : 0.1369 Learning Late: 0.5694
Epoch 46: 100%|██████████| 391/391 [06:05<00:00,  1.07batch/s]
Avg Loss : 0.1624 Validation Loss : 0.1535 Learning Late: 0.5554
Epoch 47: 100%|██████████| 391/391 [06:04<00:00,  1.07batch/s]
Avg Loss : 0.2274 Validation Loss : 0.1439 Learning Late: 0.5412
Epoch 48: 100%|██████████| 391/391 [06:03<00:00,  1.07batch/s]
Avg Loss : 0.1538 Validation Loss : 0.1668 Learning Late: 0.5269
Epoch 49: 100%|██████████| 391/391 [06:03<00:00,  1.08batch/s]
Avg Loss : 0.1506 Validation Loss : 0.1432 Learning Late: 0.5125
Epoch 50: 100%|██████████| 391/391 [06:03<00:00,  1.08batch/s]
Avg Loss : 0.1614 Validation Loss : 0.1373 Learning Late: 0.4979
Epoch 51: 100%|██████████| 391/391 [06:05<00:00,  1.07batch/s]
Avg Loss : 0.1616 Validation Loss : 0.1244 Learning Late: 0.4833
Epoch 52: 100%|██████████| 391/391 [06:04<00:00,  1.07batch/s]
Avg Loss : 0.1347 Validation Loss : 0.1687 Learning Late: 0.4686
Epoch 53: 100%|██████████| 391/391 [06:04<00:00,  1.07batch/s]
Avg Loss : 0.1633 Validation Loss : 0.1424 Learning Late: 0.4539
Epoch 54: 100%|██████████| 391/391 [06:05<00:00,  1.07batch/s]
Avg Loss : 0.1430 Validation Loss : 0.1644 Learning Late: 0.4391
Epoch 55: 100%|██████████| 391/391 [06:03<00:00,  1.08batch/s]
Avg Loss : 0.1193 Validation Loss : 0.1178 Learning Late: 0.4243
Epoch 56: 100%|██████████| 391/391 [06:03<00:00,  1.08batch/s]
Avg Loss : 0.1368 Validation Loss : 0.1404 Learning Late: 0.4095
Epoch 57: 100%|██████████| 391/391 [06:02<00:00,  1.08batch/s]
Avg Loss : 0.1423 Validation Loss : 0.1521 Learning Late: 0.3947
Epoch 58: 100%|██████████| 391/391 [06:04<00:00,  1.07batch/s]
Avg Loss : 0.1382 Validation Loss : 0.1436 Learning Late: 0.3799
Epoch 59: 100%|██████████| 391/391 [06:00<00:00,  1.08batch/s]
Avg Loss : 0.1245 Validation Loss : 0.1408 Learning Late: 0.3652
Epoch 60: 100%|██████████| 391/391 [06:00<00:00,  1.08batch/s]
Avg Loss : 0.1201 Validation Loss : 0.1324 Learning Late: 0.3506
Epoch 61: 100%|██████████| 391/391 [06:03<00:00,  1.08batch/s]
Avg Loss : 0.1488 Validation Loss : 0.1630 Learning Late: 0.3361
Epoch 62: 100%|██████████| 391/391 [06:03<00:00,  1.07batch/s]
Avg Loss : 0.1348 Validation Loss : 0.1546 Learning Late: 0.3216
Epoch 63: 100%|██████████| 391/391 [06:03<00:00,  1.08batch/s]
Avg Loss : 0.1206 Validation Loss : 0.1325 Learning Late: 0.3073
Epoch 64: 100%|██████████| 391/391 [06:01<00:00,  1.08batch/s]
Avg Loss : 0.1201 Validation Loss : 0.1494 Learning Late: 0.2932
Epoch 65: 100%|██████████| 391/391 [06:01<00:00,  1.08batch/s]
Avg Loss : 0.1162 Validation Loss : 0.1114 Learning Late: 0.2792
Epoch 66: 100%|██████████| 391/391 [06:02<00:00,  1.08batch/s]
Avg Loss : 0.1207 Validation Loss : 0.1015 Learning Late: 0.2653
Epoch 67: 100%|██████████| 391/391 [06:02<00:00,  1.08batch/s]
Avg Loss : 0.1216 Validation Loss : 0.1174 Learning Late: 0.2517
Epoch 68: 100%|██████████| 391/391 [05:57<00:00,  1.09batch/s]
Avg Loss : 0.1247 Validation Loss : 0.1677 Learning Late: 0.2383
Epoch 69: 100%|██████████| 391/391 [05:58<00:00,  1.09batch/s]
Avg Loss : 0.1164 Validation Loss : 0.1288 Learning Late: 0.2251
Epoch 70: 100%|██████████| 391/391 [06:02<00:00,  1.08batch/s]
Avg Loss : 0.1134 Validation Loss : 0.1236 Learning Late: 0.2121
Epoch 71: 100%|██████████| 391/391 [06:05<00:00,  1.07batch/s]
Avg Loss : 0.1136 Validation Loss : 0.0873 Learning Late: 0.1994
Epoch 72: 100%|██████████| 391/391 [06:02<00:00,  1.08batch/s]
Avg Loss : 0.1195 Validation Loss : 0.1018 Learning Late: 0.1870
Epoch 73: 100%|██████████| 391/391 [06:00<00:00,  1.09batch/s]
Avg Loss : 0.1107 Validation Loss : 0.1198 Learning Late: 0.1749
Epoch 74: 100%|██████████| 391/391 [06:05<00:00,  1.07batch/s]
Avg Loss : 0.1207 Validation Loss : 0.1323 Learning Late: 0.1631
Epoch 75: 100%|██████████| 391/391 [06:13<00:00,  1.05batch/s]
Avg Loss : 0.1152 Validation Loss : 0.1004 Learning Late: 0.1516
Epoch 76: 100%|██████████| 391/391 [06:16<00:00,  1.04batch/s]
Avg Loss : 0.1087 Validation Loss : 0.1344 Learning Late: 0.1404
Epoch 77: 100%|██████████| 391/391 [06:04<00:00,  1.07batch/s]
Avg Loss : 0.1063 Validation Loss : 0.1044 Learning Late: 0.1295
Epoch 78: 100%|██████████| 391/391 [06:04<00:00,  1.07batch/s]
Avg Loss : 0.1087 Validation Loss : 0.1158 Learning Late: 0.1191
Epoch 79: 100%|██████████| 391/391 [06:02<00:00,  1.08batch/s]
Avg Loss : 0.0928 Validation Loss : 0.0947 Learning Late: 0.1090
Epoch 80: 100%|██████████| 391/391 [06:07<00:00,  1.06batch/s]
Avg Loss : 0.1046 Validation Loss : 0.0947 Learning Late: 0.0993
Epoch 81: 100%|██████████| 391/391 [06:01<00:00,  1.08batch/s]
Avg Loss : 0.0949 Validation Loss : 0.0988 Learning Late: 0.0899
Epoch 82: 100%|██████████| 391/391 [05:59<00:00,  1.09batch/s]
Avg Loss : 0.0970 Validation Loss : 0.1080 Learning Late: 0.0810
Epoch 83: 100%|██████████| 391/391 [06:01<00:00,  1.08batch/s]
Avg Loss : 0.0982 Validation Loss : 0.1126 Learning Late: 0.0725
Epoch 84: 100%|██████████| 391/391 [06:18<00:00,  1.03batch/s]
Avg Loss : 0.0979 Validation Loss : 0.0949 Learning Late: 0.0645
Epoch 85: 100%|██████████| 391/391 [06:05<00:00,  1.07batch/s]
Avg Loss : 0.1016 Validation Loss : 0.0942 Learning Late: 0.0568
Epoch 86: 100%|██████████| 391/391 [06:07<00:00,  1.06batch/s]
Avg Loss : 0.0990 Validation Loss : 0.0938 Learning Late: 0.0497
Epoch 87: 100%|██████████| 391/391 [06:07<00:00,  1.06batch/s]
Avg Loss : 0.1074 Validation Loss : 0.1056 Learning Late: 0.0429
Epoch 88: 100%|██████████| 391/391 [06:07<00:00,  1.06batch/s]
Avg Loss : 0.1099 Validation Loss : 0.0868 Learning Late: 0.0367
Epoch 89: 100%|██████████| 391/391 [06:04<00:00,  1.07batch/s]
Avg Loss : 0.0975 Validation Loss : 0.1177 Learning Late: 0.0309
Epoch 90: 100%|██████████| 391/391 [06:03<00:00,  1.08batch/s]
Avg Loss : 0.0921 Validation Loss : 0.0880 Learning Late: 0.0256
Epoch 91: 100%|██████████| 391/391 [06:00<00:00,  1.09batch/s]
Avg Loss : 0.0923 Validation Loss : 0.1173 Learning Late: 0.0208
Epoch 92: 100%|██████████| 391/391 [05:59<00:00,  1.09batch/s]
Avg Loss : 0.0971 Validation Loss : 0.1046 Learning Late: 0.0164
Epoch 93: 100%|██████████| 391/391 [06:03<00:00,  1.07batch/s]
Avg Loss : 0.0985 Validation Loss : 0.0835 Learning Late: 0.0126
Epoch 94: 100%|██████████| 391/391 [06:00<00:00,  1.08batch/s]
Avg Loss : 0.1048 Validation Loss : 0.0935 Learning Late: 0.0093
Epoch 95: 100%|██████████| 391/391 [06:06<00:00,  1.07batch/s]
Avg Loss : 0.0991 Validation Loss : 0.1167 Learning Late: 0.0064
Epoch 96: 100%|██████████| 391/391 [06:04<00:00,  1.07batch/s]
Avg Loss : 0.0946 Validation Loss : 0.0997 Learning Late: 0.0041
Epoch 97: 100%|██████████| 391/391 [06:03<00:00,  1.07batch/s]
Avg Loss : 0.1018 Validation Loss : 0.1096 Learning Late: 0.0023
Epoch 98: 100%|██████████| 391/391 [06:03<00:00,  1.08batch/s]
Avg Loss : 0.0951 Validation Loss : 0.1084 Learning Late: 0.0010
Epoch 99: 100%|██████████| 391/391 [06:03<00:00,  1.07batch/s]
Avg Loss : 0.0906 Validation Loss : 0.1075 Learning Late: 0.0003
Epoch 100: 100%|██████████| 391/391 [06:05<00:00,  1.07batch/s]
Avg Loss : 0.1005 Validation Loss : 0.1032 Learning Late: 0.0000
FG 학습 완료. 이제 F의 output을 실제 dataset의 label과 연결.
Files already downloaded and verified
Files already downloaded and verified
Epoch 1: 100%|██████████| 391/391 [00:24<00:00, 15.81batch/s]
Avg Loss : 6.1150 Validation Loss : 3.4107 Learning Late: 0.0010
Epoch 2: 100%|██████████| 391/391 [00:24<00:00, 16.05batch/s]
Avg Loss : 2.9553 Validation Loss : 2.8090 Learning Late: 0.0010
Epoch 3: 100%|██████████| 391/391 [00:24<00:00, 16.24batch/s]
Avg Loss : 2.5241 Validation Loss : 2.4114 Learning Late: 0.0010
Epoch 4: 100%|██████████| 391/391 [00:24<00:00, 15.79batch/s]
Avg Loss : 2.3320 Validation Loss : 2.7320 Learning Late: 0.0010
Epoch 5: 100%|██████████| 391/391 [00:24<00:00, 15.72batch/s]
Avg Loss : 2.2676 Validation Loss : 2.1541 Learning Late: 0.0010
Epoch 6: 100%|██████████| 391/391 [00:24<00:00, 15.92batch/s]
Avg Loss : 2.2830 Validation Loss : 2.2201 Learning Late: 0.0010
Epoch 7: 100%|██████████| 391/391 [00:24<00:00, 15.78batch/s]
Avg Loss : 2.1971 Validation Loss : 2.1686 Learning Late: 0.0010
Epoch 8: 100%|██████████| 391/391 [00:24<00:00, 15.88batch/s]
Avg Loss : 2.1968 Validation Loss : 2.6359 Learning Late: 0.0010
Epoch 9: 100%|██████████| 391/391 [00:24<00:00, 15.88batch/s]
Avg Loss : 2.2339 Validation Loss : 2.2516 Learning Late: 0.0010
Epoch 10: 100%|██████████| 391/391 [00:24<00:00, 15.66batch/s]
Avg Loss : 2.2070 Validation Loss : 2.2208 Learning Late: 0.0010
Epoch 11: 100%|██████████| 391/391 [00:25<00:00, 15.61batch/s]
Avg Loss : 2.2056 Validation Loss : 2.0982 Learning Late: 0.0010
Epoch 12: 100%|██████████| 391/391 [00:24<00:00, 16.28batch/s]
Avg Loss : 2.2486 Validation Loss : 2.5152 Learning Late: 0.0010
Epoch 13: 100%|██████████| 391/391 [00:24<00:00, 15.85batch/s]
Avg Loss : 2.2476 Validation Loss : 2.3605 Learning Late: 0.0010
Epoch 14: 100%|██████████| 391/391 [00:24<00:00, 16.21batch/s]
Avg Loss : 2.2400 Validation Loss : 2.5842 Learning Late: 0.0010
Epoch 15: 100%|██████████| 391/391 [00:24<00:00, 16.17batch/s]
Avg Loss : 2.2021 Validation Loss : 2.3259 Learning Late: 0.0010
Epoch 16: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 2.2360 Validation Loss : 2.4168 Learning Late: 0.0010
Epoch 17: 100%|██████████| 391/391 [00:24<00:00, 16.19batch/s]
Avg Loss : 2.1535 Validation Loss : 2.6132 Learning Late: 0.0010
Epoch 18: 100%|██████████| 391/391 [00:24<00:00, 15.74batch/s]
Avg Loss : 2.1574 Validation Loss : 2.1266 Learning Late: 0.0010
Epoch 19: 100%|██████████| 391/391 [00:24<00:00, 15.78batch/s]
Avg Loss : 2.1725 Validation Loss : 2.5315 Learning Late: 0.0010
Epoch 20: 100%|██████████| 391/391 [00:24<00:00, 16.10batch/s]
Avg Loss : 2.1969 Validation Loss : 2.2341 Learning Late: 0.0010
Epoch 21: 100%|██████████| 391/391 [00:24<00:00, 16.12batch/s]
Avg Loss : 2.1887 Validation Loss : 2.3818 Learning Late: 0.0010
Epoch 22: 100%|██████████| 391/391 [00:24<00:00, 16.08batch/s]
Avg Loss : 2.1646 Validation Loss : 2.5979 Learning Late: 0.0010
Epoch 23: 100%|██████████| 391/391 [00:24<00:00, 15.96batch/s]
Avg Loss : 2.1653 Validation Loss : 2.1713 Learning Late: 0.0010
Epoch 24: 100%|██████████| 391/391 [00:24<00:00, 15.71batch/s]
Avg Loss : 2.1634 Validation Loss : 2.2653 Learning Late: 0.0010
Epoch 25: 100%|██████████| 391/391 [00:24<00:00, 15.95batch/s]
Avg Loss : 2.2132 Validation Loss : 2.1659 Learning Late: 0.0010
Epoch 26: 100%|██████████| 391/391 [00:24<00:00, 15.86batch/s]
Avg Loss : 2.2302 Validation Loss : 2.1988 Learning Late: 0.0010
Epoch 27: 100%|██████████| 391/391 [00:24<00:00, 16.08batch/s]
Avg Loss : 2.1640 Validation Loss : 2.4481 Learning Late: 0.0010
Epoch 28: 100%|██████████| 391/391 [00:24<00:00, 15.87batch/s]
Avg Loss : 2.1908 Validation Loss : 2.1094 Learning Late: 0.0010
Epoch 29: 100%|██████████| 391/391 [00:24<00:00, 16.03batch/s]
Avg Loss : 2.1357 Validation Loss : 2.1444 Learning Late: 0.0010
Epoch 30: 100%|██████████| 391/391 [00:24<00:00, 15.93batch/s]
Avg Loss : 2.1727 Validation Loss : 2.3690 Learning Late: 0.0010
Epoch 31: 100%|██████████| 391/391 [00:24<00:00, 16.05batch/s]
Avg Loss : 2.1685 Validation Loss : 2.2277 Learning Late: 0.0010
Epoch 32: 100%|██████████| 391/391 [00:24<00:00, 15.70batch/s]
Avg Loss : 2.1657 Validation Loss : 2.0378 Learning Late: 0.0010
Epoch 33: 100%|██████████| 391/391 [00:24<00:00, 15.85batch/s]
Avg Loss : 2.2091 Validation Loss : 2.1437 Learning Late: 0.0010
Epoch 34: 100%|██████████| 391/391 [00:24<00:00, 16.03batch/s]
Avg Loss : 2.1465 Validation Loss : 2.1436 Learning Late: 0.0010
Epoch 35: 100%|██████████| 391/391 [00:25<00:00, 15.54batch/s]
Avg Loss : 2.1199 Validation Loss : 2.1632 Learning Late: 0.0010
Epoch 36: 100%|██████████| 391/391 [00:25<00:00, 15.59batch/s]
Avg Loss : 2.1411 Validation Loss : 2.4122 Learning Late: 0.0010
Epoch 37: 100%|██████████| 391/391 [00:24<00:00, 15.93batch/s]
Avg Loss : 2.1214 Validation Loss : 2.1617 Learning Late: 0.0010
Epoch 38: 100%|██████████| 391/391 [00:24<00:00, 16.04batch/s]
Avg Loss : 2.1400 Validation Loss : 2.0251 Learning Late: 0.0009
Epoch 39: 100%|██████████| 391/391 [00:24<00:00, 15.92batch/s]
Avg Loss : 2.1174 Validation Loss : 2.4995 Learning Late: 0.0009
Epoch 40: 100%|██████████| 391/391 [00:24<00:00, 16.15batch/s]
Avg Loss : 2.0739 Validation Loss : 2.2052 Learning Late: 0.0009
Epoch 41: 100%|██████████| 391/391 [00:24<00:00, 15.97batch/s]
Avg Loss : 2.0427 Validation Loss : 2.0572 Learning Late: 0.0009
Epoch 42: 100%|██████████| 391/391 [00:24<00:00, 15.90batch/s]
Avg Loss : 2.1222 Validation Loss : 2.1565 Learning Late: 0.0009
Epoch 43: 100%|██████████| 391/391 [00:24<00:00, 16.24batch/s]
Avg Loss : 2.1222 Validation Loss : 2.1639 Learning Late: 0.0009
Epoch 44: 100%|██████████| 391/391 [00:23<00:00, 16.39batch/s]
Avg Loss : 2.0670 Validation Loss : 1.9366 Learning Late: 0.0009
Epoch 45: 100%|██████████| 391/391 [00:24<00:00, 16.03batch/s]
Avg Loss : 2.1217 Validation Loss : 2.2667 Learning Late: 0.0009
Epoch 46: 100%|██████████| 391/391 [00:24<00:00, 15.72batch/s]
Avg Loss : 2.0281 Validation Loss : 2.2923 Learning Late: 0.0009
Epoch 47: 100%|██████████| 391/391 [00:24<00:00, 15.95batch/s]
Avg Loss : 2.1273 Validation Loss : 2.2006 Learning Late: 0.0009
Epoch 48: 100%|██████████| 391/391 [00:24<00:00, 15.69batch/s]
Avg Loss : 2.0114 Validation Loss : 2.0537 Learning Late: 0.0009
Epoch 49: 100%|██████████| 391/391 [00:24<00:00, 16.14batch/s]
Avg Loss : 2.0294 Validation Loss : 2.0448 Learning Late: 0.0009
Epoch 50: 100%|██████████| 391/391 [00:24<00:00, 15.82batch/s]
Avg Loss : 2.0630 Validation Loss : 1.9982 Learning Late: 0.0009
Epoch 51: 100%|██████████| 391/391 [00:23<00:00, 16.36batch/s]
Avg Loss : 2.0644 Validation Loss : 2.0649 Learning Late: 0.0009
Epoch 52: 100%|██████████| 391/391 [00:24<00:00, 15.79batch/s]
Avg Loss : 2.0542 Validation Loss : 2.0416 Learning Late: 0.0009
Epoch 53: 100%|██████████| 391/391 [00:24<00:00, 16.19batch/s]
Avg Loss : 1.9972 Validation Loss : 1.8303 Learning Late: 0.0009
Epoch 54: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 2.0329 Validation Loss : 1.9674 Learning Late: 0.0009
Epoch 55: 100%|██████████| 391/391 [00:23<00:00, 16.36batch/s]
Avg Loss : 1.9945 Validation Loss : 2.0574 Learning Late: 0.0009
Epoch 56: 100%|██████████| 391/391 [00:24<00:00, 15.84batch/s]
Avg Loss : 1.9616 Validation Loss : 2.0035 Learning Late: 0.0009
Epoch 57: 100%|██████████| 391/391 [00:24<00:00, 16.16batch/s]
Avg Loss : 1.9637 Validation Loss : 2.0663 Learning Late: 0.0009
Epoch 58: 100%|██████████| 391/391 [00:24<00:00, 16.03batch/s]
Avg Loss : 2.0378 Validation Loss : 2.0841 Learning Late: 0.0009
Epoch 59: 100%|██████████| 391/391 [00:24<00:00, 16.12batch/s]
Avg Loss : 1.9954 Validation Loss : 1.9697 Learning Late: 0.0008
Epoch 60: 100%|██████████| 391/391 [00:24<00:00, 15.97batch/s]
Avg Loss : 1.9985 Validation Loss : 2.0196 Learning Late: 0.0008
Epoch 61: 100%|██████████| 391/391 [00:24<00:00, 16.05batch/s]
Avg Loss : 1.9361 Validation Loss : 2.0553 Learning Late: 0.0008
Epoch 62: 100%|██████████| 391/391 [00:24<00:00, 15.83batch/s]
Avg Loss : 1.9808 Validation Loss : 2.1781 Learning Late: 0.0008
Epoch 63: 100%|██████████| 391/391 [00:24<00:00, 16.27batch/s]
Avg Loss : 1.9542 Validation Loss : 1.8382 Learning Late: 0.0008
Epoch 64: 100%|██████████| 391/391 [00:24<00:00, 16.12batch/s]
Avg Loss : 1.9217 Validation Loss : 1.8968 Learning Late: 0.0008
Epoch 65: 100%|██████████| 391/391 [00:24<00:00, 15.71batch/s]
Avg Loss : 1.9011 Validation Loss : 2.0368 Learning Late: 0.0008
Epoch 66: 100%|██████████| 391/391 [00:24<00:00, 15.87batch/s]
Avg Loss : 1.8808 Validation Loss : 1.9466 Learning Late: 0.0008
Epoch 67: 100%|██████████| 391/391 [00:24<00:00, 15.97batch/s]
Avg Loss : 1.8836 Validation Loss : 2.1416 Learning Late: 0.0008
Epoch 68: 100%|██████████| 391/391 [00:24<00:00, 15.74batch/s]
Avg Loss : 1.8992 Validation Loss : 1.8456 Learning Late: 0.0008
Epoch 69: 100%|██████████| 391/391 [00:24<00:00, 15.96batch/s]
Avg Loss : 1.8805 Validation Loss : 1.9254 Learning Late: 0.0008
Epoch 70: 100%|██████████| 391/391 [00:24<00:00, 15.74batch/s]
Avg Loss : 1.8653 Validation Loss : 1.8808 Learning Late: 0.0008
Epoch 71: 100%|██████████| 391/391 [00:25<00:00, 15.21batch/s]
Avg Loss : 1.8787 Validation Loss : 2.0645 Learning Late: 0.0008
Epoch 72: 100%|██████████| 391/391 [00:29<00:00, 13.11batch/s]
Avg Loss : 1.8995 Validation Loss : 1.8029 Learning Late: 0.0008
Epoch 73: 100%|██████████| 391/391 [00:24<00:00, 15.82batch/s]
Avg Loss : 1.7862 Validation Loss : 1.9326 Learning Late: 0.0008
Epoch 74: 100%|██████████| 391/391 [00:25<00:00, 15.41batch/s]
Avg Loss : 1.8152 Validation Loss : 2.1003 Learning Late: 0.0007
Epoch 75: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.8285 Validation Loss : 2.0167 Learning Late: 0.0007
Epoch 76: 100%|██████████| 391/391 [00:28<00:00, 13.95batch/s]
Avg Loss : 1.7997 Validation Loss : 1.8720 Learning Late: 0.0007
Epoch 77: 100%|██████████| 391/391 [00:24<00:00, 16.15batch/s]
Avg Loss : 1.7961 Validation Loss : 2.1483 Learning Late: 0.0007
Epoch 78: 100%|██████████| 391/391 [00:24<00:00, 15.76batch/s]
Avg Loss : 1.7878 Validation Loss : 1.8422 Learning Late: 0.0007
Epoch 79: 100%|██████████| 391/391 [00:24<00:00, 15.86batch/s]
Avg Loss : 1.7808 Validation Loss : 1.8008 Learning Late: 0.0007
Epoch 80: 100%|██████████| 391/391 [00:29<00:00, 13.07batch/s]
Avg Loss : 1.7917 Validation Loss : 1.8406 Learning Late: 0.0007
Epoch 81: 100%|██████████| 391/391 [00:25<00:00, 15.50batch/s]
Avg Loss : 1.7153 Validation Loss : 1.9797 Learning Late: 0.0007
Epoch 82: 100%|██████████| 391/391 [00:24<00:00, 16.06batch/s]
Avg Loss : 1.7318 Validation Loss : 1.9158 Learning Late: 0.0007
Epoch 83: 100%|██████████| 391/391 [00:24<00:00, 15.90batch/s]
Avg Loss : 1.7532 Validation Loss : 1.8931 Learning Late: 0.0007
Epoch 84: 100%|██████████| 391/391 [00:25<00:00, 15.56batch/s]
Avg Loss : 1.7136 Validation Loss : 1.6389 Learning Late: 0.0007
Epoch 85: 100%|██████████| 391/391 [00:32<00:00, 11.87batch/s]
Avg Loss : 1.7153 Validation Loss : 1.8120 Learning Late: 0.0007
Epoch 86: 100%|██████████| 391/391 [00:27<00:00, 14.32batch/s]
Avg Loss : 1.7313 Validation Loss : 1.7903 Learning Late: 0.0007
Epoch 87: 100%|██████████| 391/391 [00:24<00:00, 15.88batch/s]
Avg Loss : 1.7246 Validation Loss : 1.7207 Learning Late: 0.0006
Epoch 88: 100%|██████████| 391/391 [00:24<00:00, 15.77batch/s]
Avg Loss : 1.6650 Validation Loss : 1.9361 Learning Late: 0.0006
Epoch 89: 100%|██████████| 391/391 [00:27<00:00, 13.97batch/s]
Avg Loss : 1.6864 Validation Loss : 1.6991 Learning Late: 0.0006
Epoch 90: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.7026 Validation Loss : 1.7739 Learning Late: 0.0006
Epoch 91: 100%|██████████| 391/391 [00:24<00:00, 15.92batch/s]
Avg Loss : 1.6446 Validation Loss : 1.7895 Learning Late: 0.0006
Epoch 92: 100%|██████████| 391/391 [00:27<00:00, 14.24batch/s]
Avg Loss : 1.6243 Validation Loss : 1.7352 Learning Late: 0.0006
Epoch 93: 100%|██████████| 391/391 [00:28<00:00, 13.75batch/s]
Avg Loss : 1.6269 Validation Loss : 1.8091 Learning Late: 0.0006
Epoch 94: 100%|██████████| 391/391 [00:24<00:00, 16.16batch/s]
Avg Loss : 1.6176 Validation Loss : 1.8045 Learning Late: 0.0006
Epoch 95: 100%|██████████| 391/391 [00:24<00:00, 15.93batch/s]
Avg Loss : 1.6245 Validation Loss : 1.6932 Learning Late: 0.0006
Epoch 96: 100%|██████████| 391/391 [00:24<00:00, 15.86batch/s]
Avg Loss : 1.5806 Validation Loss : 1.5690 Learning Late: 0.0006
Epoch 97: 100%|██████████| 391/391 [00:24<00:00, 16.19batch/s]
Avg Loss : 1.5588 Validation Loss : 1.6048 Learning Late: 0.0006
Epoch 98: 100%|██████████| 391/391 [00:24<00:00, 16.11batch/s]
Avg Loss : 1.5748 Validation Loss : 1.6554 Learning Late: 0.0006
Epoch 99: 100%|██████████| 391/391 [00:24<00:00, 16.16batch/s]
Avg Loss : 1.5672 Validation Loss : 1.6191 Learning Late: 0.0005
Epoch 100: 100%|██████████| 391/391 [00:24<00:00, 15.86batch/s]
Avg Loss : 1.5466 Validation Loss : 1.5374 Learning Late: 0.0005
Epoch 101: 100%|██████████| 391/391 [00:23<00:00, 16.30batch/s]
Avg Loss : 1.5419 Validation Loss : 1.6928 Learning Late: 0.0005
Epoch 102: 100%|██████████| 391/391 [00:24<00:00, 16.22batch/s]
Avg Loss : 1.5407 Validation Loss : 1.6644 Learning Late: 0.0005
Epoch 103: 100%|██████████| 391/391 [00:24<00:00, 16.29batch/s]
Avg Loss : 1.5326 Validation Loss : 1.7342 Learning Late: 0.0005
Epoch 104: 100%|██████████| 391/391 [00:24<00:00, 16.21batch/s]
Avg Loss : 1.5189 Validation Loss : 1.5790 Learning Late: 0.0005
Epoch 105: 100%|██████████| 391/391 [00:24<00:00, 15.80batch/s]
Avg Loss : 1.4916 Validation Loss : 1.6373 Learning Late: 0.0005
Epoch 106: 100%|██████████| 391/391 [00:24<00:00, 16.03batch/s]
Avg Loss : 1.5265 Validation Loss : 1.5058 Learning Late: 0.0005
Epoch 107: 100%|██████████| 391/391 [00:24<00:00, 15.81batch/s]
Avg Loss : 1.5004 Validation Loss : 1.5228 Learning Late: 0.0005
Epoch 108: 100%|██████████| 391/391 [00:25<00:00, 15.60batch/s]
Avg Loss : 1.4858 Validation Loss : 1.4462 Learning Late: 0.0005
Epoch 109: 100%|██████████| 391/391 [00:24<00:00, 15.97batch/s]
Avg Loss : 1.4672 Validation Loss : 1.5048 Learning Late: 0.0005
Epoch 110: 100%|██████████| 391/391 [00:24<00:00, 15.71batch/s]
Avg Loss : 1.4667 Validation Loss : 1.4621 Learning Late: 0.0005
Epoch 111: 100%|██████████| 391/391 [00:24<00:00, 15.89batch/s]
Avg Loss : 1.4743 Validation Loss : 1.5886 Learning Late: 0.0005
Epoch 112: 100%|██████████| 391/391 [00:24<00:00, 15.89batch/s]
Avg Loss : 1.4504 Validation Loss : 1.4407 Learning Late: 0.0004
Epoch 113: 100%|██████████| 391/391 [00:24<00:00, 16.18batch/s]
Avg Loss : 1.4271 Validation Loss : 1.4610 Learning Late: 0.0004
Epoch 114: 100%|██████████| 391/391 [00:24<00:00, 15.88batch/s]
Avg Loss : 1.4247 Validation Loss : 1.4203 Learning Late: 0.0004
Epoch 115: 100%|██████████| 391/391 [00:24<00:00, 15.68batch/s]
Avg Loss : 1.4118 Validation Loss : 1.4116 Learning Late: 0.0004
Epoch 116: 100%|██████████| 391/391 [00:25<00:00, 15.13batch/s]
Avg Loss : 1.4108 Validation Loss : 1.3555 Learning Late: 0.0004
Epoch 117: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.4025 Validation Loss : 1.3711 Learning Late: 0.0004
Epoch 118: 100%|██████████| 391/391 [00:24<00:00, 15.86batch/s]
Avg Loss : 1.3778 Validation Loss : 1.6144 Learning Late: 0.0004
Epoch 119: 100%|██████████| 391/391 [00:24<00:00, 15.89batch/s]
Avg Loss : 1.3940 Validation Loss : 1.3521 Learning Late: 0.0004
Epoch 120: 100%|██████████| 391/391 [00:24<00:00, 16.04batch/s]
Avg Loss : 1.3554 Validation Loss : 1.4471 Learning Late: 0.0004
Epoch 121: 100%|██████████| 391/391 [00:25<00:00, 15.58batch/s]
Avg Loss : 1.3779 Validation Loss : 1.4739 Learning Late: 0.0004
Epoch 122: 100%|██████████| 391/391 [00:24<00:00, 15.72batch/s]
Avg Loss : 1.3464 Validation Loss : 1.4552 Learning Late: 0.0004
Epoch 123: 100%|██████████| 391/391 [00:24<00:00, 15.79batch/s]
Avg Loss : 1.3529 Validation Loss : 1.4228 Learning Late: 0.0004
Epoch 124: 100%|██████████| 391/391 [00:24<00:00, 16.24batch/s]
Avg Loss : 1.3458 Validation Loss : 1.4556 Learning Late: 0.0003
Epoch 125: 100%|██████████| 391/391 [00:24<00:00, 15.75batch/s]
Avg Loss : 1.3187 Validation Loss : 1.3866 Learning Late: 0.0003
Epoch 126: 100%|██████████| 391/391 [00:24<00:00, 15.78batch/s]
Avg Loss : 1.3066 Validation Loss : 1.3218 Learning Late: 0.0003
Epoch 127: 100%|██████████| 391/391 [00:24<00:00, 16.18batch/s]
Avg Loss : 1.3100 Validation Loss : 1.3535 Learning Late: 0.0003
Epoch 128: 100%|██████████| 391/391 [00:24<00:00, 16.24batch/s]
Avg Loss : 1.3073 Validation Loss : 1.3667 Learning Late: 0.0003
Epoch 129: 100%|██████████| 391/391 [00:24<00:00, 15.82batch/s]
Avg Loss : 1.3102 Validation Loss : 1.2778 Learning Late: 0.0003
Epoch 130: 100%|██████████| 391/391 [00:24<00:00, 15.83batch/s]
Avg Loss : 1.2744 Validation Loss : 1.3307 Learning Late: 0.0003
Epoch 131: 100%|██████████| 391/391 [00:24<00:00, 16.06batch/s]
Avg Loss : 1.2797 Validation Loss : 1.2976 Learning Late: 0.0003
Epoch 132: 100%|██████████| 391/391 [00:24<00:00, 16.15batch/s]
Avg Loss : 1.2660 Validation Loss : 1.2706 Learning Late: 0.0003
Epoch 133: 100%|██████████| 391/391 [00:24<00:00, 15.74batch/s]
Avg Loss : 1.2597 Validation Loss : 1.2417 Learning Late: 0.0003
Epoch 134: 100%|██████████| 391/391 [00:24<00:00, 16.17batch/s]
Avg Loss : 1.2458 Validation Loss : 1.3029 Learning Late: 0.0003
Epoch 135: 100%|██████████| 391/391 [00:24<00:00, 16.17batch/s]
Avg Loss : 1.2630 Validation Loss : 1.2750 Learning Late: 0.0003
Epoch 136: 100%|██████████| 391/391 [00:24<00:00, 15.64batch/s]
Avg Loss : 1.2361 Validation Loss : 1.2929 Learning Late: 0.0003
Epoch 137: 100%|██████████| 391/391 [00:24<00:00, 15.97batch/s]
Avg Loss : 1.2581 Validation Loss : 1.3136 Learning Late: 0.0002
Epoch 138: 100%|██████████| 391/391 [00:24<00:00, 16.28batch/s]
Avg Loss : 1.2286 Validation Loss : 1.2795 Learning Late: 0.0002
Epoch 139: 100%|██████████| 391/391 [00:24<00:00, 15.83batch/s]
Avg Loss : 1.2189 Validation Loss : 1.2508 Learning Late: 0.0002
Epoch 140: 100%|██████████| 391/391 [00:24<00:00, 16.06batch/s]
Avg Loss : 1.2117 Validation Loss : 1.2656 Learning Late: 0.0002
Epoch 141: 100%|██████████| 391/391 [00:24<00:00, 16.21batch/s]
Avg Loss : 1.2079 Validation Loss : 1.2392 Learning Late: 0.0002
Epoch 142: 100%|██████████| 391/391 [00:24<00:00, 16.21batch/s]
Avg Loss : 1.1939 Validation Loss : 1.2701 Learning Late: 0.0002
Epoch 143: 100%|██████████| 391/391 [00:23<00:00, 16.49batch/s]
Avg Loss : 1.1944 Validation Loss : 1.2693 Learning Late: 0.0002
Epoch 144: 100%|██████████| 391/391 [00:23<00:00, 16.44batch/s]
Avg Loss : 1.1968 Validation Loss : 1.2231 Learning Late: 0.0002
Epoch 145: 100%|██████████| 391/391 [00:23<00:00, 16.44batch/s]
Avg Loss : 1.1839 Validation Loss : 1.2132 Learning Late: 0.0002
Epoch 146: 100%|██████████| 391/391 [00:23<00:00, 16.40batch/s]
Avg Loss : 1.1769 Validation Loss : 1.2186 Learning Late: 0.0002
Epoch 147: 100%|██████████| 391/391 [00:25<00:00, 15.62batch/s]
Avg Loss : 1.1665 Validation Loss : 1.1820 Learning Late: 0.0002
Epoch 148: 100%|██████████| 391/391 [00:24<00:00, 16.09batch/s]
Avg Loss : 1.1600 Validation Loss : 1.1769 Learning Late: 0.0002
Epoch 149: 100%|██████████| 391/391 [00:24<00:00, 15.99batch/s]
Avg Loss : 1.1559 Validation Loss : 1.2421 Learning Late: 0.0002
Epoch 150: 100%|██████████| 391/391 [00:25<00:00, 15.41batch/s]
Avg Loss : 1.1609 Validation Loss : 1.2281 Learning Late: 0.0002
Epoch 151: 100%|██████████| 391/391 [00:24<00:00, 16.15batch/s]
Avg Loss : 1.1432 Validation Loss : 1.1630 Learning Late: 0.0002
Epoch 152: 100%|██████████| 391/391 [00:24<00:00, 16.24batch/s]
Avg Loss : 1.1331 Validation Loss : 1.1817 Learning Late: 0.0001
Epoch 153: 100%|██████████| 391/391 [00:23<00:00, 16.31batch/s]
Avg Loss : 1.1295 Validation Loss : 1.1850 Learning Late: 0.0001
Epoch 154: 100%|██████████| 391/391 [00:24<00:00, 16.27batch/s]
Avg Loss : 1.1435 Validation Loss : 1.1886 Learning Late: 0.0001
Epoch 155: 100%|██████████| 391/391 [00:24<00:00, 16.12batch/s]
Avg Loss : 1.1181 Validation Loss : 1.1662 Learning Late: 0.0001
Epoch 156: 100%|██████████| 391/391 [00:24<00:00, 16.15batch/s]
Avg Loss : 1.1180 Validation Loss : 1.1793 Learning Late: 0.0001
Epoch 157: 100%|██████████| 391/391 [00:24<00:00, 16.16batch/s]
Avg Loss : 1.1165 Validation Loss : 1.1555 Learning Late: 0.0001
Epoch 158: 100%|██████████| 391/391 [00:24<00:00, 16.17batch/s]
Avg Loss : 1.1053 Validation Loss : 1.1482 Learning Late: 0.0001
Epoch 159: 100%|██████████| 391/391 [00:24<00:00, 16.18batch/s]
Avg Loss : 1.1058 Validation Loss : 1.1526 Learning Late: 0.0001
Epoch 160: 100%|██████████| 391/391 [00:24<00:00, 16.16batch/s]
Avg Loss : 1.0995 Validation Loss : 1.1588 Learning Late: 0.0001
Epoch 161: 100%|██████████| 391/391 [00:24<00:00, 16.18batch/s]
Avg Loss : 1.0956 Validation Loss : 1.1539 Learning Late: 0.0001
Epoch 162: 100%|██████████| 391/391 [00:24<00:00, 16.19batch/s]
Avg Loss : 1.0916 Validation Loss : 1.1748 Learning Late: 0.0001
Epoch 163: 100%|██████████| 391/391 [00:24<00:00, 16.18batch/s]
Avg Loss : 1.0841 Validation Loss : 1.1406 Learning Late: 0.0001
Epoch 164: 100%|██████████| 391/391 [00:23<00:00, 16.34batch/s]
Avg Loss : 1.0791 Validation Loss : 1.1274 Learning Late: 0.0001
Epoch 165: 100%|██████████| 391/391 [00:24<00:00, 16.18batch/s]
Avg Loss : 1.0746 Validation Loss : 1.1304 Learning Late: 0.0001
Epoch 166: 100%|██████████| 391/391 [00:24<00:00, 16.21batch/s]
Avg Loss : 1.0724 Validation Loss : 1.1295 Learning Late: 0.0001
Epoch 167: 100%|██████████| 391/391 [00:24<00:00, 15.82batch/s]
Avg Loss : 1.0713 Validation Loss : 1.1163 Learning Late: 0.0001
Epoch 168: 100%|██████████| 391/391 [00:24<00:00, 15.94batch/s]
Avg Loss : 1.0665 Validation Loss : 1.1176 Learning Late: 0.0001
Epoch 169: 100%|██████████| 391/391 [00:23<00:00, 16.37batch/s]
Avg Loss : 1.0611 Validation Loss : 1.1187 Learning Late: 0.0001
Epoch 170: 100%|██████████| 391/391 [00:23<00:00, 16.45batch/s]
Avg Loss : 1.0595 Validation Loss : 1.1164 Learning Late: 0.0001
Epoch 171: 100%|██████████| 391/391 [00:23<00:00, 16.56batch/s]
Avg Loss : 1.0549 Validation Loss : 1.1296 Learning Late: 0.0001
Epoch 172: 100%|██████████| 391/391 [00:23<00:00, 16.42batch/s]
Avg Loss : 1.0508 Validation Loss : 1.1107 Learning Late: 0.0001
Epoch 173: 100%|██████████| 391/391 [00:23<00:00, 16.44batch/s]
Avg Loss : 1.0463 Validation Loss : 1.1090 Learning Late: 0.0000
Epoch 174: 100%|██████████| 391/391 [00:23<00:00, 16.42batch/s]
Avg Loss : 1.0444 Validation Loss : 1.0986 Learning Late: 0.0000
Epoch 175: 100%|██████████| 391/391 [00:23<00:00, 16.45batch/s]
Avg Loss : 1.0401 Validation Loss : 1.1100 Learning Late: 0.0000
Epoch 176: 100%|██████████| 391/391 [00:23<00:00, 16.44batch/s]
Avg Loss : 1.0375 Validation Loss : 1.0981 Learning Late: 0.0000
Epoch 177: 100%|██████████| 391/391 [00:23<00:00, 16.31batch/s]
Avg Loss : 1.0357 Validation Loss : 1.1090 Learning Late: 0.0000
Epoch 178: 100%|██████████| 391/391 [00:23<00:00, 16.31batch/s]
Avg Loss : 1.0301 Validation Loss : 1.0970 Learning Late: 0.0000
Epoch 179: 100%|██████████| 391/391 [00:23<00:00, 16.31batch/s]
Avg Loss : 1.0290 Validation Loss : 1.0907 Learning Late: 0.0000
Epoch 180: 100%|██████████| 391/391 [00:23<00:00, 16.43batch/s]
Avg Loss : 1.0258 Validation Loss : 1.0919 Learning Late: 0.0000
Epoch 181: 100%|██████████| 391/391 [00:23<00:00, 16.46batch/s]
Avg Loss : 1.0232 Validation Loss : 1.0982 Learning Late: 0.0000
Epoch 182: 100%|██████████| 391/391 [00:23<00:00, 16.44batch/s]
Avg Loss : 1.0216 Validation Loss : 1.0894 Learning Late: 0.0000
Epoch 183: 100%|██████████| 391/391 [00:23<00:00, 16.44batch/s]
Avg Loss : 1.0182 Validation Loss : 1.0867 Learning Late: 0.0000
Epoch 184: 100%|██████████| 391/391 [00:23<00:00, 16.45batch/s]
Avg Loss : 1.0170 Validation Loss : 1.0864 Learning Late: 0.0000
Epoch 185: 100%|██████████| 391/391 [00:23<00:00, 16.57batch/s]
Avg Loss : 1.0150 Validation Loss : 1.0781 Learning Late: 0.0000
Epoch 186: 100%|██████████| 391/391 [00:23<00:00, 16.45batch/s]
Avg Loss : 1.0121 Validation Loss : 1.0765 Learning Late: 0.0000
Epoch 187: 100%|██████████| 391/391 [00:23<00:00, 16.45batch/s]
Avg Loss : 1.0099 Validation Loss : 1.0780 Learning Late: 0.0000
Epoch 188: 100%|██████████| 391/391 [00:24<00:00, 15.87batch/s]
Avg Loss : 1.0088 Validation Loss : 1.0757 Learning Late: 0.0000
Epoch 189: 100%|██████████| 391/391 [00:24<00:00, 16.29batch/s]
Avg Loss : 1.0070 Validation Loss : 1.0723 Learning Late: 0.0000
Epoch 190: 100%|██████████| 391/391 [00:24<00:00, 16.09batch/s]
Avg Loss : 1.0058 Validation Loss : 1.0776 Learning Late: 0.0000
Epoch 191: 100%|██████████| 391/391 [00:23<00:00, 16.41batch/s]
Avg Loss : 1.0039 Validation Loss : 1.0733 Learning Late: 0.0000
Epoch 192: 100%|██████████| 391/391 [00:23<00:00, 16.37batch/s]
Avg Loss : 1.0022 Validation Loss : 1.0685 Learning Late: 0.0000
Epoch 193: 100%|██████████| 391/391 [00:24<00:00, 15.88batch/s]
Avg Loss : 1.0010 Validation Loss : 1.0699 Learning Late: 0.0000
Epoch 194: 100%|██████████| 391/391 [00:24<00:00, 16.14batch/s]
Avg Loss : 1.0004 Validation Loss : 1.0732 Learning Late: 0.0000
Epoch 195: 100%|██████████| 391/391 [00:24<00:00, 16.10batch/s]
Avg Loss : 0.9996 Validation Loss : 1.0744 Learning Late: 0.0000
Epoch 196: 100%|██████████| 391/391 [00:23<00:00, 16.31batch/s]
Avg Loss : 0.9987 Validation Loss : 1.0741 Learning Late: 0.0000
Epoch 197: 100%|██████████| 391/391 [00:24<00:00, 16.24batch/s]
Avg Loss : 0.9979 Validation Loss : 1.0721 Learning Late: 0.0000
Epoch 198: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 0.9971 Validation Loss : 1.0754 Learning Late: 0.0000
Epoch 199: 100%|██████████| 391/391 [00:24<00:00, 16.23batch/s]
Avg Loss : 0.9971 Validation Loss : 1.0695 Learning Late: 0.0000
Epoch 200: 100%|██████████| 391/391 [00:23<00:00, 16.39batch/s]
Avg Loss : 0.9969 Validation Loss : 1.0726 Learning Late: 0.0000
실제 test
100%|██████████| 79/79 [00:15<00:00,  5.06batch/s]
총 개수 : 10000
top-1 맞춘 개수 : 6227 
 정확도: 62.27
top-5 맞춘 개수 : 9626 
 정확도: 96.26

종료 코드 0(으)로 완료된 프로세스
