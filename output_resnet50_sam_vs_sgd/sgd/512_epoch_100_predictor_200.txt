Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz
100%|██████████| 170498071/170498071 [00:05<00:00, 31117285.32it/s]
Extracting ./data/cifar-10-python.tar.gz to ./data
Files already downloaded and verified
Epoch 1: 100%|██████████| 98/98 [00:35<00:00,  2.73batch/s]
Avg Loss : 6.6290 Validation Loss : 6.1756 Learning Late: 1.6971
Epoch 2: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 6.0641 Validation Loss : 5.8385 Learning Late: 1.6971
Epoch 3: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 5.6459 Validation Loss : 5.7829 Learning Late: 1.6971
Epoch 4: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 5.5455 Validation Loss : 5.2919 Learning Late: 1.6971
Epoch 5: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 5.5366 Validation Loss : 5.6259 Learning Late: 1.6971
Epoch 6: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 5.3653 Validation Loss : 5.3469 Learning Late: 1.6971
Epoch 7: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 5.0323 Validation Loss : 5.7512 Learning Late: 1.6971
Epoch 8: 100%|██████████| 98/98 [00:34<00:00,  2.85batch/s]
Avg Loss : 4.9303 Validation Loss : 4.9575 Learning Late: 1.6971
Epoch 9: 100%|██████████| 98/98 [00:34<00:00,  2.85batch/s]
Avg Loss : 4.6661 Validation Loss : 4.4229 Learning Late: 1.6971
Epoch 10: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 4.5172 Validation Loss : 4.3151 Learning Late: 1.6971
Epoch 11: 100%|██████████| 98/98 [00:34<00:00,  2.83batch/s]
Avg Loss : 4.3818 Validation Loss : 4.0145 Learning Late: 1.6965
Epoch 12: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 4.4557 Validation Loss : 4.0652 Learning Late: 1.6950
Epoch 13: 100%|██████████| 98/98 [00:34<00:00,  2.85batch/s]
Avg Loss : 4.4122 Validation Loss : 4.2433 Learning Late: 1.6924
Epoch 14: 100%|██████████| 98/98 [00:34<00:00,  2.85batch/s]
Avg Loss : 4.3230 Validation Loss : 4.3749 Learning Late: 1.6888
Epoch 15: 100%|██████████| 98/98 [00:34<00:00,  2.85batch/s]
Avg Loss : 4.4334 Validation Loss : 4.2020 Learning Late: 1.6842
Epoch 16: 100%|██████████| 98/98 [00:34<00:00,  2.85batch/s]
Avg Loss : 4.1167 Validation Loss : 4.5249 Learning Late: 1.6785
Epoch 17: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 4.1981 Validation Loss : 4.3068 Learning Late: 1.6719
Epoch 18: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 3.9963 Validation Loss : 3.6127 Learning Late: 1.6642
Epoch 19: 100%|██████████| 98/98 [00:34<00:00,  2.85batch/s]
Avg Loss : 3.6764 Validation Loss : 3.5401 Learning Late: 1.6555
Epoch 20: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 3.5639 Validation Loss : 3.4607 Learning Late: 1.6459
Epoch 21: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 3.2671 Validation Loss : 2.8334 Learning Late: 1.6353
Epoch 22: 100%|██████████| 98/98 [00:34<00:00,  2.83batch/s]
Avg Loss : 3.0576 Validation Loss : 2.9705 Learning Late: 1.6237
Epoch 23: 100%|██████████| 98/98 [00:34<00:00,  2.85batch/s]
Avg Loss : 2.9274 Validation Loss : 3.1079 Learning Late: 1.6112
Epoch 24: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 2.6937 Validation Loss : 2.7122 Learning Late: 1.5977
Epoch 25: 100%|██████████| 98/98 [00:34<00:00,  2.83batch/s]
Avg Loss : 3.0097 Validation Loss : 2.6780 Learning Late: 1.5834
Epoch 26: 100%|██████████| 98/98 [00:34<00:00,  2.83batch/s]
Avg Loss : 2.5079 Validation Loss : 2.4602 Learning Late: 1.5681
Epoch 27: 100%|██████████| 98/98 [00:34<00:00,  2.82batch/s]
Avg Loss : 2.4420 Validation Loss : 2.2978 Learning Late: 1.5520
Epoch 28: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 2.2844 Validation Loss : 2.0226 Learning Late: 1.5350
Epoch 29: 100%|██████████| 98/98 [00:34<00:00,  2.83batch/s]
Avg Loss : 2.1024 Validation Loss : 2.1979 Learning Late: 1.5172
Epoch 30: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 2.0336 Validation Loss : 2.1673 Learning Late: 1.4985
Epoch 31: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 1.9739 Validation Loss : 1.7533 Learning Late: 1.4791
Epoch 32: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 1.8717 Validation Loss : 1.9038 Learning Late: 1.4589
Epoch 33: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 1.8410 Validation Loss : 1.5566 Learning Late: 1.4380
Epoch 34: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 1.6687 Validation Loss : 1.6843 Learning Late: 1.4163
Epoch 35: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 1.6226 Validation Loss : 1.8360 Learning Late: 1.3940
Epoch 36: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 1.4942 Validation Loss : 1.4667 Learning Late: 1.3709
Epoch 37: 100%|██████████| 98/98 [00:34<00:00,  2.83batch/s]
Avg Loss : 1.4844 Validation Loss : 1.5655 Learning Late: 1.3473
Epoch 38: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 1.9840 Validation Loss : 1.8220 Learning Late: 1.3230
Epoch 39: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 1.4512 Validation Loss : 1.2731 Learning Late: 1.2982
Epoch 40: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 1.3637 Validation Loss : 1.3103 Learning Late: 1.2728
Epoch 41: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 1.2013 Validation Loss : 1.5245 Learning Late: 1.2469
Epoch 42: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 1.2154 Validation Loss : 1.1396 Learning Late: 1.2205
Epoch 43: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 1.1945 Validation Loss : 1.3587 Learning Late: 1.1937
Epoch 44: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 1.0994 Validation Loss : 1.1583 Learning Late: 1.1664
Epoch 45: 100%|██████████| 98/98 [00:34<00:00,  2.83batch/s]
Avg Loss : 1.1715 Validation Loss : 0.9971 Learning Late: 1.1387
Epoch 46: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 1.1156 Validation Loss : 1.1336 Learning Late: 1.1107
Epoch 47: 100%|██████████| 98/98 [00:34<00:00,  2.83batch/s]
Avg Loss : 1.0716 Validation Loss : 1.0445 Learning Late: 1.0824
Epoch 48: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 1.0545 Validation Loss : 1.0087 Learning Late: 1.0538
Epoch 49: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 0.9969 Validation Loss : 1.1956 Learning Late: 1.0249
Epoch 50: 100%|██████████| 98/98 [00:34<00:00,  2.83batch/s]
Avg Loss : 1.0122 Validation Loss : 0.8995 Learning Late: 0.9959
Epoch 51: 100%|██████████| 98/98 [00:34<00:00,  2.83batch/s]
Avg Loss : 0.9261 Validation Loss : 1.0783 Learning Late: 0.9666
Epoch 52: 100%|██████████| 98/98 [00:34<00:00,  2.83batch/s]
Avg Loss : 0.9222 Validation Loss : 0.8386 Learning Late: 0.9372
Epoch 53: 100%|██████████| 98/98 [00:34<00:00,  2.83batch/s]
Avg Loss : 0.9028 Validation Loss : 0.8604 Learning Late: 0.9077
Epoch 54: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 0.8735 Validation Loss : 0.8575 Learning Late: 0.8781
Epoch 55: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 0.9647 Validation Loss : 0.8837 Learning Late: 0.8485
Epoch 56: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 0.8550 Validation Loss : 0.8320 Learning Late: 0.8189
Epoch 57: 100%|██████████| 98/98 [00:34<00:00,  2.83batch/s]
Avg Loss : 0.8448 Validation Loss : 0.8186 Learning Late: 0.7893
Epoch 58: 100%|██████████| 98/98 [00:34<00:00,  2.83batch/s]
Avg Loss : 0.8030 Validation Loss : 0.8436 Learning Late: 0.7598
Epoch 59: 100%|██████████| 98/98 [00:34<00:00,  2.83batch/s]
Avg Loss : 0.8517 Validation Loss : 0.7752 Learning Late: 0.7304
Epoch 60: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 0.7579 Validation Loss : 0.7450 Learning Late: 0.7012
Epoch 61: 100%|██████████| 98/98 [00:34<00:00,  2.83batch/s]
Avg Loss : 0.7992 Validation Loss : 0.7884 Learning Late: 0.6721
Epoch 62: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 0.7470 Validation Loss : 0.7876 Learning Late: 0.6433
Epoch 63: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 0.7372 Validation Loss : 0.9067 Learning Late: 0.6146
Epoch 64: 100%|██████████| 98/98 [00:34<00:00,  2.83batch/s]
Avg Loss : 0.7766 Validation Loss : 0.7458 Learning Late: 0.5863
Epoch 65: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 0.7020 Validation Loss : 0.8122 Learning Late: 0.5583
Epoch 66: 100%|██████████| 98/98 [00:34<00:00,  2.83batch/s]
Avg Loss : 0.7497 Validation Loss : 0.7219 Learning Late: 0.5307
Epoch 67: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 0.7090 Validation Loss : 0.5619 Learning Late: 0.5034
Epoch 68: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 0.6672 Validation Loss : 0.6681 Learning Late: 0.4766
Epoch 69: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 0.6530 Validation Loss : 0.7294 Learning Late: 0.4502
Epoch 70: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 0.7084 Validation Loss : 0.5645 Learning Late: 0.4243
Epoch 71: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 0.6422 Validation Loss : 0.6452 Learning Late: 0.3989
Epoch 72: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 0.6986 Validation Loss : 0.6681 Learning Late: 0.3740
Epoch 73: 100%|██████████| 98/98 [00:34<00:00,  2.83batch/s]
Avg Loss : 0.6218 Validation Loss : 0.5796 Learning Late: 0.3498
Epoch 74: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 0.6067 Validation Loss : 0.6697 Learning Late: 0.3261
Epoch 75: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 0.6027 Validation Loss : 0.7459 Learning Late: 0.3031
Epoch 76: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 0.6225 Validation Loss : 0.6858 Learning Late: 0.2808
Epoch 77: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 0.6247 Validation Loss : 0.6902 Learning Late: 0.2591
Epoch 78: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 0.5996 Validation Loss : 0.5130 Learning Late: 0.2381
Epoch 79: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 0.6459 Validation Loss : 0.5533 Learning Late: 0.2179
Epoch 80: 100%|██████████| 98/98 [00:34<00:00,  2.83batch/s]
Avg Loss : 0.5928 Validation Loss : 0.5655 Learning Late: 0.1985
Epoch 81: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 0.5628 Validation Loss : 0.5891 Learning Late: 0.1799
Epoch 82: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 0.5879 Validation Loss : 0.5814 Learning Late: 0.1621
Epoch 83: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 0.6168 Validation Loss : 0.6112 Learning Late: 0.1451
Epoch 84: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 0.6200 Validation Loss : 0.6233 Learning Late: 0.1289
Epoch 85: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 0.5887 Validation Loss : 0.5914 Learning Late: 0.1137
Epoch 86: 100%|██████████| 98/98 [00:34<00:00,  2.83batch/s]
Avg Loss : 0.5972 Validation Loss : 0.5119 Learning Late: 0.0993
Epoch 87: 100%|██████████| 98/98 [00:34<00:00,  2.81batch/s]
Avg Loss : 0.5768 Validation Loss : 0.5893 Learning Late: 0.0859
Epoch 88: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 0.5444 Validation Loss : 0.5008 Learning Late: 0.0734
Epoch 89: 100%|██████████| 98/98 [00:34<00:00,  2.83batch/s]
Avg Loss : 0.6347 Validation Loss : 0.6855 Learning Late: 0.0618
Epoch 90: 100%|██████████| 98/98 [00:34<00:00,  2.83batch/s]
Avg Loss : 0.5846 Validation Loss : 0.5889 Learning Late: 0.0512
Epoch 91: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 0.6490 Validation Loss : 0.6229 Learning Late: 0.0415
Epoch 92: 100%|██████████| 98/98 [00:34<00:00,  2.83batch/s]
Avg Loss : 0.5526 Validation Loss : 0.5888 Learning Late: 0.0329
Epoch 93: 100%|██████████| 98/98 [00:34<00:00,  2.83batch/s]
Avg Loss : 0.6044 Validation Loss : 0.7376 Learning Late: 0.0252
Epoch 94: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 0.5737 Validation Loss : 0.4692 Learning Late: 0.0185
Epoch 95: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 0.5787 Validation Loss : 0.5981 Learning Late: 0.0129
Epoch 96: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 0.5806 Validation Loss : 0.6728 Learning Late: 0.0083
Epoch 97: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 0.5362 Validation Loss : 0.5210 Learning Late: 0.0046
Epoch 98: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 0.5357 Validation Loss : 0.6210 Learning Late: 0.0021
Epoch 99: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 0.5579 Validation Loss : 0.5785 Learning Late: 0.0005
Epoch 100: 100%|██████████| 98/98 [00:34<00:00,  2.84batch/s]
Avg Loss : 0.5681 Validation Loss : 0.5682 Learning Late: 0.0000
FG 학습 완료. 이제 F의 output을 실제 dataset의 label과 연결.
Files already downloaded and verified
Files already downloaded and verified
Epoch 1: 100%|██████████| 391/391 [00:06<00:00, 60.19batch/s]
Avg Loss : 1.4927 Validation Loss : 1.3809 Learning Late: 0.0010
Epoch 2: 100%|██████████| 391/391 [00:06<00:00, 61.59batch/s]
Avg Loss : 1.3417 Validation Loss : 1.3431 Learning Late: 0.0010
Epoch 3: 100%|██████████| 391/391 [00:06<00:00, 61.38batch/s]
Avg Loss : 1.3009 Validation Loss : 1.3113 Learning Late: 0.0010
Epoch 4: 100%|██████████| 391/391 [00:06<00:00, 61.95batch/s]
Avg Loss : 1.2746 Validation Loss : 1.2760 Learning Late: 0.0010
Epoch 5: 100%|██████████| 391/391 [00:06<00:00, 61.45batch/s]
Avg Loss : 1.2530 Validation Loss : 1.2843 Learning Late: 0.0010
Epoch 6: 100%|██████████| 391/391 [00:06<00:00, 61.73batch/s]
Avg Loss : 1.2396 Validation Loss : 1.2534 Learning Late: 0.0010
Epoch 7: 100%|██████████| 391/391 [00:06<00:00, 61.64batch/s]
Avg Loss : 1.2243 Validation Loss : 1.2511 Learning Late: 0.0010
Epoch 8: 100%|██████████| 391/391 [00:06<00:00, 61.40batch/s]
Avg Loss : 1.2152 Validation Loss : 1.2362 Learning Late: 0.0010
Epoch 9: 100%|██████████| 391/391 [00:06<00:00, 61.49batch/s]
Avg Loss : 1.2096 Validation Loss : 1.2370 Learning Late: 0.0010
Epoch 10: 100%|██████████| 391/391 [00:06<00:00, 60.76batch/s]
Avg Loss : 1.1987 Validation Loss : 1.2263 Learning Late: 0.0010
Epoch 11: 100%|██████████| 391/391 [00:06<00:00, 61.79batch/s]
Avg Loss : 1.1926 Validation Loss : 1.2213 Learning Late: 0.0010
Epoch 12: 100%|██████████| 391/391 [00:06<00:00, 61.58batch/s]
Avg Loss : 1.1838 Validation Loss : 1.2188 Learning Late: 0.0010
Epoch 13: 100%|██████████| 391/391 [00:06<00:00, 62.31batch/s]
Avg Loss : 1.1797 Validation Loss : 1.2208 Learning Late: 0.0010
Epoch 14: 100%|██████████| 391/391 [00:06<00:00, 63.16batch/s]
Avg Loss : 1.1731 Validation Loss : 1.1919 Learning Late: 0.0010
Epoch 15: 100%|██████████| 391/391 [00:06<00:00, 61.08batch/s]
Avg Loss : 1.1700 Validation Loss : 1.2052 Learning Late: 0.0010
Epoch 16: 100%|██████████| 391/391 [00:06<00:00, 61.50batch/s]
Avg Loss : 1.1659 Validation Loss : 1.2009 Learning Late: 0.0010
Epoch 17: 100%|██████████| 391/391 [00:06<00:00, 61.05batch/s]
Avg Loss : 1.1625 Validation Loss : 1.1928 Learning Late: 0.0010
Epoch 18: 100%|██████████| 391/391 [00:06<00:00, 61.16batch/s]
Avg Loss : 1.1594 Validation Loss : 1.1887 Learning Late: 0.0010
Epoch 19: 100%|██████████| 391/391 [00:06<00:00, 61.30batch/s]
Avg Loss : 1.1570 Validation Loss : 1.1915 Learning Late: 0.0010
Epoch 20: 100%|██████████| 391/391 [00:06<00:00, 61.21batch/s]
Avg Loss : 1.1538 Validation Loss : 1.1817 Learning Late: 0.0010
Epoch 21: 100%|██████████| 391/391 [00:06<00:00, 61.57batch/s]
Avg Loss : 1.1489 Validation Loss : 1.1833 Learning Late: 0.0010
Epoch 22: 100%|██████████| 391/391 [00:06<00:00, 61.10batch/s]
Avg Loss : 1.1446 Validation Loss : 1.1825 Learning Late: 0.0010
Epoch 23: 100%|██████████| 391/391 [00:06<00:00, 61.67batch/s]
Avg Loss : 1.1433 Validation Loss : 1.1946 Learning Late: 0.0010
Epoch 24: 100%|██████████| 391/391 [00:06<00:00, 61.71batch/s]
Avg Loss : 1.1408 Validation Loss : 1.1876 Learning Late: 0.0010
Epoch 25: 100%|██████████| 391/391 [00:06<00:00, 61.26batch/s]
Avg Loss : 1.1397 Validation Loss : 1.1775 Learning Late: 0.0010
Epoch 26: 100%|██████████| 391/391 [00:06<00:00, 61.21batch/s]
Avg Loss : 1.1371 Validation Loss : 1.1921 Learning Late: 0.0010
Epoch 27: 100%|██████████| 391/391 [00:06<00:00, 60.66batch/s]
Avg Loss : 1.1357 Validation Loss : 1.1842 Learning Late: 0.0010
Epoch 28: 100%|██████████| 391/391 [00:06<00:00, 61.37batch/s]
Avg Loss : 1.1341 Validation Loss : 1.1810 Learning Late: 0.0010
Epoch 29: 100%|██████████| 391/391 [00:06<00:00, 62.89batch/s]
Avg Loss : 1.1303 Validation Loss : 1.1699 Learning Late: 0.0010
Epoch 30: 100%|██████████| 391/391 [00:06<00:00, 61.92batch/s]
Avg Loss : 1.1294 Validation Loss : 1.1733 Learning Late: 0.0010
Epoch 31: 100%|██████████| 391/391 [00:06<00:00, 61.67batch/s]
Avg Loss : 1.1281 Validation Loss : 1.1682 Learning Late: 0.0010
Epoch 32: 100%|██████████| 391/391 [00:06<00:00, 61.03batch/s]
Avg Loss : 1.1267 Validation Loss : 1.1629 Learning Late: 0.0010
Epoch 33: 100%|██████████| 391/391 [00:06<00:00, 61.26batch/s]
Avg Loss : 1.1261 Validation Loss : 1.1620 Learning Late: 0.0010
Epoch 34: 100%|██████████| 391/391 [00:06<00:00, 61.18batch/s]
Avg Loss : 1.1221 Validation Loss : 1.1619 Learning Late: 0.0010
Epoch 35: 100%|██████████| 391/391 [00:06<00:00, 60.71batch/s]
Avg Loss : 1.1213 Validation Loss : 1.1701 Learning Late: 0.0010
Epoch 36: 100%|██████████| 391/391 [00:06<00:00, 61.37batch/s]
Avg Loss : 1.1215 Validation Loss : 1.1605 Learning Late: 0.0010
Epoch 37: 100%|██████████| 391/391 [00:06<00:00, 61.23batch/s]
Avg Loss : 1.1188 Validation Loss : 1.1642 Learning Late: 0.0010
Epoch 38: 100%|██████████| 391/391 [00:06<00:00, 61.07batch/s]
Avg Loss : 1.1192 Validation Loss : 1.1740 Learning Late: 0.0009
Epoch 39: 100%|██████████| 391/391 [00:06<00:00, 61.49batch/s]
Avg Loss : 1.1166 Validation Loss : 1.1626 Learning Late: 0.0009
Epoch 40: 100%|██████████| 391/391 [00:06<00:00, 61.27batch/s]
Avg Loss : 1.1147 Validation Loss : 1.1794 Learning Late: 0.0009
Epoch 41: 100%|██████████| 391/391 [00:06<00:00, 61.73batch/s]
Avg Loss : 1.1131 Validation Loss : 1.1640 Learning Late: 0.0009
Epoch 42: 100%|██████████| 391/391 [00:06<00:00, 60.64batch/s]
Avg Loss : 1.1132 Validation Loss : 1.1578 Learning Late: 0.0009
Epoch 43: 100%|██████████| 391/391 [00:06<00:00, 61.83batch/s]
Avg Loss : 1.1144 Validation Loss : 1.1574 Learning Late: 0.0009
Epoch 44: 100%|██████████| 391/391 [00:06<00:00, 61.84batch/s]
Avg Loss : 1.1102 Validation Loss : 1.1761 Learning Late: 0.0009
Epoch 45: 100%|██████████| 391/391 [00:06<00:00, 62.86batch/s]
Avg Loss : 1.1083 Validation Loss : 1.1778 Learning Late: 0.0009
Epoch 46: 100%|██████████| 391/391 [00:06<00:00, 61.45batch/s]
Avg Loss : 1.1099 Validation Loss : 1.1750 Learning Late: 0.0009
Epoch 47: 100%|██████████| 391/391 [00:06<00:00, 61.21batch/s]
Avg Loss : 1.1083 Validation Loss : 1.1655 Learning Late: 0.0009
Epoch 48: 100%|██████████| 391/391 [00:06<00:00, 61.79batch/s]
Avg Loss : 1.1077 Validation Loss : 1.1592 Learning Late: 0.0009
Epoch 49: 100%|██████████| 391/391 [00:06<00:00, 61.14batch/s]
Avg Loss : 1.1058 Validation Loss : 1.1604 Learning Late: 0.0009
Epoch 50: 100%|██████████| 391/391 [00:06<00:00, 61.06batch/s]
Avg Loss : 1.1048 Validation Loss : 1.1640 Learning Late: 0.0009
Epoch 51: 100%|██████████| 391/391 [00:06<00:00, 61.32batch/s]
Avg Loss : 1.1046 Validation Loss : 1.1606 Learning Late: 0.0009
Epoch 52: 100%|██████████| 391/391 [00:06<00:00, 61.11batch/s]
Avg Loss : 1.1028 Validation Loss : 1.1592 Learning Late: 0.0009
Epoch 53: 100%|██████████| 391/391 [00:06<00:00, 61.87batch/s]
Avg Loss : 1.1024 Validation Loss : 1.1612 Learning Late: 0.0009
Epoch 54: 100%|██████████| 391/391 [00:06<00:00, 61.55batch/s]
Avg Loss : 1.1024 Validation Loss : 1.1588 Learning Late: 0.0009
Epoch 55: 100%|██████████| 391/391 [00:06<00:00, 61.28batch/s]
Avg Loss : 1.1007 Validation Loss : 1.1520 Learning Late: 0.0009
Epoch 56: 100%|██████████| 391/391 [00:06<00:00, 61.71batch/s]
Avg Loss : 1.0989 Validation Loss : 1.1492 Learning Late: 0.0009
Epoch 57: 100%|██████████| 391/391 [00:06<00:00, 61.06batch/s]
Avg Loss : 1.0999 Validation Loss : 1.1590 Learning Late: 0.0009
Epoch 58: 100%|██████████| 391/391 [00:06<00:00, 60.63batch/s]
Avg Loss : 1.0985 Validation Loss : 1.1597 Learning Late: 0.0009
Epoch 59: 100%|██████████| 391/391 [00:06<00:00, 60.71batch/s]
Avg Loss : 1.0998 Validation Loss : 1.1531 Learning Late: 0.0008
Epoch 60: 100%|██████████| 391/391 [00:06<00:00, 61.86batch/s]
Avg Loss : 1.0971 Validation Loss : 1.1647 Learning Late: 0.0008
Epoch 61: 100%|██████████| 391/391 [00:06<00:00, 62.16batch/s]
Avg Loss : 1.0961 Validation Loss : 1.1538 Learning Late: 0.0008
Epoch 62: 100%|██████████| 391/391 [00:06<00:00, 61.21batch/s]
Avg Loss : 1.0977 Validation Loss : 1.1648 Learning Late: 0.0008
Epoch 63: 100%|██████████| 391/391 [00:06<00:00, 61.48batch/s]
Avg Loss : 1.0972 Validation Loss : 1.1591 Learning Late: 0.0008
Epoch 64: 100%|██████████| 391/391 [00:06<00:00, 61.39batch/s]
Avg Loss : 1.0945 Validation Loss : 1.1576 Learning Late: 0.0008
Epoch 65: 100%|██████████| 391/391 [00:06<00:00, 61.23batch/s]
Avg Loss : 1.0940 Validation Loss : 1.1548 Learning Late: 0.0008
Epoch 66: 100%|██████████| 391/391 [00:06<00:00, 61.51batch/s]
Avg Loss : 1.0948 Validation Loss : 1.1496 Learning Late: 0.0008
Epoch 67: 100%|██████████| 391/391 [00:06<00:00, 60.85batch/s]
Avg Loss : 1.0946 Validation Loss : 1.1587 Learning Late: 0.0008
Epoch 68: 100%|██████████| 391/391 [00:06<00:00, 61.76batch/s]
Avg Loss : 1.0909 Validation Loss : 1.1474 Learning Late: 0.0008
Epoch 69: 100%|██████████| 391/391 [00:06<00:00, 61.40batch/s]
Avg Loss : 1.0908 Validation Loss : 1.1654 Learning Late: 0.0008
Epoch 70: 100%|██████████| 391/391 [00:06<00:00, 61.22batch/s]
Avg Loss : 1.0902 Validation Loss : 1.1446 Learning Late: 0.0008
Epoch 71: 100%|██████████| 391/391 [00:06<00:00, 61.67batch/s]
Avg Loss : 1.0914 Validation Loss : 1.1664 Learning Late: 0.0008
Epoch 72: 100%|██████████| 391/391 [00:06<00:00, 61.02batch/s]
Avg Loss : 1.0909 Validation Loss : 1.1525 Learning Late: 0.0008
Epoch 73: 100%|██████████| 391/391 [00:06<00:00, 61.54batch/s]
Avg Loss : 1.0884 Validation Loss : 1.1547 Learning Late: 0.0008
Epoch 74: 100%|██████████| 391/391 [00:06<00:00, 60.50batch/s]
Avg Loss : 1.0898 Validation Loss : 1.1587 Learning Late: 0.0007
Epoch 75: 100%|██████████| 391/391 [00:06<00:00, 60.40batch/s]
Avg Loss : 1.0881 Validation Loss : 1.1507 Learning Late: 0.0007
Epoch 76: 100%|██████████| 391/391 [00:06<00:00, 62.34batch/s]
Avg Loss : 1.0874 Validation Loss : 1.1586 Learning Late: 0.0007
Epoch 77: 100%|██████████| 391/391 [00:06<00:00, 60.92batch/s]
Avg Loss : 1.0885 Validation Loss : 1.1460 Learning Late: 0.0007
Epoch 78: 100%|██████████| 391/391 [00:06<00:00, 61.45batch/s]
Avg Loss : 1.0866 Validation Loss : 1.1590 Learning Late: 0.0007
Epoch 79: 100%|██████████| 391/391 [00:06<00:00, 61.49batch/s]
Avg Loss : 1.0874 Validation Loss : 1.1622 Learning Late: 0.0007
Epoch 80: 100%|██████████| 391/391 [00:06<00:00, 61.28batch/s]
Avg Loss : 1.0865 Validation Loss : 1.1566 Learning Late: 0.0007
Epoch 81: 100%|██████████| 391/391 [00:06<00:00, 61.58batch/s]
Avg Loss : 1.0858 Validation Loss : 1.1580 Learning Late: 0.0007
Epoch 82: 100%|██████████| 391/391 [00:06<00:00, 60.75batch/s]
Avg Loss : 1.0837 Validation Loss : 1.1455 Learning Late: 0.0007
Epoch 83: 100%|██████████| 391/391 [00:06<00:00, 61.42batch/s]
Avg Loss : 1.0865 Validation Loss : 1.1461 Learning Late: 0.0007
Epoch 84: 100%|██████████| 391/391 [00:06<00:00, 61.25batch/s]
Avg Loss : 1.0830 Validation Loss : 1.1407 Learning Late: 0.0007
Epoch 85: 100%|██████████| 391/391 [00:06<00:00, 61.18batch/s]
Avg Loss : 1.0830 Validation Loss : 1.1550 Learning Late: 0.0007
Epoch 86: 100%|██████████| 391/391 [00:06<00:00, 61.12batch/s]
Avg Loss : 1.0818 Validation Loss : 1.1419 Learning Late: 0.0007
Epoch 87: 100%|██████████| 391/391 [00:06<00:00, 61.07batch/s]
Avg Loss : 1.0838 Validation Loss : 1.1384 Learning Late: 0.0006
Epoch 88: 100%|██████████| 391/391 [00:06<00:00, 61.46batch/s]
Avg Loss : 1.0819 Validation Loss : 1.1481 Learning Late: 0.0006
Epoch 89: 100%|██████████| 391/391 [00:06<00:00, 61.32batch/s]
Avg Loss : 1.0816 Validation Loss : 1.1451 Learning Late: 0.0006
Epoch 90: 100%|██████████| 391/391 [00:06<00:00, 60.69batch/s]
Avg Loss : 1.0817 Validation Loss : 1.1396 Learning Late: 0.0006
Epoch 91: 100%|██████████| 391/391 [00:06<00:00, 62.13batch/s]
Avg Loss : 1.0803 Validation Loss : 1.1469 Learning Late: 0.0006
Epoch 92: 100%|██████████| 391/391 [00:06<00:00, 61.93batch/s]
Avg Loss : 1.0803 Validation Loss : 1.1511 Learning Late: 0.0006
Epoch 93: 100%|██████████| 391/391 [00:06<00:00, 61.47batch/s]
Avg Loss : 1.0789 Validation Loss : 1.1465 Learning Late: 0.0006
Epoch 94: 100%|██████████| 391/391 [00:06<00:00, 61.08batch/s]
Avg Loss : 1.0809 Validation Loss : 1.1434 Learning Late: 0.0006
Epoch 95: 100%|██████████| 391/391 [00:06<00:00, 61.36batch/s]
Avg Loss : 1.0781 Validation Loss : 1.1403 Learning Late: 0.0006
Epoch 96: 100%|██████████| 391/391 [00:06<00:00, 61.31batch/s]
Avg Loss : 1.0777 Validation Loss : 1.1545 Learning Late: 0.0006
Epoch 97: 100%|██████████| 391/391 [00:06<00:00, 61.27batch/s]
Avg Loss : 1.0787 Validation Loss : 1.1426 Learning Late: 0.0006
Epoch 98: 100%|██████████| 391/391 [00:06<00:00, 61.03batch/s]
Avg Loss : 1.0780 Validation Loss : 1.1487 Learning Late: 0.0006
Epoch 99: 100%|██████████| 391/391 [00:06<00:00, 60.98batch/s]
Avg Loss : 1.0781 Validation Loss : 1.1438 Learning Late: 0.0005
Epoch 100: 100%|██████████| 391/391 [00:06<00:00, 61.29batch/s]
Avg Loss : 1.0766 Validation Loss : 1.1400 Learning Late: 0.0005
Epoch 101: 100%|██████████| 391/391 [00:06<00:00, 61.57batch/s]
Avg Loss : 1.0764 Validation Loss : 1.1427 Learning Late: 0.0005
Epoch 102: 100%|██████████| 391/391 [00:06<00:00, 60.69batch/s]
Avg Loss : 1.0773 Validation Loss : 1.1352 Learning Late: 0.0005
Epoch 103: 100%|██████████| 391/391 [00:06<00:00, 61.24batch/s]
Avg Loss : 1.0755 Validation Loss : 1.1449 Learning Late: 0.0005
Epoch 104: 100%|██████████| 391/391 [00:06<00:00, 61.19batch/s]
Avg Loss : 1.0753 Validation Loss : 1.1424 Learning Late: 0.0005
Epoch 105: 100%|██████████| 391/391 [00:06<00:00, 61.14batch/s]
Avg Loss : 1.0765 Validation Loss : 1.1470 Learning Late: 0.0005
Epoch 106: 100%|██████████| 391/391 [00:06<00:00, 61.33batch/s]
Avg Loss : 1.0750 Validation Loss : 1.1393 Learning Late: 0.0005
Epoch 107: 100%|██████████| 391/391 [00:06<00:00, 62.48batch/s]
Avg Loss : 1.0739 Validation Loss : 1.1511 Learning Late: 0.0005
Epoch 108: 100%|██████████| 391/391 [00:06<00:00, 62.58batch/s]
Avg Loss : 1.0743 Validation Loss : 1.1528 Learning Late: 0.0005
Epoch 109: 100%|██████████| 391/391 [00:06<00:00, 61.16batch/s]
Avg Loss : 1.0740 Validation Loss : 1.1403 Learning Late: 0.0005
Epoch 110: 100%|██████████| 391/391 [00:06<00:00, 61.67batch/s]
Avg Loss : 1.0732 Validation Loss : 1.1475 Learning Late: 0.0005
Epoch 111: 100%|██████████| 391/391 [00:06<00:00, 61.34batch/s]
Avg Loss : 1.0727 Validation Loss : 1.1384 Learning Late: 0.0005
Epoch 112: 100%|██████████| 391/391 [00:06<00:00, 61.39batch/s]
Avg Loss : 1.0717 Validation Loss : 1.1450 Learning Late: 0.0004
Epoch 113: 100%|██████████| 391/391 [00:06<00:00, 61.30batch/s]
Avg Loss : 1.0716 Validation Loss : 1.1375 Learning Late: 0.0004
Epoch 114: 100%|██████████| 391/391 [00:06<00:00, 60.72batch/s]
Avg Loss : 1.0714 Validation Loss : 1.1433 Learning Late: 0.0004
Epoch 115: 100%|██████████| 391/391 [00:06<00:00, 61.32batch/s]
Avg Loss : 1.0723 Validation Loss : 1.1509 Learning Late: 0.0004
Epoch 116: 100%|██████████| 391/391 [00:06<00:00, 61.52batch/s]
Avg Loss : 1.0701 Validation Loss : 1.1409 Learning Late: 0.0004
Epoch 117: 100%|██████████| 391/391 [00:06<00:00, 61.03batch/s]
Avg Loss : 1.0701 Validation Loss : 1.1395 Learning Late: 0.0004
Epoch 118: 100%|██████████| 391/391 [00:06<00:00, 61.82batch/s]
Avg Loss : 1.0705 Validation Loss : 1.1389 Learning Late: 0.0004
Epoch 119: 100%|██████████| 391/391 [00:06<00:00, 61.24batch/s]
Avg Loss : 1.0690 Validation Loss : 1.1474 Learning Late: 0.0004
Epoch 120: 100%|██████████| 391/391 [00:06<00:00, 61.51batch/s]
Avg Loss : 1.0701 Validation Loss : 1.1405 Learning Late: 0.0004
Epoch 121: 100%|██████████| 391/391 [00:06<00:00, 61.37batch/s]
Avg Loss : 1.0699 Validation Loss : 1.1360 Learning Late: 0.0004
Epoch 122: 100%|██████████| 391/391 [00:06<00:00, 61.48batch/s]
Avg Loss : 1.0690 Validation Loss : 1.1392 Learning Late: 0.0004
Epoch 123: 100%|██████████| 391/391 [00:06<00:00, 62.92batch/s]
Avg Loss : 1.0688 Validation Loss : 1.1375 Learning Late: 0.0004
Epoch 124: 100%|██████████| 391/391 [00:06<00:00, 60.98batch/s]
Avg Loss : 1.0680 Validation Loss : 1.1361 Learning Late: 0.0003
Epoch 125: 100%|██████████| 391/391 [00:06<00:00, 61.42batch/s]
Avg Loss : 1.0682 Validation Loss : 1.1400 Learning Late: 0.0003
Epoch 126: 100%|██████████| 391/391 [00:06<00:00, 61.36batch/s]
Avg Loss : 1.0681 Validation Loss : 1.1370 Learning Late: 0.0003
Epoch 127: 100%|██████████| 391/391 [00:06<00:00, 61.25batch/s]
Avg Loss : 1.0675 Validation Loss : 1.1361 Learning Late: 0.0003
Epoch 128: 100%|██████████| 391/391 [00:06<00:00, 61.60batch/s]
Avg Loss : 1.0678 Validation Loss : 1.1354 Learning Late: 0.0003
Epoch 129: 100%|██████████| 391/391 [00:06<00:00, 61.28batch/s]
Avg Loss : 1.0670 Validation Loss : 1.1368 Learning Late: 0.0003
Epoch 130: 100%|██████████| 391/391 [00:06<00:00, 61.52batch/s]
Avg Loss : 1.0665 Validation Loss : 1.1419 Learning Late: 0.0003
Epoch 131: 100%|██████████| 391/391 [00:06<00:00, 61.24batch/s]
Avg Loss : 1.0662 Validation Loss : 1.1415 Learning Late: 0.0003
Epoch 132: 100%|██████████| 391/391 [00:06<00:00, 61.25batch/s]
Avg Loss : 1.0659 Validation Loss : 1.1418 Learning Late: 0.0003
Epoch 133: 100%|██████████| 391/391 [00:06<00:00, 61.51batch/s]
Avg Loss : 1.0657 Validation Loss : 1.1384 Learning Late: 0.0003
Epoch 134: 100%|██████████| 391/391 [00:06<00:00, 61.28batch/s]
Avg Loss : 1.0655 Validation Loss : 1.1367 Learning Late: 0.0003
Epoch 135: 100%|██████████| 391/391 [00:06<00:00, 61.43batch/s]
Avg Loss : 1.0658 Validation Loss : 1.1401 Learning Late: 0.0003
Epoch 136: 100%|██████████| 391/391 [00:06<00:00, 61.16batch/s]
Avg Loss : 1.0644 Validation Loss : 1.1343 Learning Late: 0.0003
Epoch 137: 100%|██████████| 391/391 [00:06<00:00, 61.10batch/s]
Avg Loss : 1.0650 Validation Loss : 1.1331 Learning Late: 0.0002
Epoch 138: 100%|██████████| 391/391 [00:06<00:00, 62.21batch/s]
Avg Loss : 1.0641 Validation Loss : 1.1342 Learning Late: 0.0002
Epoch 139: 100%|██████████| 391/391 [00:06<00:00, 62.24batch/s]
Avg Loss : 1.0645 Validation Loss : 1.1311 Learning Late: 0.0002
Epoch 140: 100%|██████████| 391/391 [00:06<00:00, 61.64batch/s]
Avg Loss : 1.0643 Validation Loss : 1.1333 Learning Late: 0.0002
Epoch 141: 100%|██████████| 391/391 [00:06<00:00, 61.00batch/s]
Avg Loss : 1.0631 Validation Loss : 1.1384 Learning Late: 0.0002
Epoch 142: 100%|██████████| 391/391 [00:06<00:00, 61.33batch/s]
Avg Loss : 1.0634 Validation Loss : 1.1368 Learning Late: 0.0002
Epoch 143: 100%|██████████| 391/391 [00:06<00:00, 61.69batch/s]
Avg Loss : 1.0629 Validation Loss : 1.1347 Learning Late: 0.0002
Epoch 144: 100%|██████████| 391/391 [00:06<00:00, 60.99batch/s]
Avg Loss : 1.0630 Validation Loss : 1.1386 Learning Late: 0.0002
Epoch 145: 100%|██████████| 391/391 [00:06<00:00, 61.60batch/s]
Avg Loss : 1.0623 Validation Loss : 1.1435 Learning Late: 0.0002
Epoch 146: 100%|██████████| 391/391 [00:06<00:00, 61.38batch/s]
Avg Loss : 1.0623 Validation Loss : 1.1304 Learning Late: 0.0002
Epoch 147: 100%|██████████| 391/391 [00:06<00:00, 61.53batch/s]
Avg Loss : 1.0619 Validation Loss : 1.1335 Learning Late: 0.0002
Epoch 148: 100%|██████████| 391/391 [00:06<00:00, 61.63batch/s]
Avg Loss : 1.0619 Validation Loss : 1.1306 Learning Late: 0.0002
Epoch 149: 100%|██████████| 391/391 [00:06<00:00, 61.06batch/s]
Avg Loss : 1.0615 Validation Loss : 1.1348 Learning Late: 0.0002
Epoch 150: 100%|██████████| 391/391 [00:06<00:00, 61.72batch/s]
Avg Loss : 1.0618 Validation Loss : 1.1398 Learning Late: 0.0002
Epoch 151: 100%|██████████| 391/391 [00:06<00:00, 61.43batch/s]
Avg Loss : 1.0610 Validation Loss : 1.1334 Learning Late: 0.0002
Epoch 152: 100%|██████████| 391/391 [00:06<00:00, 61.15batch/s]
Avg Loss : 1.0613 Validation Loss : 1.1385 Learning Late: 0.0001
Epoch 153: 100%|██████████| 391/391 [00:06<00:00, 61.73batch/s]
Avg Loss : 1.0607 Validation Loss : 1.1312 Learning Late: 0.0001
Epoch 154: 100%|██████████| 391/391 [00:06<00:00, 62.49batch/s]
Avg Loss : 1.0606 Validation Loss : 1.1346 Learning Late: 0.0001
Epoch 155: 100%|██████████| 391/391 [00:06<00:00, 61.52batch/s]
Avg Loss : 1.0599 Validation Loss : 1.1342 Learning Late: 0.0001
Epoch 156: 100%|██████████| 391/391 [00:06<00:00, 60.99batch/s]
Avg Loss : 1.0600 Validation Loss : 1.1382 Learning Late: 0.0001
Epoch 157: 100%|██████████| 391/391 [00:06<00:00, 60.92batch/s]
Avg Loss : 1.0600 Validation Loss : 1.1332 Learning Late: 0.0001
Epoch 158: 100%|██████████| 391/391 [00:06<00:00, 61.51batch/s]
Avg Loss : 1.0594 Validation Loss : 1.1326 Learning Late: 0.0001
Epoch 159: 100%|██████████| 391/391 [00:06<00:00, 61.07batch/s]
Avg Loss : 1.0592 Validation Loss : 1.1327 Learning Late: 0.0001
Epoch 160: 100%|██████████| 391/391 [00:06<00:00, 61.57batch/s]
Avg Loss : 1.0598 Validation Loss : 1.1378 Learning Late: 0.0001
Epoch 161: 100%|██████████| 391/391 [00:06<00:00, 61.05batch/s]
Avg Loss : 1.0592 Validation Loss : 1.1314 Learning Late: 0.0001
Epoch 162: 100%|██████████| 391/391 [00:06<00:00, 61.14batch/s]
Avg Loss : 1.0589 Validation Loss : 1.1328 Learning Late: 0.0001
Epoch 163: 100%|██████████| 391/391 [00:06<00:00, 61.33batch/s]
Avg Loss : 1.0589 Validation Loss : 1.1352 Learning Late: 0.0001
Epoch 164: 100%|██████████| 391/391 [00:06<00:00, 61.12batch/s]
Avg Loss : 1.0590 Validation Loss : 1.1360 Learning Late: 0.0001
Epoch 165: 100%|██████████| 391/391 [00:06<00:00, 61.52batch/s]
Avg Loss : 1.0586 Validation Loss : 1.1374 Learning Late: 0.0001
Epoch 166: 100%|██████████| 391/391 [00:06<00:00, 61.15batch/s]
Avg Loss : 1.0583 Validation Loss : 1.1289 Learning Late: 0.0001
Epoch 167: 100%|██████████| 391/391 [00:06<00:00, 61.36batch/s]
Avg Loss : 1.0583 Validation Loss : 1.1344 Learning Late: 0.0001
Epoch 168: 100%|██████████| 391/391 [00:06<00:00, 61.71batch/s]
Avg Loss : 1.0579 Validation Loss : 1.1374 Learning Late: 0.0001
Epoch 169: 100%|██████████| 391/391 [00:06<00:00, 61.64batch/s]
Avg Loss : 1.0579 Validation Loss : 1.1331 Learning Late: 0.0001
Epoch 170: 100%|██████████| 391/391 [00:06<00:00, 62.99batch/s]
Avg Loss : 1.0577 Validation Loss : 1.1342 Learning Late: 0.0001
Epoch 171: 100%|██████████| 391/391 [00:06<00:00, 61.27batch/s]
Avg Loss : 1.0574 Validation Loss : 1.1344 Learning Late: 0.0001
Epoch 172: 100%|██████████| 391/391 [00:06<00:00, 61.29batch/s]
Avg Loss : 1.0576 Validation Loss : 1.1326 Learning Late: 0.0001
Epoch 173: 100%|██████████| 391/391 [00:06<00:00, 61.07batch/s]
Avg Loss : 1.0574 Validation Loss : 1.1293 Learning Late: 0.0000
Epoch 174: 100%|██████████| 391/391 [00:06<00:00, 60.96batch/s]
Avg Loss : 1.0573 Validation Loss : 1.1343 Learning Late: 0.0000
Epoch 175: 100%|██████████| 391/391 [00:06<00:00, 61.69batch/s]
Avg Loss : 1.0574 Validation Loss : 1.1399 Learning Late: 0.0000
Epoch 176: 100%|██████████| 391/391 [00:06<00:00, 61.36batch/s]
Avg Loss : 1.0572 Validation Loss : 1.1307 Learning Late: 0.0000
Epoch 177: 100%|██████████| 391/391 [00:06<00:00, 61.54batch/s]
Avg Loss : 1.0571 Validation Loss : 1.1362 Learning Late: 0.0000
Epoch 178: 100%|██████████| 391/391 [00:06<00:00, 61.19batch/s]
Avg Loss : 1.0568 Validation Loss : 1.1373 Learning Late: 0.0000
Epoch 179: 100%|██████████| 391/391 [00:06<00:00, 60.84batch/s]
Avg Loss : 1.0568 Validation Loss : 1.1322 Learning Late: 0.0000
Epoch 180: 100%|██████████| 391/391 [00:06<00:00, 61.47batch/s]
Avg Loss : 1.0566 Validation Loss : 1.1316 Learning Late: 0.0000
Epoch 181: 100%|██████████| 391/391 [00:06<00:00, 61.37batch/s]
Avg Loss : 1.0565 Validation Loss : 1.1325 Learning Late: 0.0000
Epoch 182: 100%|██████████| 391/391 [00:06<00:00, 61.66batch/s]
Avg Loss : 1.0563 Validation Loss : 1.1323 Learning Late: 0.0000
Epoch 183: 100%|██████████| 391/391 [00:06<00:00, 61.35batch/s]
Avg Loss : 1.0563 Validation Loss : 1.1367 Learning Late: 0.0000
Epoch 184: 100%|██████████| 391/391 [00:06<00:00, 61.29batch/s]
Avg Loss : 1.0562 Validation Loss : 1.1320 Learning Late: 0.0000
Epoch 185: 100%|██████████| 391/391 [00:06<00:00, 62.89batch/s]
Avg Loss : 1.0560 Validation Loss : 1.1335 Learning Late: 0.0000
Epoch 186: 100%|██████████| 391/391 [00:06<00:00, 61.57batch/s]
Avg Loss : 1.0561 Validation Loss : 1.1318 Learning Late: 0.0000
Epoch 187: 100%|██████████| 391/391 [00:06<00:00, 61.28batch/s]
Avg Loss : 1.0558 Validation Loss : 1.1375 Learning Late: 0.0000
Epoch 188: 100%|██████████| 391/391 [00:06<00:00, 61.52batch/s]
Avg Loss : 1.0559 Validation Loss : 1.1312 Learning Late: 0.0000
Epoch 189: 100%|██████████| 391/391 [00:06<00:00, 60.58batch/s]
Avg Loss : 1.0558 Validation Loss : 1.1290 Learning Late: 0.0000
Epoch 190: 100%|██████████| 391/391 [00:06<00:00, 61.10batch/s]
Avg Loss : 1.0557 Validation Loss : 1.1343 Learning Late: 0.0000
Epoch 191: 100%|██████████| 391/391 [00:06<00:00, 61.05batch/s]
Avg Loss : 1.0560 Validation Loss : 1.1373 Learning Late: 0.0000
Epoch 192: 100%|██████████| 391/391 [00:06<00:00, 61.32batch/s]
Avg Loss : 1.0557 Validation Loss : 1.1305 Learning Late: 0.0000
Epoch 193: 100%|██████████| 391/391 [00:06<00:00, 61.27batch/s]
Avg Loss : 1.0555 Validation Loss : 1.1297 Learning Late: 0.0000
Epoch 194: 100%|██████████| 391/391 [00:06<00:00, 61.24batch/s]
Avg Loss : 1.0555 Validation Loss : 1.1371 Learning Late: 0.0000
Epoch 195: 100%|██████████| 391/391 [00:06<00:00, 61.24batch/s]
Avg Loss : 1.0556 Validation Loss : 1.1333 Learning Late: 0.0000
Epoch 196: 100%|██████████| 391/391 [00:06<00:00, 61.18batch/s]
Avg Loss : 1.0555 Validation Loss : 1.1329 Learning Late: 0.0000
Epoch 197: 100%|██████████| 391/391 [00:06<00:00, 61.20batch/s]
Avg Loss : 1.0555 Validation Loss : 1.1315 Learning Late: 0.0000
Epoch 198: 100%|██████████| 391/391 [00:06<00:00, 61.38batch/s]
Avg Loss : 1.0554 Validation Loss : 1.1313 Learning Late: 0.0000
Epoch 199: 100%|██████████| 391/391 [00:06<00:00, 61.05batch/s]
Avg Loss : 1.0554 Validation Loss : 1.1291 Learning Late: 0.0000
Epoch 200: 100%|██████████| 391/391 [00:06<00:00, 62.53batch/s]
Avg Loss : 1.0555 Validation Loss : 1.1344 Learning Late: 0.0000

실제 test
100%|██████████| 79/79 [00:01<00:00, 64.11batch/s]총 개수 : 10000
top-1 맞춘 개수 : 5944
 정확도: 59.44
top-5 맞춘 개수 : 9586
 정확도: 95.86
