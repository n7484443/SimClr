Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz
100%|██████████| 170498071/170498071 [00:02<00:00, 82620442.14it/s]
Extracting ./data/cifar-10-python.tar.gz to ./data
Files already downloaded and verified
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Epoch 1: 100%|██████████| 196/196 [01:38<00:00,  1.98batch/s]
Avg Loss : 5.3920 Validation Loss : 4.8761 Learning Late: 1.2000
Epoch 2: 100%|██████████| 196/196 [01:41<00:00,  1.93batch/s]
Avg Loss : 4.7856 Validation Loss : 4.8537 Learning Late: 1.2000
Epoch 3: 100%|██████████| 196/196 [01:41<00:00,  1.93batch/s]
Avg Loss : 4.7378 Validation Loss : 4.8649 Learning Late: 1.2000
Epoch 4: 100%|██████████| 196/196 [01:41<00:00,  1.93batch/s]
Avg Loss : 4.5034 Validation Loss : 4.2254 Learning Late: 1.2000
Epoch 5: 100%|██████████| 196/196 [01:41<00:00,  1.93batch/s]
Avg Loss : 3.9755 Validation Loss : 3.5771 Learning Late: 1.2000
Epoch 6: 100%|██████████| 196/196 [01:41<00:00,  1.92batch/s]
Avg Loss : 3.5209 Validation Loss : 3.6460 Learning Late: 1.2000
Epoch 7: 100%|██████████| 196/196 [01:41<00:00,  1.93batch/s]
Avg Loss : 3.2911 Validation Loss : 2.9152 Learning Late: 1.2000
Epoch 8: 100%|██████████| 196/196 [01:41<00:00,  1.93batch/s]
Avg Loss : 3.0621 Validation Loss : 2.9079 Learning Late: 1.2000
Epoch 9: 100%|██████████| 196/196 [01:41<00:00,  1.93batch/s]
Avg Loss : 2.9850 Validation Loss : 3.0815 Learning Late: 1.2000
Epoch 10: 100%|██████████| 196/196 [01:41<00:00,  1.92batch/s]
Avg Loss : 2.8658 Validation Loss : 2.4447 Learning Late: 1.2000
Epoch 11: 100%|██████████| 196/196 [01:41<00:00,  1.93batch/s]
Avg Loss : 2.4366 Validation Loss : 2.2077 Learning Late: 1.1996
Epoch 12: 100%|██████████| 196/196 [01:41<00:00,  1.92batch/s]
Avg Loss : 2.0869 Validation Loss : 1.8593 Learning Late: 1.1985
Epoch 13: 100%|██████████| 196/196 [01:41<00:00,  1.93batch/s]
Avg Loss : 2.0236 Validation Loss : 1.7869 Learning Late: 1.1967
Epoch 14: 100%|██████████| 196/196 [01:41<00:00,  1.93batch/s]
Avg Loss : 1.7305 Validation Loss : 1.5259 Learning Late: 1.1942
Epoch 15: 100%|██████████| 196/196 [01:41<00:00,  1.92batch/s]
Avg Loss : 1.4996 Validation Loss : 1.2093 Learning Late: 1.1909
Epoch 16: 100%|██████████| 196/196 [01:41<00:00,  1.93batch/s]
Avg Loss : 1.3218 Validation Loss : 1.1570 Learning Late: 1.1869
Epoch 17: 100%|██████████| 196/196 [01:41<00:00,  1.93batch/s]
Avg Loss : 1.1685 Validation Loss : 1.3282 Learning Late: 1.1822
Epoch 18: 100%|██████████| 196/196 [01:41<00:00,  1.93batch/s]
Avg Loss : 0.9957 Validation Loss : 0.9077 Learning Late: 1.1768
Epoch 19: 100%|██████████| 196/196 [01:41<00:00,  1.93batch/s]
Avg Loss : 1.0154 Validation Loss : 0.9091 Learning Late: 1.1706
Epoch 20: 100%|██████████| 196/196 [01:41<00:00,  1.93batch/s]
Avg Loss : 0.8578 Validation Loss : 0.7882 Learning Late: 1.1638
Epoch 21: 100%|██████████| 196/196 [01:41<00:00,  1.93batch/s]
Avg Loss : 0.8247 Validation Loss : 0.7899 Learning Late: 1.1563
Epoch 22: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.8128 Validation Loss : 0.6585 Learning Late: 1.1481
Epoch 23: 100%|██████████| 196/196 [01:41<00:00,  1.92batch/s]
Avg Loss : 0.6772 Validation Loss : 0.6651 Learning Late: 1.1393
Epoch 24: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.7029 Validation Loss : 0.5134 Learning Late: 1.1298
Epoch 25: 100%|██████████| 196/196 [01:41<00:00,  1.92batch/s]
Avg Loss : 0.7872 Validation Loss : 0.6305 Learning Late: 1.1196
Epoch 26: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.5736 Validation Loss : 0.6532 Learning Late: 1.1088
Epoch 27: 100%|██████████| 196/196 [01:41<00:00,  1.93batch/s]
Avg Loss : 0.5355 Validation Loss : 0.5187 Learning Late: 1.0974
Epoch 28: 100%|██████████| 196/196 [01:41<00:00,  1.93batch/s]
Avg Loss : 0.5237 Validation Loss : 0.5480 Learning Late: 1.0854
Epoch 29: 100%|██████████| 196/196 [01:41<00:00,  1.93batch/s]
Avg Loss : 0.4739 Validation Loss : 0.4263 Learning Late: 1.0728
Epoch 30: 100%|██████████| 196/196 [01:41<00:00,  1.92batch/s]
Avg Loss : 0.4700 Validation Loss : 0.4017 Learning Late: 1.0596
Epoch 31: 100%|██████████| 196/196 [01:41<00:00,  1.93batch/s]
Avg Loss : 0.5674 Validation Loss : 0.4700 Learning Late: 1.0459
Epoch 32: 100%|██████████| 196/196 [01:41<00:00,  1.93batch/s]
Avg Loss : 0.4828 Validation Loss : 0.4714 Learning Late: 1.0316
Epoch 33: 100%|██████████| 196/196 [01:41<00:00,  1.93batch/s]
Avg Loss : 0.4419 Validation Loss : 0.3820 Learning Late: 1.0168
Epoch 34: 100%|██████████| 196/196 [01:41<00:00,  1.92batch/s]
Avg Loss : 0.4042 Validation Loss : 0.3808 Learning Late: 1.0015
Epoch 35: 100%|██████████| 196/196 [01:41<00:00,  1.93batch/s]
Avg Loss : 0.4330 Validation Loss : 0.5043 Learning Late: 0.9857
Epoch 36: 100%|██████████| 196/196 [01:41<00:00,  1.92batch/s]
Avg Loss : 0.4011 Validation Loss : 0.4021 Learning Late: 0.9694
Epoch 37: 100%|██████████| 196/196 [01:41<00:00,  1.92batch/s]
Avg Loss : 0.3634 Validation Loss : 0.4608 Learning Late: 0.9527
Epoch 38: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.3723 Validation Loss : 0.3632 Learning Late: 0.9355
Epoch 39: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.3833 Validation Loss : 0.3961 Learning Late: 0.9180
Epoch 40: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.3903 Validation Loss : 0.3382 Learning Late: 0.9000
Epoch 41: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.3735 Validation Loss : 0.3670 Learning Late: 0.8817
Epoch 42: 100%|██████████| 196/196 [01:41<00:00,  1.92batch/s]
Avg Loss : 0.3240 Validation Loss : 0.3210 Learning Late: 0.8630
Epoch 43: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.3650 Validation Loss : 0.3108 Learning Late: 0.8440
Epoch 44: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.3002 Validation Loss : 0.2881 Learning Late: 0.8248
Epoch 45: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.3156 Validation Loss : 0.4012 Learning Late: 0.8052
Epoch 46: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.3067 Validation Loss : 0.3119 Learning Late: 0.7854
Epoch 47: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.2786 Validation Loss : 0.3572 Learning Late: 0.7654
Epoch 48: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.3226 Validation Loss : 0.2790 Learning Late: 0.7452
Epoch 49: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.2753 Validation Loss : 0.3398 Learning Late: 0.7247
Epoch 50: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.2538 Validation Loss : 0.2839 Learning Late: 0.7042
Epoch 51: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.2875 Validation Loss : 0.3017 Learning Late: 0.6835
Epoch 52: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.2748 Validation Loss : 0.3295 Learning Late: 0.6627
Epoch 53: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.2947 Validation Loss : 0.2426 Learning Late: 0.6419
Epoch 54: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.2783 Validation Loss : 0.3048 Learning Late: 0.6209
Epoch 55: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.2509 Validation Loss : 0.2261 Learning Late: 0.6000
Epoch 56: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.2638 Validation Loss : 0.2753 Learning Late: 0.5791
Epoch 57: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.2396 Validation Loss : 0.2862 Learning Late: 0.5581
Epoch 58: 100%|██████████| 196/196 [01:42<00:00,  1.91batch/s]
Avg Loss : 0.2579 Validation Loss : 0.3069 Learning Late: 0.5373
Epoch 59: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.2385 Validation Loss : 0.2812 Learning Late: 0.5165
Epoch 60: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.2647 Validation Loss : 0.2214 Learning Late: 0.4958
Epoch 61: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.2474 Validation Loss : 0.2816 Learning Late: 0.4753
Epoch 62: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.2401 Validation Loss : 0.1777 Learning Late: 0.4548
Epoch 63: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.2582 Validation Loss : 0.2907 Learning Late: 0.4346
Epoch 64: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.2393 Validation Loss : 0.2123 Learning Late: 0.4146
Epoch 65: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.2545 Validation Loss : 0.2357 Learning Late: 0.3948
Epoch 66: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.2372 Validation Loss : 0.2463 Learning Late: 0.3752
Epoch 67: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.2287 Validation Loss : 0.2089 Learning Late: 0.3560
Epoch 68: 100%|██████████| 196/196 [01:42<00:00,  1.91batch/s]
Avg Loss : 0.2358 Validation Loss : 0.2041 Learning Late: 0.3370
Epoch 69: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.2353 Validation Loss : 0.1870 Learning Late: 0.3183
Epoch 70: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.2219 Validation Loss : 0.1860 Learning Late: 0.3000
Epoch 71: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.2192 Validation Loss : 0.2719 Learning Late: 0.2820
Epoch 72: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.2293 Validation Loss : 0.2469 Learning Late: 0.2645
Epoch 73: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.2329 Validation Loss : 0.1689 Learning Late: 0.2473
Epoch 74: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.2307 Validation Loss : 0.2191 Learning Late: 0.2306
Epoch 75: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.1973 Validation Loss : 0.2047 Learning Late: 0.2143
Epoch 76: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.2209 Validation Loss : 0.2694 Learning Late: 0.1985
Epoch 77: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.2127 Validation Loss : 0.1782 Learning Late: 0.1832
Epoch 78: 100%|██████████| 196/196 [01:42<00:00,  1.91batch/s]
Avg Loss : 0.2036 Validation Loss : 0.1566 Learning Late: 0.1684
Epoch 79: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.2139 Validation Loss : 0.2080 Learning Late: 0.1541
Epoch 80: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.2213 Validation Loss : 0.2028 Learning Late: 0.1404
Epoch 81: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.2096 Validation Loss : 0.1687 Learning Late: 0.1272
Epoch 82: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.2123 Validation Loss : 0.2344 Learning Late: 0.1146
Epoch 83: 100%|██████████| 196/196 [01:42<00:00,  1.91batch/s]
Avg Loss : 0.2234 Validation Loss : 0.2181 Learning Late: 0.1026
Epoch 84: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.1878 Validation Loss : 0.1926 Learning Late: 0.0912
Epoch 85: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.2261 Validation Loss : 0.2570 Learning Late: 0.0804
Epoch 86: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.1941 Validation Loss : 0.1948 Learning Late: 0.0702
Epoch 87: 100%|██████████| 196/196 [01:42<00:00,  1.91batch/s]
Avg Loss : 0.2136 Validation Loss : 0.2267 Learning Late: 0.0607
Epoch 88: 100%|██████████| 196/196 [01:42<00:00,  1.91batch/s]
Avg Loss : 0.1997 Validation Loss : 0.1717 Learning Late: 0.0519
Epoch 89: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.2057 Validation Loss : 0.2198 Learning Late: 0.0437
Epoch 90: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.1980 Validation Loss : 0.2027 Learning Late: 0.0362
Epoch 91: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.2104 Validation Loss : 0.1833 Learning Late: 0.0294
Epoch 92: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.2087 Validation Loss : 0.2356 Learning Late: 0.0232
Epoch 93: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.2051 Validation Loss : 0.2315 Learning Late: 0.0178
Epoch 94: 100%|██████████| 196/196 [01:42<00:00,  1.91batch/s]
Avg Loss : 0.2106 Validation Loss : 0.2285 Learning Late: 0.0131
Epoch 95: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.1935 Validation Loss : 0.2133 Learning Late: 0.0091
Epoch 96: 100%|██████████| 196/196 [01:42<00:00,  1.92batch/s]
Avg Loss : 0.1957 Validation Loss : 0.2076 Learning Late: 0.0058
Epoch 97: 100%|██████████| 196/196 [01:42<00:00,  1.91batch/s]
Avg Loss : 0.2175 Validation Loss : 0.2634 Learning Late: 0.0033
Epoch 98: 100%|██████████| 196/196 [01:42<00:00,  1.91batch/s]
Avg Loss : 0.2104 Validation Loss : 0.1736 Learning Late: 0.0015
Epoch 99: 100%|██████████| 196/196 [01:42<00:00,  1.91batch/s]
Avg Loss : 0.2111 Validation Loss : 0.2387 Learning Late: 0.0004
Epoch 100: 100%|██████████| 196/196 [01:42<00:00,  1.91batch/s]
Avg Loss : 0.2205 Validation Loss : 0.1939 Learning Late: 0.0000
FG 학습 완료. 이제 F의 output을 실제 dataset의 label과 연결.
Files already downloaded and verified
Files already downloaded and verified
Epoch 1: 100%|██████████| 391/391 [00:16<00:00, 23.47batch/s]
Avg Loss : 1.4046 Validation Loss : 1.3035 Learning Late: 0.0010
Epoch 2: 100%|██████████| 391/391 [00:16<00:00, 23.25batch/s]
Avg Loss : 1.2658 Validation Loss : 1.2598 Learning Late: 0.0010
Epoch 3: 100%|██████████| 391/391 [00:16<00:00, 23.87batch/s]
Avg Loss : 1.2275 Validation Loss : 1.2352 Learning Late: 0.0010
Epoch 4: 100%|██████████| 391/391 [00:16<00:00, 23.32batch/s]
Avg Loss : 1.2032 Validation Loss : 1.2191 Learning Late: 0.0010
Epoch 5: 100%|██████████| 391/391 [00:16<00:00, 23.85batch/s]
Avg Loss : 1.1855 Validation Loss : 1.2055 Learning Late: 0.0010
Epoch 6: 100%|██████████| 391/391 [00:16<00:00, 23.25batch/s]
Avg Loss : 1.1723 Validation Loss : 1.1874 Learning Late: 0.0010
Epoch 7: 100%|██████████| 391/391 [00:16<00:00, 23.90batch/s]
Avg Loss : 1.1604 Validation Loss : 1.1880 Learning Late: 0.0010
Epoch 8: 100%|██████████| 391/391 [00:16<00:00, 23.66batch/s]
Avg Loss : 1.1518 Validation Loss : 1.1750 Learning Late: 0.0010
Epoch 9: 100%|██████████| 391/391 [00:16<00:00, 23.62batch/s]
Avg Loss : 1.1428 Validation Loss : 1.1830 Learning Late: 0.0010
Epoch 10: 100%|██████████| 391/391 [00:16<00:00, 23.84batch/s]
Avg Loss : 1.1365 Validation Loss : 1.1668 Learning Late: 0.0010
Epoch 11: 100%|██████████| 391/391 [00:16<00:00, 23.27batch/s]
Avg Loss : 1.1292 Validation Loss : 1.1701 Learning Late: 0.0010
Epoch 12: 100%|██████████| 391/391 [00:16<00:00, 23.84batch/s]
Avg Loss : 1.1239 Validation Loss : 1.1621 Learning Late: 0.0010
Epoch 13: 100%|██████████| 391/391 [00:16<00:00, 23.13batch/s]
Avg Loss : 1.1203 Validation Loss : 1.1462 Learning Late: 0.0010
Epoch 14: 100%|██████████| 391/391 [00:16<00:00, 23.88batch/s]
Avg Loss : 1.1136 Validation Loss : 1.1474 Learning Late: 0.0010
Epoch 15: 100%|██████████| 391/391 [00:16<00:00, 23.03batch/s]
Avg Loss : 1.1091 Validation Loss : 1.1543 Learning Late: 0.0010
Epoch 16: 100%|██████████| 391/391 [00:16<00:00, 23.83batch/s]
Avg Loss : 1.1070 Validation Loss : 1.1410 Learning Late: 0.0010
Epoch 17: 100%|██████████| 391/391 [00:16<00:00, 23.96batch/s]
Avg Loss : 1.1019 Validation Loss : 1.1338 Learning Late: 0.0010
Epoch 18: 100%|██████████| 391/391 [00:16<00:00, 23.62batch/s]
Avg Loss : 1.0980 Validation Loss : 1.1307 Learning Late: 0.0010
Epoch 19: 100%|██████████| 391/391 [00:16<00:00, 23.98batch/s]
Avg Loss : 1.0938 Validation Loss : 1.1343 Learning Late: 0.0010
Epoch 20: 100%|██████████| 391/391 [00:16<00:00, 23.41batch/s]
Avg Loss : 1.0912 Validation Loss : 1.1345 Learning Late: 0.0010
Epoch 21: 100%|██████████| 391/391 [00:16<00:00, 24.05batch/s]
Avg Loss : 1.0906 Validation Loss : 1.1239 Learning Late: 0.0010
Epoch 22: 100%|██████████| 391/391 [00:16<00:00, 23.12batch/s]
Avg Loss : 1.0862 Validation Loss : 1.1321 Learning Late: 0.0010
Epoch 23: 100%|██████████| 391/391 [00:16<00:00, 23.75batch/s]
Avg Loss : 1.0818 Validation Loss : 1.1250 Learning Late: 0.0010
Epoch 24: 100%|██████████| 391/391 [00:17<00:00, 22.97batch/s]
Avg Loss : 1.0810 Validation Loss : 1.1166 Learning Late: 0.0010
Epoch 25: 100%|██████████| 391/391 [00:16<00:00, 23.86batch/s]
Avg Loss : 1.0781 Validation Loss : 1.1225 Learning Late: 0.0010
Epoch 26: 100%|██████████| 391/391 [00:16<00:00, 23.17batch/s]
Avg Loss : 1.0767 Validation Loss : 1.1189 Learning Late: 0.0010
Epoch 27: 100%|██████████| 391/391 [00:16<00:00, 23.86batch/s]
Avg Loss : 1.0743 Validation Loss : 1.1214 Learning Late: 0.0010
Epoch 28: 100%|██████████| 391/391 [00:16<00:00, 23.87batch/s]
Avg Loss : 1.0721 Validation Loss : 1.1177 Learning Late: 0.0010
Epoch 29: 100%|██████████| 391/391 [00:16<00:00, 23.85batch/s]
Avg Loss : 1.0691 Validation Loss : 1.1149 Learning Late: 0.0010
Epoch 30: 100%|██████████| 391/391 [00:16<00:00, 23.85batch/s]
Avg Loss : 1.0698 Validation Loss : 1.1133 Learning Late: 0.0010
Epoch 31: 100%|██████████| 391/391 [00:16<00:00, 23.55batch/s]
Avg Loss : 1.0684 Validation Loss : 1.1181 Learning Late: 0.0010
Epoch 32: 100%|██████████| 391/391 [00:16<00:00, 23.82batch/s]
Avg Loss : 1.0672 Validation Loss : 1.1149 Learning Late: 0.0010
Epoch 33: 100%|██████████| 391/391 [00:16<00:00, 23.31batch/s]
Avg Loss : 1.0643 Validation Loss : 1.1250 Learning Late: 0.0010
Epoch 34: 100%|██████████| 391/391 [00:16<00:00, 23.64batch/s]
Avg Loss : 1.0634 Validation Loss : 1.1186 Learning Late: 0.0010
Epoch 35: 100%|██████████| 391/391 [00:16<00:00, 23.03batch/s]
Avg Loss : 1.0622 Validation Loss : 1.1156 Learning Late: 0.0010
Epoch 36: 100%|██████████| 391/391 [00:16<00:00, 23.77batch/s]
Avg Loss : 1.0580 Validation Loss : 1.1093 Learning Late: 0.0010
Epoch 37: 100%|██████████| 391/391 [00:16<00:00, 23.38batch/s]
Avg Loss : 1.0591 Validation Loss : 1.1077 Learning Late: 0.0010
Epoch 38: 100%|██████████| 391/391 [00:16<00:00, 23.86batch/s]
Avg Loss : 1.0582 Validation Loss : 1.1109 Learning Late: 0.0009
Epoch 39: 100%|██████████| 391/391 [00:16<00:00, 23.80batch/s]
Avg Loss : 1.0575 Validation Loss : 1.1036 Learning Late: 0.0009
Epoch 40: 100%|██████████| 391/391 [00:16<00:00, 23.79batch/s]
Avg Loss : 1.0546 Validation Loss : 1.1071 Learning Late: 0.0009
Epoch 41: 100%|██████████| 391/391 [00:16<00:00, 23.89batch/s]
Avg Loss : 1.0540 Validation Loss : 1.1033 Learning Late: 0.0009
Epoch 42: 100%|██████████| 391/391 [00:16<00:00, 23.26batch/s]
Avg Loss : 1.0525 Validation Loss : 1.1071 Learning Late: 0.0009
Epoch 43: 100%|██████████| 391/391 [00:16<00:00, 23.64batch/s]
Avg Loss : 1.0514 Validation Loss : 1.1034 Learning Late: 0.0009
Epoch 44: 100%|██████████| 391/391 [00:16<00:00, 23.01batch/s]
Avg Loss : 1.0512 Validation Loss : 1.0988 Learning Late: 0.0009
Epoch 45: 100%|██████████| 391/391 [00:16<00:00, 23.78batch/s]
Avg Loss : 1.0489 Validation Loss : 1.0948 Learning Late: 0.0009
Epoch 46: 100%|██████████| 391/391 [00:16<00:00, 23.17batch/s]
Avg Loss : 1.0478 Validation Loss : 1.0970 Learning Late: 0.0009
Epoch 47: 100%|██████████| 391/391 [00:16<00:00, 23.62batch/s]
Avg Loss : 1.0478 Validation Loss : 1.0994 Learning Late: 0.0009
Epoch 48: 100%|██████████| 391/391 [00:16<00:00, 23.96batch/s]
Avg Loss : 1.0475 Validation Loss : 1.1063 Learning Late: 0.0009
Epoch 49: 100%|██████████| 391/391 [00:16<00:00, 23.75batch/s]
Avg Loss : 1.0452 Validation Loss : 1.1018 Learning Late: 0.0009
Epoch 50: 100%|██████████| 391/391 [00:16<00:00, 23.89batch/s]
Avg Loss : 1.0430 Validation Loss : 1.1107 Learning Late: 0.0009
Epoch 51: 100%|██████████| 391/391 [00:16<00:00, 23.29batch/s]
Avg Loss : 1.0436 Validation Loss : 1.1092 Learning Late: 0.0009
Epoch 52: 100%|██████████| 391/391 [00:16<00:00, 23.63batch/s]
Avg Loss : 1.0437 Validation Loss : 1.0952 Learning Late: 0.0009
Epoch 53: 100%|██████████| 391/391 [00:16<00:00, 23.17batch/s]
Avg Loss : 1.0420 Validation Loss : 1.0991 Learning Late: 0.0009
Epoch 54: 100%|██████████| 391/391 [00:16<00:00, 23.81batch/s]
Avg Loss : 1.0414 Validation Loss : 1.0983 Learning Late: 0.0009
Epoch 55: 100%|██████████| 391/391 [00:17<00:00, 22.92batch/s]
Avg Loss : 1.0411 Validation Loss : 1.0975 Learning Late: 0.0009
Epoch 56: 100%|██████████| 391/391 [00:16<00:00, 23.80batch/s]
Avg Loss : 1.0394 Validation Loss : 1.1100 Learning Late: 0.0009
Epoch 57: 100%|██████████| 391/391 [00:16<00:00, 23.04batch/s]
Avg Loss : 1.0382 Validation Loss : 1.1035 Learning Late: 0.0009
Epoch 58: 100%|██████████| 391/391 [00:16<00:00, 23.60batch/s]
Avg Loss : 1.0375 Validation Loss : 1.1017 Learning Late: 0.0009
Epoch 59: 100%|██████████| 391/391 [00:16<00:00, 23.74batch/s]
Avg Loss : 1.0372 Validation Loss : 1.1089 Learning Late: 0.0008
Epoch 60: 100%|██████████| 391/391 [00:16<00:00, 23.52batch/s]
Avg Loss : 1.0362 Validation Loss : 1.0876 Learning Late: 0.0008
Epoch 61: 100%|██████████| 391/391 [00:16<00:00, 23.78batch/s]
Avg Loss : 1.0358 Validation Loss : 1.0974 Learning Late: 0.0008
Epoch 62: 100%|██████████| 391/391 [00:16<00:00, 23.36batch/s]
Avg Loss : 1.0353 Validation Loss : 1.1025 Learning Late: 0.0008
Epoch 63: 100%|██████████| 391/391 [00:16<00:00, 23.63batch/s]
Avg Loss : 1.0339 Validation Loss : 1.0964 Learning Late: 0.0008
Epoch 64: 100%|██████████| 391/391 [00:16<00:00, 23.00batch/s]
Avg Loss : 1.0337 Validation Loss : 1.0935 Learning Late: 0.0008
Epoch 65: 100%|██████████| 391/391 [00:16<00:00, 23.87batch/s]
Avg Loss : 1.0335 Validation Loss : 1.0945 Learning Late: 0.0008
Epoch 66: 100%|██████████| 391/391 [00:17<00:00, 22.89batch/s]
Avg Loss : 1.0332 Validation Loss : 1.1035 Learning Late: 0.0008
Epoch 67: 100%|██████████| 391/391 [00:16<00:00, 23.79batch/s]
Avg Loss : 1.0324 Validation Loss : 1.0890 Learning Late: 0.0008
Epoch 68: 100%|██████████| 391/391 [00:16<00:00, 23.25batch/s]
Avg Loss : 1.0306 Validation Loss : 1.0875 Learning Late: 0.0008
Epoch 69: 100%|██████████| 391/391 [00:16<00:00, 23.60batch/s]
Avg Loss : 1.0298 Validation Loss : 1.0963 Learning Late: 0.0008
Epoch 70: 100%|██████████| 391/391 [00:16<00:00, 23.66batch/s]
Avg Loss : 1.0310 Validation Loss : 1.0893 Learning Late: 0.0008
Epoch 71: 100%|██████████| 391/391 [00:16<00:00, 23.46batch/s]
Avg Loss : 1.0295 Validation Loss : 1.0960 Learning Late: 0.0008
Epoch 72: 100%|██████████| 391/391 [00:16<00:00, 23.72batch/s]
Avg Loss : 1.0295 Validation Loss : 1.0922 Learning Late: 0.0008
Epoch 73: 100%|██████████| 391/391 [00:16<00:00, 23.24batch/s]
Avg Loss : 1.0294 Validation Loss : 1.0944 Learning Late: 0.0008
Epoch 74: 100%|██████████| 391/391 [00:16<00:00, 23.80batch/s]
Avg Loss : 1.0264 Validation Loss : 1.0911 Learning Late: 0.0007
Epoch 75: 100%|██████████| 391/391 [00:17<00:00, 22.83batch/s]
Avg Loss : 1.0266 Validation Loss : 1.0956 Learning Late: 0.0007
Epoch 76: 100%|██████████| 391/391 [00:16<00:00, 23.67batch/s]
Avg Loss : 1.0266 Validation Loss : 1.0970 Learning Late: 0.0007
Epoch 77: 100%|██████████| 391/391 [00:16<00:00, 23.22batch/s]
Avg Loss : 1.0264 Validation Loss : 1.0927 Learning Late: 0.0007
Epoch 78: 100%|██████████| 391/391 [00:16<00:00, 23.49batch/s]
Avg Loss : 1.0266 Validation Loss : 1.0816 Learning Late: 0.0007
Epoch 79: 100%|██████████| 391/391 [00:16<00:00, 23.65batch/s]
Avg Loss : 1.0261 Validation Loss : 1.0977 Learning Late: 0.0007
Epoch 80: 100%|██████████| 391/391 [00:16<00:00, 23.54batch/s]
Avg Loss : 1.0245 Validation Loss : 1.0858 Learning Late: 0.0007
Epoch 81: 100%|██████████| 391/391 [00:16<00:00, 23.80batch/s]
Avg Loss : 1.0248 Validation Loss : 1.1017 Learning Late: 0.0007
Epoch 82: 100%|██████████| 391/391 [00:16<00:00, 23.07batch/s]
Avg Loss : 1.0251 Validation Loss : 1.0926 Learning Late: 0.0007
Epoch 83: 100%|██████████| 391/391 [00:16<00:00, 23.59batch/s]
Avg Loss : 1.0239 Validation Loss : 1.0929 Learning Late: 0.0007
Epoch 84: 100%|██████████| 391/391 [00:17<00:00, 22.96batch/s]
Avg Loss : 1.0231 Validation Loss : 1.0933 Learning Late: 0.0007
Epoch 85: 100%|██████████| 391/391 [00:16<00:00, 23.71batch/s]
Avg Loss : 1.0231 Validation Loss : 1.0872 Learning Late: 0.0007
Epoch 86: 100%|██████████| 391/391 [00:17<00:00, 22.67batch/s]
Avg Loss : 1.0210 Validation Loss : 1.0927 Learning Late: 0.0007
Epoch 87: 100%|██████████| 391/391 [00:16<00:00, 23.69batch/s]
Avg Loss : 1.0209 Validation Loss : 1.0956 Learning Late: 0.0006
Epoch 88: 100%|██████████| 391/391 [00:16<00:00, 23.18batch/s]
Avg Loss : 1.0214 Validation Loss : 1.0951 Learning Late: 0.0006
Epoch 89: 100%|██████████| 391/391 [00:16<00:00, 23.54batch/s]
Avg Loss : 1.0210 Validation Loss : 1.0850 Learning Late: 0.0006
Epoch 90: 100%|██████████| 391/391 [00:16<00:00, 23.86batch/s]
Avg Loss : 1.0193 Validation Loss : 1.0885 Learning Late: 0.0006
Epoch 91: 100%|██████████| 391/391 [00:16<00:00, 23.76batch/s]
Avg Loss : 1.0203 Validation Loss : 1.0849 Learning Late: 0.0006
Epoch 92: 100%|██████████| 391/391 [00:16<00:00, 23.67batch/s]
Avg Loss : 1.0201 Validation Loss : 1.0918 Learning Late: 0.0006
Epoch 93: 100%|██████████| 391/391 [00:16<00:00, 23.12batch/s]
Avg Loss : 1.0197 Validation Loss : 1.0847 Learning Late: 0.0006
Epoch 94: 100%|██████████| 391/391 [00:16<00:00, 23.70batch/s]
Avg Loss : 1.0177 Validation Loss : 1.0947 Learning Late: 0.0006
Epoch 95: 100%|██████████| 391/391 [00:17<00:00, 22.86batch/s]
Avg Loss : 1.0182 Validation Loss : 1.0850 Learning Late: 0.0006
Epoch 96: 100%|██████████| 391/391 [00:16<00:00, 23.51batch/s]
Avg Loss : 1.0171 Validation Loss : 1.0848 Learning Late: 0.0006
Epoch 97: 100%|██████████| 391/391 [00:17<00:00, 22.92batch/s]
Avg Loss : 1.0175 Validation Loss : 1.0852 Learning Late: 0.0006
Epoch 98: 100%|██████████| 391/391 [00:16<00:00, 23.73batch/s]
Avg Loss : 1.0169 Validation Loss : 1.0777 Learning Late: 0.0006
Epoch 99: 100%|██████████| 391/391 [00:16<00:00, 23.44batch/s]
Avg Loss : 1.0166 Validation Loss : 1.0912 Learning Late: 0.0005
Epoch 100: 100%|██████████| 391/391 [00:16<00:00, 23.35batch/s]
Avg Loss : 1.0154 Validation Loss : 1.0858 Learning Late: 0.0005
Epoch 101: 100%|██████████| 391/391 [00:16<00:00, 23.74batch/s]
Avg Loss : 1.0149 Validation Loss : 1.0872 Learning Late: 0.0005
Epoch 102: 100%|██████████| 391/391 [00:17<00:00, 22.96batch/s]
Avg Loss : 1.0149 Validation Loss : 1.0900 Learning Late: 0.0005
Epoch 103: 100%|██████████| 391/391 [00:16<00:00, 23.53batch/s]
Avg Loss : 1.0154 Validation Loss : 1.0823 Learning Late: 0.0005
Epoch 104: 100%|██████████| 391/391 [00:17<00:00, 22.63batch/s]
Avg Loss : 1.0145 Validation Loss : 1.0864 Learning Late: 0.0005
Epoch 105: 100%|██████████| 391/391 [00:16<00:00, 23.82batch/s]
Avg Loss : 1.0145 Validation Loss : 1.0919 Learning Late: 0.0005
Epoch 106: 100%|██████████| 391/391 [00:17<00:00, 22.95batch/s]
Avg Loss : 1.0140 Validation Loss : 1.0850 Learning Late: 0.0005
Epoch 107: 100%|██████████| 391/391 [00:16<00:00, 23.55batch/s]
Avg Loss : 1.0141 Validation Loss : 1.0808 Learning Late: 0.0005
Epoch 108: 100%|██████████| 391/391 [00:16<00:00, 23.72batch/s]
Avg Loss : 1.0131 Validation Loss : 1.0950 Learning Late: 0.0005
Epoch 109: 100%|██████████| 391/391 [00:16<00:00, 23.29batch/s]
Avg Loss : 1.0138 Validation Loss : 1.0883 Learning Late: 0.0005
Epoch 110: 100%|██████████| 391/391 [00:16<00:00, 23.64batch/s]
Avg Loss : 1.0125 Validation Loss : 1.0789 Learning Late: 0.0005
Epoch 111: 100%|██████████| 391/391 [00:17<00:00, 22.96batch/s]
Avg Loss : 1.0117 Validation Loss : 1.0866 Learning Late: 0.0005
Epoch 112: 100%|██████████| 391/391 [00:16<00:00, 23.35batch/s]
Avg Loss : 1.0113 Validation Loss : 1.0856 Learning Late: 0.0004
Epoch 113: 100%|██████████| 391/391 [00:17<00:00, 22.95batch/s]
Avg Loss : 1.0116 Validation Loss : 1.0802 Learning Late: 0.0004
Epoch 114: 100%|██████████| 391/391 [00:16<00:00, 23.61batch/s]
Avg Loss : 1.0111 Validation Loss : 1.0783 Learning Late: 0.0004
Epoch 115: 100%|██████████| 391/391 [00:16<00:00, 23.12batch/s]
Avg Loss : 1.0107 Validation Loss : 1.0890 Learning Late: 0.0004
Epoch 116: 100%|██████████| 391/391 [00:16<00:00, 23.32batch/s]
Avg Loss : 1.0109 Validation Loss : 1.0795 Learning Late: 0.0004
Epoch 117: 100%|██████████| 391/391 [00:16<00:00, 23.40batch/s]
Avg Loss : 1.0105 Validation Loss : 1.0837 Learning Late: 0.0004
Epoch 118: 100%|██████████| 391/391 [00:16<00:00, 23.35batch/s]
Avg Loss : 1.0103 Validation Loss : 1.0899 Learning Late: 0.0004
Epoch 119: 100%|██████████| 391/391 [00:16<00:00, 23.66batch/s]
Avg Loss : 1.0098 Validation Loss : 1.0817 Learning Late: 0.0004
Epoch 120: 100%|██████████| 391/391 [00:16<00:00, 23.41batch/s]
Avg Loss : 1.0095 Validation Loss : 1.0832 Learning Late: 0.0004
Epoch 121: 100%|██████████| 391/391 [00:16<00:00, 23.34batch/s]
Avg Loss : 1.0093 Validation Loss : 1.0812 Learning Late: 0.0004
Epoch 122: 100%|██████████| 391/391 [00:17<00:00, 22.72batch/s]
Avg Loss : 1.0090 Validation Loss : 1.0837 Learning Late: 0.0004
Epoch 123: 100%|██████████| 391/391 [00:16<00:00, 23.33batch/s]
Avg Loss : 1.0086 Validation Loss : 1.0788 Learning Late: 0.0004
Epoch 124: 100%|██████████| 391/391 [00:16<00:00, 23.00batch/s]
Avg Loss : 1.0081 Validation Loss : 1.0885 Learning Late: 0.0003
Epoch 125: 100%|██████████| 391/391 [00:16<00:00, 23.38batch/s]
Avg Loss : 1.0079 Validation Loss : 1.0841 Learning Late: 0.0003
Epoch 126: 100%|██████████| 391/391 [00:16<00:00, 23.57batch/s]
Avg Loss : 1.0076 Validation Loss : 1.0805 Learning Late: 0.0003
Epoch 127: 100%|██████████| 391/391 [00:16<00:00, 23.41batch/s]
Avg Loss : 1.0073 Validation Loss : 1.0802 Learning Late: 0.0003
Epoch 128: 100%|██████████| 391/391 [00:16<00:00, 23.24batch/s]
Avg Loss : 1.0069 Validation Loss : 1.0797 Learning Late: 0.0003
Epoch 129: 100%|██████████| 391/391 [00:17<00:00, 22.93batch/s]
Avg Loss : 1.0069 Validation Loss : 1.0836 Learning Late: 0.0003
Epoch 130: 100%|██████████| 391/391 [00:16<00:00, 23.40batch/s]
Avg Loss : 1.0061 Validation Loss : 1.0778 Learning Late: 0.0003
Epoch 131: 100%|██████████| 391/391 [00:17<00:00, 22.78batch/s]
Avg Loss : 1.0069 Validation Loss : 1.0794 Learning Late: 0.0003
Epoch 132: 100%|██████████| 391/391 [00:16<00:00, 23.51batch/s]
Avg Loss : 1.0060 Validation Loss : 1.0845 Learning Late: 0.0003
Epoch 133: 100%|██████████| 391/391 [00:17<00:00, 22.83batch/s]
Avg Loss : 1.0055 Validation Loss : 1.0799 Learning Late: 0.0003
Epoch 134: 100%|██████████| 391/391 [00:16<00:00, 23.48batch/s]
Avg Loss : 1.0048 Validation Loss : 1.0879 Learning Late: 0.0003
Epoch 135: 100%|██████████| 391/391 [00:16<00:00, 23.12batch/s]
Avg Loss : 1.0054 Validation Loss : 1.0894 Learning Late: 0.0003
Epoch 136: 100%|██████████| 391/391 [00:16<00:00, 23.21batch/s]
Avg Loss : 1.0056 Validation Loss : 1.0789 Learning Late: 0.0003
Epoch 137: 100%|██████████| 391/391 [00:16<00:00, 23.74batch/s]
Avg Loss : 1.0049 Validation Loss : 1.0772 Learning Late: 0.0002
Epoch 138: 100%|██████████| 391/391 [00:17<00:00, 22.93batch/s]
Avg Loss : 1.0042 Validation Loss : 1.0823 Learning Late: 0.0002
Epoch 139: 100%|██████████| 391/391 [00:16<00:00, 23.31batch/s]
Avg Loss : 1.0040 Validation Loss : 1.0788 Learning Late: 0.0002
Epoch 140: 100%|██████████| 391/391 [00:17<00:00, 22.87batch/s]
Avg Loss : 1.0037 Validation Loss : 1.0801 Learning Late: 0.0002
Epoch 141: 100%|██████████| 391/391 [00:16<00:00, 23.33batch/s]
Avg Loss : 1.0037 Validation Loss : 1.0809 Learning Late: 0.0002
Epoch 142: 100%|██████████| 391/391 [00:17<00:00, 22.90batch/s]
Avg Loss : 1.0035 Validation Loss : 1.0789 Learning Late: 0.0002
Epoch 143: 100%|██████████| 391/391 [00:16<00:00, 23.34batch/s]
Avg Loss : 1.0031 Validation Loss : 1.0799 Learning Late: 0.0002
Epoch 144: 100%|██████████| 391/391 [00:16<00:00, 23.55batch/s]
Avg Loss : 1.0031 Validation Loss : 1.0778 Learning Late: 0.0002
Epoch 145: 100%|██████████| 391/391 [00:16<00:00, 23.14batch/s]
Avg Loss : 1.0030 Validation Loss : 1.0752 Learning Late: 0.0002
Epoch 146: 100%|██████████| 391/391 [00:16<00:00, 23.52batch/s]
Avg Loss : 1.0024 Validation Loss : 1.0753 Learning Late: 0.0002
Epoch 147: 100%|██████████| 391/391 [00:17<00:00, 22.94batch/s]
Avg Loss : 1.0027 Validation Loss : 1.0771 Learning Late: 0.0002
Epoch 148: 100%|██████████| 391/391 [00:16<00:00, 23.39batch/s]
Avg Loss : 1.0021 Validation Loss : 1.0784 Learning Late: 0.0002
Epoch 149: 100%|██████████| 391/391 [00:17<00:00, 22.83batch/s]
Avg Loss : 1.0017 Validation Loss : 1.0764 Learning Late: 0.0002
Epoch 150: 100%|██████████| 391/391 [00:16<00:00, 23.34batch/s]
Avg Loss : 1.0016 Validation Loss : 1.0807 Learning Late: 0.0002
Epoch 151: 100%|██████████| 391/391 [00:16<00:00, 23.13batch/s]
Avg Loss : 1.0013 Validation Loss : 1.0764 Learning Late: 0.0002
Epoch 152: 100%|██████████| 391/391 [00:16<00:00, 23.30batch/s]
Avg Loss : 1.0012 Validation Loss : 1.0750 Learning Late: 0.0001
Epoch 153: 100%|██████████| 391/391 [00:16<00:00, 23.58batch/s]
Avg Loss : 1.0012 Validation Loss : 1.0728 Learning Late: 0.0001
Epoch 154: 100%|██████████| 391/391 [00:16<00:00, 23.22batch/s]
Avg Loss : 1.0011 Validation Loss : 1.0818 Learning Late: 0.0001
Epoch 155: 100%|██████████| 391/391 [00:16<00:00, 23.44batch/s]
Avg Loss : 1.0006 Validation Loss : 1.0805 Learning Late: 0.0001
Epoch 156: 100%|██████████| 391/391 [00:17<00:00, 22.60batch/s]
Avg Loss : 1.0006 Validation Loss : 1.0751 Learning Late: 0.0001
Epoch 157: 100%|██████████| 391/391 [00:16<00:00, 23.43batch/s]
Avg Loss : 1.0002 Validation Loss : 1.0763 Learning Late: 0.0001
Epoch 158: 100%|██████████| 391/391 [00:17<00:00, 22.97batch/s]
Avg Loss : 1.0003 Validation Loss : 1.0776 Learning Late: 0.0001
Epoch 159: 100%|██████████| 391/391 [00:16<00:00, 23.14batch/s]
Avg Loss : 0.9997 Validation Loss : 1.0781 Learning Late: 0.0001
Epoch 160: 100%|██████████| 391/391 [00:17<00:00, 22.87batch/s]
Avg Loss : 1.0001 Validation Loss : 1.0839 Learning Late: 0.0001
Epoch 161: 100%|██████████| 391/391 [00:16<00:00, 23.34batch/s]
Avg Loss : 0.9999 Validation Loss : 1.0819 Learning Late: 0.0001
Epoch 162: 100%|██████████| 391/391 [00:16<00:00, 23.35batch/s]
Avg Loss : 0.9998 Validation Loss : 1.0777 Learning Late: 0.0001
Epoch 163: 100%|██████████| 391/391 [00:16<00:00, 23.05batch/s]
Avg Loss : 0.9994 Validation Loss : 1.0710 Learning Late: 0.0001
Epoch 164: 100%|██████████| 391/391 [00:16<00:00, 23.47batch/s]
Avg Loss : 0.9991 Validation Loss : 1.0734 Learning Late: 0.0001
Epoch 165: 100%|██████████| 391/391 [00:17<00:00, 22.56batch/s]
Avg Loss : 0.9989 Validation Loss : 1.0758 Learning Late: 0.0001
Epoch 166: 100%|██████████| 391/391 [00:16<00:00, 23.61batch/s]
Avg Loss : 0.9993 Validation Loss : 1.0771 Learning Late: 0.0001
Epoch 167: 100%|██████████| 391/391 [00:17<00:00, 22.79batch/s]
Avg Loss : 0.9989 Validation Loss : 1.0808 Learning Late: 0.0001
Epoch 168: 100%|██████████| 391/391 [00:16<00:00, 23.33batch/s]
Avg Loss : 0.9986 Validation Loss : 1.0773 Learning Late: 0.0001
Epoch 169: 100%|██████████| 391/391 [00:17<00:00, 22.69batch/s]
Avg Loss : 0.9986 Validation Loss : 1.0760 Learning Late: 0.0001
Epoch 170: 100%|██████████| 391/391 [00:16<00:00, 23.58batch/s]
Avg Loss : 0.9985 Validation Loss : 1.0764 Learning Late: 0.0001
Epoch 171: 100%|██████████| 391/391 [00:16<00:00, 23.28batch/s]
Avg Loss : 0.9983 Validation Loss : 1.0737 Learning Late: 0.0001
Epoch 172: 100%|██████████| 391/391 [00:16<00:00, 23.25batch/s]
Avg Loss : 0.9983 Validation Loss : 1.0765 Learning Late: 0.0001
Epoch 173: 100%|██████████| 391/391 [00:16<00:00, 23.30batch/s]
Avg Loss : 0.9980 Validation Loss : 1.0792 Learning Late: 0.0000
Epoch 174: 100%|██████████| 391/391 [00:17<00:00, 22.70batch/s]
Avg Loss : 0.9981 Validation Loss : 1.0795 Learning Late: 0.0000
Epoch 175: 100%|██████████| 391/391 [00:16<00:00, 23.17batch/s]
Avg Loss : 0.9978 Validation Loss : 1.0830 Learning Late: 0.0000
Epoch 176: 100%|██████████| 391/391 [00:17<00:00, 22.54batch/s]
Avg Loss : 0.9978 Validation Loss : 1.0771 Learning Late: 0.0000
Epoch 177: 100%|██████████| 391/391 [00:16<00:00, 23.29batch/s]
Avg Loss : 0.9976 Validation Loss : 1.0758 Learning Late: 0.0000
Epoch 178: 100%|██████████| 391/391 [00:16<00:00, 23.07batch/s]
Avg Loss : 0.9978 Validation Loss : 1.0726 Learning Late: 0.0000
Epoch 179: 100%|██████████| 391/391 [00:16<00:00, 23.19batch/s]
Avg Loss : 0.9974 Validation Loss : 1.0762 Learning Late: 0.0000
Epoch 180: 100%|██████████| 391/391 [00:16<00:00, 23.31batch/s]
Avg Loss : 0.9973 Validation Loss : 1.0760 Learning Late: 0.0000
Epoch 181: 100%|██████████| 391/391 [00:17<00:00, 22.78batch/s]
Avg Loss : 0.9971 Validation Loss : 1.0787 Learning Late: 0.0000
Epoch 182: 100%|██████████| 391/391 [00:16<00:00, 23.20batch/s]
Avg Loss : 0.9970 Validation Loss : 1.0772 Learning Late: 0.0000
Epoch 183: 100%|██████████| 391/391 [00:17<00:00, 22.86batch/s]
Avg Loss : 0.9970 Validation Loss : 1.0777 Learning Late: 0.0000
Epoch 184: 100%|██████████| 391/391 [00:16<00:00, 23.33batch/s]
Avg Loss : 0.9970 Validation Loss : 1.0738 Learning Late: 0.0000
Epoch 185: 100%|██████████| 391/391 [00:17<00:00, 22.43batch/s]
Avg Loss : 0.9969 Validation Loss : 1.0739 Learning Late: 0.0000
Epoch 186: 100%|██████████| 391/391 [00:16<00:00, 23.15batch/s]
Avg Loss : 0.9966 Validation Loss : 1.0776 Learning Late: 0.0000
Epoch 187: 100%|██████████| 391/391 [00:17<00:00, 22.85batch/s]
Avg Loss : 0.9967 Validation Loss : 1.0776 Learning Late: 0.0000
Epoch 188: 100%|██████████| 391/391 [00:16<00:00, 23.27batch/s]
Avg Loss : 0.9967 Validation Loss : 1.0787 Learning Late: 0.0000
Epoch 189: 100%|██████████| 391/391 [00:16<00:00, 23.22batch/s]
Avg Loss : 0.9965 Validation Loss : 1.0817 Learning Late: 0.0000
Epoch 190: 100%|██████████| 391/391 [00:17<00:00, 22.94batch/s]
Avg Loss : 0.9967 Validation Loss : 1.0720 Learning Late: 0.0000
Epoch 191: 100%|██████████| 391/391 [00:16<00:00, 23.44batch/s]
Avg Loss : 0.9965 Validation Loss : 1.0770 Learning Late: 0.0000
Epoch 192: 100%|██████████| 391/391 [00:17<00:00, 22.58batch/s]
Avg Loss : 0.9965 Validation Loss : 1.0748 Learning Late: 0.0000
Epoch 193: 100%|██████████| 391/391 [00:16<00:00, 23.45batch/s]
Avg Loss : 0.9966 Validation Loss : 1.0729 Learning Late: 0.0000
Epoch 194: 100%|██████████| 391/391 [00:17<00:00, 22.32batch/s]
Avg Loss : 0.9965 Validation Loss : 1.0797 Learning Late: 0.0000
Epoch 195: 100%|██████████| 391/391 [00:16<00:00, 23.12batch/s]
Avg Loss : 0.9962 Validation Loss : 1.0746 Learning Late: 0.0000
Epoch 196: 100%|██████████| 391/391 [00:17<00:00, 22.35batch/s]
Avg Loss : 0.9962 Validation Loss : 1.0719 Learning Late: 0.0000
Epoch 197: 100%|██████████| 391/391 [00:16<00:00, 23.02batch/s]
Avg Loss : 0.9964 Validation Loss : 1.0771 Learning Late: 0.0000
Epoch 198: 100%|██████████| 391/391 [00:17<00:00, 22.54batch/s]
Avg Loss : 0.9964 Validation Loss : 1.0782 Learning Late: 0.0000
Epoch 199: 100%|██████████| 391/391 [00:16<00:00, 23.22batch/s]
Avg Loss : 0.9960 Validation Loss : 1.0813 Learning Late: 0.0000
Epoch 200: 100%|██████████| 391/391 [00:17<00:00, 22.65batch/s]
Avg Loss : 0.9962 Validation Loss : 1.0725 Learning Late: 0.0000

실제 test
100%|██████████| 79/79 [00:03<00:00, 25.18batch/s]총 개수 : 10000
top-1 맞춘 개수 : 6249
 정확도: 62.49
top-5 맞춘 개수 : 9621
 정확도: 96.21
