Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz
100%|██████████| 170498071/170498071 [00:02<00:00, 76969744.72it/s]
Extracting ./data/cifar-10-python.tar.gz to ./data
Files already downloaded and verified
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Epoch 1: 100%|██████████| 98/98 [01:12<00:00,  1.34batch/s]
Avg Loss : 6.2918 Validation Loss : 5.9020 Learning Late: 1.6971
Epoch 2: 100%|██████████| 98/98 [01:12<00:00,  1.34batch/s]
Avg Loss : 5.6404 Validation Loss : 5.5585 Learning Late: 1.6971
Epoch 3: 100%|██████████| 98/98 [01:12<00:00,  1.36batch/s]
Avg Loss : 5.5161 Validation Loss : 5.5377 Learning Late: 1.6971
Epoch 4: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 5.5026 Validation Loss : 5.6855 Learning Late: 1.6971
Epoch 5: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 5.2223 Validation Loss : 4.7635 Learning Late: 1.6971
Epoch 6: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 4.9532 Validation Loss : 4.8426 Learning Late: 1.6971
Epoch 7: 100%|██████████| 98/98 [01:11<00:00,  1.36batch/s]
Avg Loss : 4.8621 Validation Loss : 4.7221 Learning Late: 1.6971
Epoch 8: 100%|██████████| 98/98 [01:12<00:00,  1.36batch/s]
Avg Loss : 4.6273 Validation Loss : 4.6909 Learning Late: 1.6971
Epoch 9: 100%|██████████| 98/98 [01:12<00:00,  1.36batch/s]
Avg Loss : 4.4683 Validation Loss : 4.5949 Learning Late: 1.6971
Epoch 10: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 4.5228 Validation Loss : 4.5039 Learning Late: 1.6971
Epoch 11: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 4.5215 Validation Loss : 4.2797 Learning Late: 1.6965
Epoch 12: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 4.1182 Validation Loss : 4.0149 Learning Late: 1.6950
Epoch 13: 100%|██████████| 98/98 [01:11<00:00,  1.36batch/s]
Avg Loss : 3.9195 Validation Loss : 3.6292 Learning Late: 1.6924
Epoch 14: 100%|██████████| 98/98 [01:11<00:00,  1.36batch/s]
Avg Loss : 3.8685 Validation Loss : 3.4907 Learning Late: 1.6888
Epoch 15: 100%|██████████| 98/98 [01:12<00:00,  1.36batch/s]
Avg Loss : 3.6819 Validation Loss : 3.7954 Learning Late: 1.6842
Epoch 16: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 3.8300 Validation Loss : 3.6203 Learning Late: 1.6785
Epoch 17: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 3.4441 Validation Loss : 3.1592 Learning Late: 1.6719
Epoch 18: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 3.1727 Validation Loss : 2.9635 Learning Late: 1.6642
Epoch 19: 100%|██████████| 98/98 [01:11<00:00,  1.36batch/s]
Avg Loss : 3.0641 Validation Loss : 3.0131 Learning Late: 1.6555
Epoch 20: 100%|██████████| 98/98 [01:12<00:00,  1.36batch/s]
Avg Loss : 2.8092 Validation Loss : 2.7041 Learning Late: 1.6459
Epoch 21: 100%|██████████| 98/98 [01:12<00:00,  1.36batch/s]
Avg Loss : 2.7642 Validation Loss : 2.6805 Learning Late: 1.6353
Epoch 22: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 2.7268 Validation Loss : 2.6795 Learning Late: 1.6237
Epoch 23: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 2.5434 Validation Loss : 2.4839 Learning Late: 1.6112
Epoch 24: 100%|██████████| 98/98 [01:11<00:00,  1.36batch/s]
Avg Loss : 2.5409 Validation Loss : 2.4793 Learning Late: 1.5977
Epoch 25: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 2.3610 Validation Loss : 2.3506 Learning Late: 1.5834
Epoch 26: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 2.5959 Validation Loss : 2.3292 Learning Late: 1.5681
Epoch 27: 100%|██████████| 98/98 [01:12<00:00,  1.36batch/s]
Avg Loss : 2.2579 Validation Loss : 2.1589 Learning Late: 1.5520
Epoch 28: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 2.2590 Validation Loss : 2.1374 Learning Late: 1.5350
Epoch 29: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 2.1625 Validation Loss : 1.9580 Learning Late: 1.5172
Epoch 30: 100%|██████████| 98/98 [01:11<00:00,  1.36batch/s]
Avg Loss : 2.0254 Validation Loss : 2.0922 Learning Late: 1.4985
Epoch 31: 100%|██████████| 98/98 [01:11<00:00,  1.36batch/s]
Avg Loss : 2.1863 Validation Loss : 2.2456 Learning Late: 1.4791
Epoch 32: 100%|██████████| 98/98 [01:11<00:00,  1.36batch/s]
Avg Loss : 2.0321 Validation Loss : 1.8907 Learning Late: 1.4589
Epoch 33: 100%|██████████| 98/98 [01:12<00:00,  1.36batch/s]
Avg Loss : 1.8884 Validation Loss : 1.7721 Learning Late: 1.4380
Epoch 34: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 1.8105 Validation Loss : 1.7432 Learning Late: 1.4163
Epoch 35: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 1.7778 Validation Loss : 1.6868 Learning Late: 1.3940
Epoch 36: 100%|██████████| 98/98 [01:11<00:00,  1.36batch/s]
Avg Loss : 1.6718 Validation Loss : 1.5875 Learning Late: 1.3709
Epoch 37: 100%|██████████| 98/98 [01:11<00:00,  1.36batch/s]
Avg Loss : 1.5889 Validation Loss : 1.4908 Learning Late: 1.3473
Epoch 38: 100%|██████████| 98/98 [01:11<00:00,  1.36batch/s]
Avg Loss : 1.5241 Validation Loss : 1.4379 Learning Late: 1.3230
Epoch 39: 100%|██████████| 98/98 [01:12<00:00,  1.36batch/s]
Avg Loss : 1.4775 Validation Loss : 1.2951 Learning Late: 1.2982
Epoch 40: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 1.4216 Validation Loss : 1.1938 Learning Late: 1.2728
Epoch 41: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 1.3537 Validation Loss : 1.3114 Learning Late: 1.2469
Epoch 42: 100%|██████████| 98/98 [01:11<00:00,  1.36batch/s]
Avg Loss : 1.3328 Validation Loss : 1.4678 Learning Late: 1.2205
Epoch 43: 100%|██████████| 98/98 [01:11<00:00,  1.36batch/s]
Avg Loss : 1.3806 Validation Loss : 1.1797 Learning Late: 1.1937
Epoch 44: 100%|██████████| 98/98 [01:11<00:00,  1.36batch/s]
Avg Loss : 1.2721 Validation Loss : 1.4134 Learning Late: 1.1664
Epoch 45: 100%|██████████| 98/98 [01:12<00:00,  1.36batch/s]
Avg Loss : 1.1975 Validation Loss : 1.3833 Learning Late: 1.1387
Epoch 46: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 1.2852 Validation Loss : 1.3135 Learning Late: 1.1107
Epoch 47: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 1.2040 Validation Loss : 1.0829 Learning Late: 1.0824
Epoch 48: 100%|██████████| 98/98 [01:11<00:00,  1.36batch/s]
Avg Loss : 1.1304 Validation Loss : 1.1018 Learning Late: 1.0538
Epoch 49: 100%|██████████| 98/98 [01:11<00:00,  1.36batch/s]
Avg Loss : 1.1249 Validation Loss : 1.1113 Learning Late: 1.0249
Epoch 50: 100%|██████████| 98/98 [01:11<00:00,  1.36batch/s]
Avg Loss : 1.0641 Validation Loss : 1.0615 Learning Late: 0.9959
Epoch 51: 100%|██████████| 98/98 [01:12<00:00,  1.36batch/s]
Avg Loss : 1.0998 Validation Loss : 1.1071 Learning Late: 0.9666
Epoch 52: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 1.0366 Validation Loss : 1.1071 Learning Late: 0.9372
Epoch 53: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 1.0584 Validation Loss : 0.9345 Learning Late: 0.9077
Epoch 54: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 1.0347 Validation Loss : 0.9255 Learning Late: 0.8781
Epoch 55: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 1.0039 Validation Loss : 0.9289 Learning Late: 0.8485
Epoch 56: 100%|██████████| 98/98 [01:11<00:00,  1.36batch/s]
Avg Loss : 0.9811 Validation Loss : 0.9051 Learning Late: 0.8189
Epoch 57: 100%|██████████| 98/98 [01:12<00:00,  1.36batch/s]
Avg Loss : 0.9768 Validation Loss : 0.8626 Learning Late: 0.7893
Epoch 58: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 0.8569 Validation Loss : 0.8537 Learning Late: 0.7598
Epoch 59: 100%|██████████| 98/98 [01:11<00:00,  1.36batch/s]
Avg Loss : 0.8942 Validation Loss : 1.0111 Learning Late: 0.7304
Epoch 60: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 0.8931 Validation Loss : 0.8735 Learning Late: 0.7012
Epoch 61: 100%|██████████| 98/98 [01:11<00:00,  1.36batch/s]
Avg Loss : 0.9358 Validation Loss : 0.7292 Learning Late: 0.6721
Epoch 62: 100%|██████████| 98/98 [01:11<00:00,  1.36batch/s]
Avg Loss : 0.8769 Validation Loss : 0.8533 Learning Late: 0.6433
Epoch 63: 100%|██████████| 98/98 [01:12<00:00,  1.35batch/s]
Avg Loss : 0.9073 Validation Loss : 0.7985 Learning Late: 0.6146
Epoch 64: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 0.8008 Validation Loss : 0.7501 Learning Late: 0.5863
Epoch 65: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 0.8116 Validation Loss : 0.9766 Learning Late: 0.5583
Epoch 66: 100%|██████████| 98/98 [01:11<00:00,  1.36batch/s]
Avg Loss : 0.8817 Validation Loss : 0.7009 Learning Late: 0.5307
Epoch 67: 100%|██████████| 98/98 [01:12<00:00,  1.36batch/s]
Avg Loss : 0.7564 Validation Loss : 0.8288 Learning Late: 0.5034
Epoch 68: 100%|██████████| 98/98 [01:12<00:00,  1.35batch/s]
Avg Loss : 0.8505 Validation Loss : 0.7196 Learning Late: 0.4766
Epoch 69: 100%|██████████| 98/98 [01:12<00:00,  1.35batch/s]
Avg Loss : 0.8435 Validation Loss : 0.6827 Learning Late: 0.4502
Epoch 70: 100%|██████████| 98/98 [01:12<00:00,  1.35batch/s]
Avg Loss : 0.7303 Validation Loss : 0.8072 Learning Late: 0.4243
Epoch 71: 100%|██████████| 98/98 [01:12<00:00,  1.35batch/s]
Avg Loss : 0.7167 Validation Loss : 0.7623 Learning Late: 0.3989
Epoch 72: 100%|██████████| 98/98 [01:12<00:00,  1.36batch/s]
Avg Loss : 0.7199 Validation Loss : 0.6840 Learning Late: 0.3740
Epoch 73: 100%|██████████| 98/98 [01:11<00:00,  1.36batch/s]
Avg Loss : 0.7522 Validation Loss : 0.7213 Learning Late: 0.3498
Epoch 74: 100%|██████████| 98/98 [01:12<00:00,  1.36batch/s]
Avg Loss : 0.7696 Validation Loss : 0.7143 Learning Late: 0.3261
Epoch 75: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 0.7165 Validation Loss : 0.7386 Learning Late: 0.3031
Epoch 76: 100%|██████████| 98/98 [01:11<00:00,  1.36batch/s]
Avg Loss : 0.7713 Validation Loss : 0.6778 Learning Late: 0.2808
Epoch 77: 100%|██████████| 98/98 [01:12<00:00,  1.36batch/s]
Avg Loss : 0.6715 Validation Loss : 0.7427 Learning Late: 0.2591
Epoch 78: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 0.6753 Validation Loss : 0.6731 Learning Late: 0.2381
Epoch 79: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 0.6607 Validation Loss : 0.7818 Learning Late: 0.2179
Epoch 80: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 0.7537 Validation Loss : 0.6357 Learning Late: 0.1985
Epoch 81: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 0.7043 Validation Loss : 0.6656 Learning Late: 0.1799
Epoch 82: 100%|██████████| 98/98 [01:11<00:00,  1.36batch/s]
Avg Loss : 0.7030 Validation Loss : 0.7183 Learning Late: 0.1621
Epoch 83: 100%|██████████| 98/98 [01:11<00:00,  1.36batch/s]
Avg Loss : 0.6788 Validation Loss : 0.6203 Learning Late: 0.1451
Epoch 84: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 0.7360 Validation Loss : 0.7136 Learning Late: 0.1289
Epoch 85: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 0.6716 Validation Loss : 0.6729 Learning Late: 0.1137
Epoch 86: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 0.6853 Validation Loss : 0.6999 Learning Late: 0.0993
Epoch 87: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 0.6615 Validation Loss : 0.6804 Learning Late: 0.0859
Epoch 88: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 0.7180 Validation Loss : 0.6288 Learning Late: 0.0734
Epoch 89: 100%|██████████| 98/98 [01:11<00:00,  1.36batch/s]
Avg Loss : 0.7102 Validation Loss : 0.7172 Learning Late: 0.0618
Epoch 90: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 0.6566 Validation Loss : 0.5944 Learning Late: 0.0512
Epoch 91: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 0.6521 Validation Loss : 0.7608 Learning Late: 0.0415
Epoch 92: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 0.6730 Validation Loss : 0.6450 Learning Late: 0.0329
Epoch 93: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 0.6235 Validation Loss : 0.5981 Learning Late: 0.0252
Epoch 94: 100%|██████████| 98/98 [01:11<00:00,  1.36batch/s]
Avg Loss : 0.6641 Validation Loss : 0.5439 Learning Late: 0.0185
Epoch 95: 100%|██████████| 98/98 [01:12<00:00,  1.36batch/s]
Avg Loss : 0.6762 Validation Loss : 0.5788 Learning Late: 0.0129
Epoch 96: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 0.6457 Validation Loss : 0.6445 Learning Late: 0.0083
Epoch 97: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 0.6876 Validation Loss : 0.7185 Learning Late: 0.0046
Epoch 98: 100%|██████████| 98/98 [01:11<00:00,  1.37batch/s]
Avg Loss : 0.6366 Validation Loss : 0.6159 Learning Late: 0.0021
Epoch 99: 100%|██████████| 98/98 [01:12<00:00,  1.36batch/s]
Avg Loss : 0.6587 Validation Loss : 0.6963 Learning Late: 0.0005
Epoch 100: 100%|██████████| 98/98 [01:12<00:00,  1.36batch/s]
Avg Loss : 0.6360 Validation Loss : 0.7022 Learning Late: 0.0000
FG 학습 완료. 이제 F의 output을 실제 dataset의 label과 연결.
Files already downloaded and verified
Files already downloaded and verified
Epoch 1: 100%|██████████| 391/391 [00:11<00:00, 34.94batch/s]
Avg Loss : 1.5026 Validation Loss : 1.4250 Learning Late: 0.0010
Epoch 2: 100%|██████████| 391/391 [00:11<00:00, 35.05batch/s]
Avg Loss : 1.3818 Validation Loss : 1.3689 Learning Late: 0.0010
Epoch 3: 100%|██████████| 391/391 [00:11<00:00, 35.31batch/s]
Avg Loss : 1.3483 Validation Loss : 1.3585 Learning Late: 0.0010
Epoch 4: 100%|██████████| 391/391 [00:11<00:00, 34.84batch/s]
Avg Loss : 1.3221 Validation Loss : 1.3291 Learning Late: 0.0010
Epoch 5: 100%|██████████| 391/391 [00:10<00:00, 35.68batch/s]
Avg Loss : 1.3071 Validation Loss : 1.3186 Learning Late: 0.0010
Epoch 6: 100%|██████████| 391/391 [00:11<00:00, 34.40batch/s]
Avg Loss : 1.2902 Validation Loss : 1.3089 Learning Late: 0.0010
Epoch 7: 100%|██████████| 391/391 [00:11<00:00, 33.38batch/s]
Avg Loss : 1.2800 Validation Loss : 1.3084 Learning Late: 0.0010
Epoch 8: 100%|██████████| 391/391 [00:11<00:00, 33.81batch/s]
Avg Loss : 1.2696 Validation Loss : 1.2807 Learning Late: 0.0010
Epoch 9: 100%|██████████| 391/391 [00:11<00:00, 33.48batch/s]
Avg Loss : 1.2608 Validation Loss : 1.2900 Learning Late: 0.0010
Epoch 10: 100%|██████████| 391/391 [00:11<00:00, 32.59batch/s]
Avg Loss : 1.2545 Validation Loss : 1.2908 Learning Late: 0.0010
Epoch 11: 100%|██████████| 391/391 [00:12<00:00, 31.65batch/s]
Avg Loss : 1.2447 Validation Loss : 1.2856 Learning Late: 0.0010
Epoch 12: 100%|██████████| 391/391 [00:12<00:00, 31.44batch/s]
Avg Loss : 1.2399 Validation Loss : 1.2713 Learning Late: 0.0010
Epoch 13: 100%|██████████| 391/391 [00:12<00:00, 31.35batch/s]
Avg Loss : 1.2331 Validation Loss : 1.2641 Learning Late: 0.0010
Epoch 14: 100%|██████████| 391/391 [00:12<00:00, 31.36batch/s]
Avg Loss : 1.2286 Validation Loss : 1.2584 Learning Late: 0.0010
Epoch 15: 100%|██████████| 391/391 [00:12<00:00, 30.33batch/s]
Avg Loss : 1.2244 Validation Loss : 1.2599 Learning Late: 0.0010
Epoch 16: 100%|██████████| 391/391 [00:12<00:00, 31.13batch/s]
Avg Loss : 1.2177 Validation Loss : 1.2457 Learning Late: 0.0010
Epoch 17: 100%|██████████| 391/391 [00:12<00:00, 30.60batch/s]
Avg Loss : 1.2152 Validation Loss : 1.2591 Learning Late: 0.0010
Epoch 18: 100%|██████████| 391/391 [00:12<00:00, 32.41batch/s]
Avg Loss : 1.2110 Validation Loss : 1.2623 Learning Late: 0.0010
Epoch 19: 100%|██████████| 391/391 [00:11<00:00, 32.95batch/s]
Avg Loss : 1.2077 Validation Loss : 1.2379 Learning Late: 0.0010
Epoch 20: 100%|██████████| 391/391 [00:11<00:00, 34.21batch/s]
Avg Loss : 1.2049 Validation Loss : 1.2344 Learning Late: 0.0010
Epoch 21: 100%|██████████| 391/391 [00:11<00:00, 34.50batch/s]
Avg Loss : 1.2005 Validation Loss : 1.2450 Learning Late: 0.0010
Epoch 22: 100%|██████████| 391/391 [00:11<00:00, 35.24batch/s]
Avg Loss : 1.1961 Validation Loss : 1.2316 Learning Late: 0.0010
Epoch 23: 100%|██████████| 391/391 [00:11<00:00, 34.84batch/s]
Avg Loss : 1.1939 Validation Loss : 1.2420 Learning Late: 0.0010
Epoch 24: 100%|██████████| 391/391 [00:11<00:00, 34.66batch/s]
Avg Loss : 1.1921 Validation Loss : 1.2318 Learning Late: 0.0010
Epoch 25: 100%|██████████| 391/391 [00:11<00:00, 34.40batch/s]
Avg Loss : 1.1931 Validation Loss : 1.2278 Learning Late: 0.0010
Epoch 26: 100%|██████████| 391/391 [00:11<00:00, 34.64batch/s]
Avg Loss : 1.1879 Validation Loss : 1.2364 Learning Late: 0.0010
Epoch 27: 100%|██████████| 391/391 [00:11<00:00, 34.98batch/s]
Avg Loss : 1.1837 Validation Loss : 1.2225 Learning Late: 0.0010
Epoch 28: 100%|██████████| 391/391 [00:11<00:00, 34.94batch/s]
Avg Loss : 1.1841 Validation Loss : 1.2220 Learning Late: 0.0010
Epoch 29: 100%|██████████| 391/391 [00:11<00:00, 34.75batch/s]
Avg Loss : 1.1794 Validation Loss : 1.2179 Learning Late: 0.0010
Epoch 30: 100%|██████████| 391/391 [00:11<00:00, 34.89batch/s]
Avg Loss : 1.1780 Validation Loss : 1.2193 Learning Late: 0.0010
Epoch 31: 100%|██████████| 391/391 [00:11<00:00, 35.01batch/s]
Avg Loss : 1.1744 Validation Loss : 1.2101 Learning Late: 0.0010
Epoch 32: 100%|██████████| 391/391 [00:11<00:00, 34.59batch/s]
Avg Loss : 1.1761 Validation Loss : 1.2181 Learning Late: 0.0010
Epoch 33: 100%|██████████| 391/391 [00:11<00:00, 35.14batch/s]
Avg Loss : 1.1727 Validation Loss : 1.2112 Learning Late: 0.0010
Epoch 34: 100%|██████████| 391/391 [00:11<00:00, 34.90batch/s]
Avg Loss : 1.1722 Validation Loss : 1.2162 Learning Late: 0.0010
Epoch 35: 100%|██████████| 391/391 [00:11<00:00, 35.18batch/s]
Avg Loss : 1.1666 Validation Loss : 1.2125 Learning Late: 0.0010
Epoch 36: 100%|██████████| 391/391 [00:11<00:00, 32.81batch/s]
Avg Loss : 1.1677 Validation Loss : 1.2083 Learning Late: 0.0010
Epoch 37: 100%|██████████| 391/391 [00:12<00:00, 31.89batch/s]
Avg Loss : 1.1675 Validation Loss : 1.2208 Learning Late: 0.0010
Epoch 38: 100%|██████████| 391/391 [00:12<00:00, 31.73batch/s]
Avg Loss : 1.1627 Validation Loss : 1.2196 Learning Late: 0.0009
Epoch 39: 100%|██████████| 391/391 [00:11<00:00, 32.91batch/s]
Avg Loss : 1.1634 Validation Loss : 1.2132 Learning Late: 0.0009
Epoch 40: 100%|██████████| 391/391 [00:11<00:00, 33.37batch/s]
Avg Loss : 1.1612 Validation Loss : 1.2126 Learning Late: 0.0009
Epoch 41: 100%|██████████| 391/391 [00:11<00:00, 34.32batch/s]
Avg Loss : 1.1605 Validation Loss : 1.2007 Learning Late: 0.0009
Epoch 42: 100%|██████████| 391/391 [00:11<00:00, 34.32batch/s]
Avg Loss : 1.1614 Validation Loss : 1.2000 Learning Late: 0.0009
Epoch 43: 100%|██████████| 391/391 [00:11<00:00, 34.34batch/s]
Avg Loss : 1.1580 Validation Loss : 1.2165 Learning Late: 0.0009
Epoch 44: 100%|██████████| 391/391 [00:11<00:00, 33.35batch/s]
Avg Loss : 1.1584 Validation Loss : 1.2256 Learning Late: 0.0009
Epoch 45: 100%|██████████| 391/391 [00:11<00:00, 34.34batch/s]
Avg Loss : 1.1562 Validation Loss : 1.2054 Learning Late: 0.0009
Epoch 46: 100%|██████████| 391/391 [00:11<00:00, 34.58batch/s]
Avg Loss : 1.1545 Validation Loss : 1.2007 Learning Late: 0.0009
Epoch 47: 100%|██████████| 391/391 [00:11<00:00, 34.52batch/s]
Avg Loss : 1.1556 Validation Loss : 1.2001 Learning Late: 0.0009
Epoch 48: 100%|██████████| 391/391 [00:11<00:00, 34.29batch/s]
Avg Loss : 1.1525 Validation Loss : 1.2061 Learning Late: 0.0009
Epoch 49: 100%|██████████| 391/391 [00:11<00:00, 34.91batch/s]
Avg Loss : 1.1517 Validation Loss : 1.2129 Learning Late: 0.0009
Epoch 50: 100%|██████████| 391/391 [00:11<00:00, 34.58batch/s]
Avg Loss : 1.1486 Validation Loss : 1.2075 Learning Late: 0.0009
Epoch 51: 100%|██████████| 391/391 [00:11<00:00, 34.55batch/s]
Avg Loss : 1.1479 Validation Loss : 1.2041 Learning Late: 0.0009
Epoch 52: 100%|██████████| 391/391 [00:11<00:00, 34.42batch/s]
Avg Loss : 1.1468 Validation Loss : 1.2031 Learning Late: 0.0009
Epoch 53: 100%|██████████| 391/391 [00:11<00:00, 34.33batch/s]
Avg Loss : 1.1469 Validation Loss : 1.1981 Learning Late: 0.0009
Epoch 54: 100%|██████████| 391/391 [00:11<00:00, 34.60batch/s]
Avg Loss : 1.1483 Validation Loss : 1.1967 Learning Late: 0.0009
Epoch 55: 100%|██████████| 391/391 [00:11<00:00, 34.67batch/s]
Avg Loss : 1.1457 Validation Loss : 1.2028 Learning Late: 0.0009
Epoch 56: 100%|██████████| 391/391 [00:11<00:00, 34.66batch/s]
Avg Loss : 1.1440 Validation Loss : 1.1923 Learning Late: 0.0009
Epoch 57: 100%|██████████| 391/391 [00:11<00:00, 34.45batch/s]
Avg Loss : 1.1444 Validation Loss : 1.2149 Learning Late: 0.0009
Epoch 58: 100%|██████████| 391/391 [00:11<00:00, 34.53batch/s]
Avg Loss : 1.1423 Validation Loss : 1.1941 Learning Late: 0.0009
Epoch 59: 100%|██████████| 391/391 [00:11<00:00, 34.28batch/s]
Avg Loss : 1.1416 Validation Loss : 1.2005 Learning Late: 0.0008
Epoch 60: 100%|██████████| 391/391 [00:11<00:00, 34.24batch/s]
Avg Loss : 1.1419 Validation Loss : 1.2111 Learning Late: 0.0008
Epoch 61: 100%|██████████| 391/391 [00:11<00:00, 34.00batch/s]
Avg Loss : 1.1391 Validation Loss : 1.2041 Learning Late: 0.0008
Epoch 62: 100%|██████████| 391/391 [00:11<00:00, 34.54batch/s]
Avg Loss : 1.1400 Validation Loss : 1.1920 Learning Late: 0.0008
Epoch 63: 100%|██████████| 391/391 [00:11<00:00, 34.12batch/s]
Avg Loss : 1.1383 Validation Loss : 1.2003 Learning Late: 0.0008
Epoch 64: 100%|██████████| 391/391 [00:11<00:00, 34.51batch/s]
Avg Loss : 1.1366 Validation Loss : 1.1946 Learning Late: 0.0008
Epoch 65: 100%|██████████| 391/391 [00:11<00:00, 33.40batch/s]
Avg Loss : 1.1378 Validation Loss : 1.1976 Learning Late: 0.0008
Epoch 66: 100%|██████████| 391/391 [00:11<00:00, 34.45batch/s]
Avg Loss : 1.1374 Validation Loss : 1.2046 Learning Late: 0.0008
Epoch 67: 100%|██████████| 391/391 [00:11<00:00, 33.76batch/s]
Avg Loss : 1.1347 Validation Loss : 1.1987 Learning Late: 0.0008
Epoch 68: 100%|██████████| 391/391 [00:11<00:00, 34.13batch/s]
Avg Loss : 1.1357 Validation Loss : 1.2013 Learning Late: 0.0008
Epoch 69: 100%|██████████| 391/391 [00:12<00:00, 32.54batch/s]
Avg Loss : 1.1339 Validation Loss : 1.1986 Learning Late: 0.0008
Epoch 70: 100%|██████████| 391/391 [00:11<00:00, 33.74batch/s]
Avg Loss : 1.1339 Validation Loss : 1.1860 Learning Late: 0.0008
Epoch 71: 100%|██████████| 391/391 [00:11<00:00, 33.60batch/s]
Avg Loss : 1.1326 Validation Loss : 1.1961 Learning Late: 0.0008
Epoch 72: 100%|██████████| 391/391 [00:11<00:00, 33.82batch/s]
Avg Loss : 1.1334 Validation Loss : 1.2028 Learning Late: 0.0008
Epoch 73: 100%|██████████| 391/391 [00:11<00:00, 33.13batch/s]
Avg Loss : 1.1306 Validation Loss : 1.1966 Learning Late: 0.0008
Epoch 74: 100%|██████████| 391/391 [00:11<00:00, 33.58batch/s]
Avg Loss : 1.1311 Validation Loss : 1.1987 Learning Late: 0.0007
Epoch 75: 100%|██████████| 391/391 [00:11<00:00, 33.33batch/s]
Avg Loss : 1.1299 Validation Loss : 1.1937 Learning Late: 0.0007
Epoch 76: 100%|██████████| 391/391 [00:11<00:00, 33.46batch/s]
Avg Loss : 1.1298 Validation Loss : 1.1954 Learning Late: 0.0007
Epoch 77: 100%|██████████| 391/391 [00:11<00:00, 32.84batch/s]
Avg Loss : 1.1284 Validation Loss : 1.1877 Learning Late: 0.0007
Epoch 78: 100%|██████████| 391/391 [00:11<00:00, 33.98batch/s]
Avg Loss : 1.1282 Validation Loss : 1.1893 Learning Late: 0.0007
Epoch 79: 100%|██████████| 391/391 [00:11<00:00, 33.72batch/s]
Avg Loss : 1.1272 Validation Loss : 1.1831 Learning Late: 0.0007
Epoch 80: 100%|██████████| 391/391 [00:11<00:00, 33.99batch/s]
Avg Loss : 1.1267 Validation Loss : 1.1984 Learning Late: 0.0007
Epoch 81: 100%|██████████| 391/391 [00:11<00:00, 33.86batch/s]
Avg Loss : 1.1275 Validation Loss : 1.1987 Learning Late: 0.0007
Epoch 82: 100%|██████████| 391/391 [00:11<00:00, 34.34batch/s]
Avg Loss : 1.1265 Validation Loss : 1.1894 Learning Late: 0.0007
Epoch 83: 100%|██████████| 391/391 [00:11<00:00, 33.87batch/s]
Avg Loss : 1.1252 Validation Loss : 1.1960 Learning Late: 0.0007
Epoch 84: 100%|██████████| 391/391 [00:11<00:00, 33.41batch/s]
Avg Loss : 1.1267 Validation Loss : 1.1858 Learning Late: 0.0007
Epoch 85: 100%|██████████| 391/391 [00:11<00:00, 34.27batch/s]
Avg Loss : 1.1238 Validation Loss : 1.1984 Learning Late: 0.0007
Epoch 86: 100%|██████████| 391/391 [00:11<00:00, 33.87batch/s]
Avg Loss : 1.1244 Validation Loss : 1.1869 Learning Late: 0.0007
Epoch 87: 100%|██████████| 391/391 [00:11<00:00, 33.66batch/s]
Avg Loss : 1.1229 Validation Loss : 1.1909 Learning Late: 0.0006
Epoch 88: 100%|██████████| 391/391 [00:11<00:00, 33.86batch/s]
Avg Loss : 1.1233 Validation Loss : 1.1853 Learning Late: 0.0006
Epoch 89: 100%|██████████| 391/391 [00:11<00:00, 34.34batch/s]
Avg Loss : 1.1213 Validation Loss : 1.1912 Learning Late: 0.0006
Epoch 90: 100%|██████████| 391/391 [00:11<00:00, 33.36batch/s]
Avg Loss : 1.1222 Validation Loss : 1.1851 Learning Late: 0.0006
Epoch 91: 100%|██████████| 391/391 [00:11<00:00, 34.05batch/s]
Avg Loss : 1.1223 Validation Loss : 1.1909 Learning Late: 0.0006
Epoch 92: 100%|██████████| 391/391 [00:11<00:00, 33.81batch/s]
Avg Loss : 1.1216 Validation Loss : 1.1847 Learning Late: 0.0006
Epoch 93: 100%|██████████| 391/391 [00:11<00:00, 33.98batch/s]
Avg Loss : 1.1202 Validation Loss : 1.1838 Learning Late: 0.0006
Epoch 94: 100%|██████████| 391/391 [00:11<00:00, 33.12batch/s]
Avg Loss : 1.1209 Validation Loss : 1.1845 Learning Late: 0.0006
Epoch 95: 100%|██████████| 391/391 [00:11<00:00, 33.98batch/s]
Avg Loss : 1.1197 Validation Loss : 1.1765 Learning Late: 0.0006
Epoch 96: 100%|██████████| 391/391 [00:11<00:00, 33.17batch/s]
Avg Loss : 1.1182 Validation Loss : 1.1899 Learning Late: 0.0006
Epoch 97: 100%|██████████| 391/391 [00:11<00:00, 33.40batch/s]
Avg Loss : 1.1187 Validation Loss : 1.1805 Learning Late: 0.0006
Epoch 98: 100%|██████████| 391/391 [00:11<00:00, 32.94batch/s]
Avg Loss : 1.1189 Validation Loss : 1.1832 Learning Late: 0.0006
Epoch 99: 100%|██████████| 391/391 [00:11<00:00, 33.59batch/s]
Avg Loss : 1.1172 Validation Loss : 1.1809 Learning Late: 0.0005
Epoch 100: 100%|██████████| 391/391 [00:11<00:00, 33.36batch/s]
Avg Loss : 1.1170 Validation Loss : 1.1959 Learning Late: 0.0005
Epoch 101: 100%|██████████| 391/391 [00:11<00:00, 33.79batch/s]
Avg Loss : 1.1166 Validation Loss : 1.1848 Learning Late: 0.0005
Epoch 102: 100%|██████████| 391/391 [00:11<00:00, 32.84batch/s]
Avg Loss : 1.1162 Validation Loss : 1.1780 Learning Late: 0.0005
Epoch 103: 100%|██████████| 391/391 [00:11<00:00, 33.59batch/s]
Avg Loss : 1.1163 Validation Loss : 1.1817 Learning Late: 0.0005
Epoch 104: 100%|██████████| 391/391 [00:11<00:00, 33.26batch/s]
Avg Loss : 1.1149 Validation Loss : 1.1825 Learning Late: 0.0005
Epoch 105: 100%|██████████| 391/391 [00:11<00:00, 33.48batch/s]
Avg Loss : 1.1152 Validation Loss : 1.1893 Learning Late: 0.0005
Epoch 106: 100%|██████████| 391/391 [00:11<00:00, 33.70batch/s]
Avg Loss : 1.1141 Validation Loss : 1.1824 Learning Late: 0.0005
Epoch 107: 100%|██████████| 391/391 [00:11<00:00, 34.26batch/s]
Avg Loss : 1.1141 Validation Loss : 1.1859 Learning Late: 0.0005
Epoch 108: 100%|██████████| 391/391 [00:11<00:00, 34.10batch/s]
Avg Loss : 1.1128 Validation Loss : 1.1716 Learning Late: 0.0005
Epoch 109: 100%|██████████| 391/391 [00:11<00:00, 33.36batch/s]
Avg Loss : 1.1126 Validation Loss : 1.1869 Learning Late: 0.0005
Epoch 110: 100%|██████████| 391/391 [00:11<00:00, 32.68batch/s]
Avg Loss : 1.1120 Validation Loss : 1.1776 Learning Late: 0.0005
Epoch 111: 100%|██████████| 391/391 [00:11<00:00, 33.24batch/s]
Avg Loss : 1.1124 Validation Loss : 1.1866 Learning Late: 0.0005
Epoch 112: 100%|██████████| 391/391 [00:11<00:00, 33.81batch/s]
Avg Loss : 1.1122 Validation Loss : 1.1809 Learning Late: 0.0004
Epoch 113: 100%|██████████| 391/391 [00:11<00:00, 33.05batch/s]
Avg Loss : 1.1117 Validation Loss : 1.1849 Learning Late: 0.0004
Epoch 114: 100%|██████████| 391/391 [00:11<00:00, 33.63batch/s]
Avg Loss : 1.1116 Validation Loss : 1.1768 Learning Late: 0.0004
Epoch 115: 100%|██████████| 391/391 [00:11<00:00, 33.08batch/s]
Avg Loss : 1.1098 Validation Loss : 1.1738 Learning Late: 0.0004
Epoch 116: 100%|██████████| 391/391 [00:11<00:00, 33.48batch/s]
Avg Loss : 1.1097 Validation Loss : 1.1762 Learning Late: 0.0004
Epoch 117: 100%|██████████| 391/391 [00:11<00:00, 33.48batch/s]
Avg Loss : 1.1102 Validation Loss : 1.1858 Learning Late: 0.0004
Epoch 118: 100%|██████████| 391/391 [00:11<00:00, 32.63batch/s]
Avg Loss : 1.1098 Validation Loss : 1.1754 Learning Late: 0.0004
Epoch 119: 100%|██████████| 391/391 [00:11<00:00, 32.82batch/s]
Avg Loss : 1.1092 Validation Loss : 1.1831 Learning Late: 0.0004
Epoch 120: 100%|██████████| 391/391 [00:11<00:00, 32.93batch/s]
Avg Loss : 1.1085 Validation Loss : 1.1769 Learning Late: 0.0004
Epoch 121: 100%|██████████| 391/391 [00:12<00:00, 32.46batch/s]
Avg Loss : 1.1081 Validation Loss : 1.1782 Learning Late: 0.0004
Epoch 122: 100%|██████████| 391/391 [00:12<00:00, 32.45batch/s]
Avg Loss : 1.1087 Validation Loss : 1.1783 Learning Late: 0.0004
Epoch 123: 100%|██████████| 391/391 [00:11<00:00, 32.60batch/s]
Avg Loss : 1.1073 Validation Loss : 1.1703 Learning Late: 0.0004
Epoch 124: 100%|██████████| 391/391 [00:11<00:00, 32.72batch/s]
Avg Loss : 1.1074 Validation Loss : 1.1742 Learning Late: 0.0003
Epoch 125: 100%|██████████| 391/391 [00:12<00:00, 32.26batch/s]
Avg Loss : 1.1074 Validation Loss : 1.1715 Learning Late: 0.0003
Epoch 126: 100%|██████████| 391/391 [00:12<00:00, 32.47batch/s]
Avg Loss : 1.1063 Validation Loss : 1.1807 Learning Late: 0.0003
Epoch 127: 100%|██████████| 391/391 [00:11<00:00, 32.65batch/s]
Avg Loss : 1.1055 Validation Loss : 1.1709 Learning Late: 0.0003
Epoch 128: 100%|██████████| 391/391 [00:11<00:00, 33.33batch/s]
Avg Loss : 1.1056 Validation Loss : 1.1788 Learning Late: 0.0003
Epoch 129: 100%|██████████| 391/391 [00:11<00:00, 32.60batch/s]
Avg Loss : 1.1064 Validation Loss : 1.1765 Learning Late: 0.0003
Epoch 130: 100%|██████████| 391/391 [00:11<00:00, 32.67batch/s]
Avg Loss : 1.1053 Validation Loss : 1.1742 Learning Late: 0.0003
Epoch 131: 100%|██████████| 391/391 [00:11<00:00, 32.77batch/s]
Avg Loss : 1.1054 Validation Loss : 1.1718 Learning Late: 0.0003
Epoch 132: 100%|██████████| 391/391 [00:11<00:00, 32.63batch/s]
Avg Loss : 1.1040 Validation Loss : 1.1752 Learning Late: 0.0003
Epoch 133: 100%|██████████| 391/391 [00:12<00:00, 32.47batch/s]
Avg Loss : 1.1044 Validation Loss : 1.1679 Learning Late: 0.0003
Epoch 134: 100%|██████████| 391/391 [00:11<00:00, 33.05batch/s]
Avg Loss : 1.1037 Validation Loss : 1.1806 Learning Late: 0.0003
Epoch 135: 100%|██████████| 391/391 [00:11<00:00, 33.04batch/s]
Avg Loss : 1.1034 Validation Loss : 1.1812 Learning Late: 0.0003
Epoch 136: 100%|██████████| 391/391 [00:11<00:00, 33.50batch/s]
Avg Loss : 1.1030 Validation Loss : 1.1690 Learning Late: 0.0003
Epoch 137: 100%|██████████| 391/391 [00:11<00:00, 33.01batch/s]
Avg Loss : 1.1028 Validation Loss : 1.1713 Learning Late: 0.0002
Epoch 138: 100%|██████████| 391/391 [00:11<00:00, 33.30batch/s]
Avg Loss : 1.1030 Validation Loss : 1.1767 Learning Late: 0.0002
Epoch 139: 100%|██████████| 391/391 [00:11<00:00, 32.94batch/s]
Avg Loss : 1.1028 Validation Loss : 1.1706 Learning Late: 0.0002
Epoch 140: 100%|██████████| 391/391 [00:11<00:00, 33.17batch/s]
Avg Loss : 1.1025 Validation Loss : 1.1748 Learning Late: 0.0002
Epoch 141: 100%|██████████| 391/391 [00:11<00:00, 32.98batch/s]
Avg Loss : 1.1020 Validation Loss : 1.1742 Learning Late: 0.0002
Epoch 142: 100%|██████████| 391/391 [00:11<00:00, 32.88batch/s]
Avg Loss : 1.1014 Validation Loss : 1.1742 Learning Late: 0.0002
Epoch 143: 100%|██████████| 391/391 [00:12<00:00, 32.33batch/s]
Avg Loss : 1.1012 Validation Loss : 1.1730 Learning Late: 0.0002
Epoch 144: 100%|██████████| 391/391 [00:11<00:00, 32.62batch/s]
Avg Loss : 1.1007 Validation Loss : 1.1685 Learning Late: 0.0002
Epoch 145: 100%|██████████| 391/391 [00:11<00:00, 32.79batch/s]
Avg Loss : 1.1008 Validation Loss : 1.1693 Learning Late: 0.0002
Epoch 146: 100%|██████████| 391/391 [00:11<00:00, 33.21batch/s]
Avg Loss : 1.1004 Validation Loss : 1.1709 Learning Late: 0.0002
Epoch 147: 100%|██████████| 391/391 [00:12<00:00, 32.35batch/s]
Avg Loss : 1.1002 Validation Loss : 1.1711 Learning Late: 0.0002
Epoch 148: 100%|██████████| 391/391 [00:12<00:00, 32.39batch/s]
Avg Loss : 1.0997 Validation Loss : 1.1749 Learning Late: 0.0002
Epoch 149: 100%|██████████| 391/391 [00:11<00:00, 32.85batch/s]
Avg Loss : 1.0996 Validation Loss : 1.1675 Learning Late: 0.0002
Epoch 150: 100%|██████████| 391/391 [00:12<00:00, 32.44batch/s]
Avg Loss : 1.1003 Validation Loss : 1.1667 Learning Late: 0.0002
Epoch 151: 100%|██████████| 391/391 [00:12<00:00, 31.83batch/s]
Avg Loss : 1.0993 Validation Loss : 1.1779 Learning Late: 0.0002
Epoch 152: 100%|██████████| 391/391 [00:11<00:00, 32.67batch/s]
Avg Loss : 1.0990 Validation Loss : 1.1694 Learning Late: 0.0001
Epoch 153: 100%|██████████| 391/391 [00:11<00:00, 32.78batch/s]
Avg Loss : 1.0988 Validation Loss : 1.1678 Learning Late: 0.0001
Epoch 154: 100%|██████████| 391/391 [00:12<00:00, 32.30batch/s]
Avg Loss : 1.0984 Validation Loss : 1.1774 Learning Late: 0.0001
Epoch 155: 100%|██████████| 391/391 [00:12<00:00, 32.34batch/s]
Avg Loss : 1.0982 Validation Loss : 1.1726 Learning Late: 0.0001
Epoch 156: 100%|██████████| 391/391 [00:12<00:00, 32.57batch/s]
Avg Loss : 1.0982 Validation Loss : 1.1725 Learning Late: 0.0001
Epoch 157: 100%|██████████| 391/391 [00:11<00:00, 32.79batch/s]
Avg Loss : 1.0975 Validation Loss : 1.1674 Learning Late: 0.0001
Epoch 158: 100%|██████████| 391/391 [00:12<00:00, 32.58batch/s]
Avg Loss : 1.0976 Validation Loss : 1.1777 Learning Late: 0.0001
Epoch 159: 100%|██████████| 391/391 [00:12<00:00, 32.49batch/s]
Avg Loss : 1.0977 Validation Loss : 1.1728 Learning Late: 0.0001
Epoch 160: 100%|██████████| 391/391 [00:12<00:00, 32.15batch/s]
Avg Loss : 1.0976 Validation Loss : 1.1758 Learning Late: 0.0001
Epoch 161: 100%|██████████| 391/391 [00:11<00:00, 32.62batch/s]
Avg Loss : 1.0970 Validation Loss : 1.1689 Learning Late: 0.0001
Epoch 162: 100%|██████████| 391/391 [00:12<00:00, 32.45batch/s]
Avg Loss : 1.0966 Validation Loss : 1.1710 Learning Late: 0.0001
Epoch 163: 100%|██████████| 391/391 [00:11<00:00, 32.78batch/s]
Avg Loss : 1.0962 Validation Loss : 1.1687 Learning Late: 0.0001
Epoch 164: 100%|██████████| 391/391 [00:12<00:00, 32.49batch/s]
Avg Loss : 1.0966 Validation Loss : 1.1671 Learning Late: 0.0001
Epoch 165: 100%|██████████| 391/391 [00:11<00:00, 32.86batch/s]
Avg Loss : 1.0964 Validation Loss : 1.1726 Learning Late: 0.0001
Epoch 166: 100%|██████████| 391/391 [00:12<00:00, 32.38batch/s]
Avg Loss : 1.0961 Validation Loss : 1.1693 Learning Late: 0.0001
Epoch 167: 100%|██████████| 391/391 [00:11<00:00, 32.59batch/s]
Avg Loss : 1.0957 Validation Loss : 1.1736 Learning Late: 0.0001
Epoch 168: 100%|██████████| 391/391 [00:12<00:00, 32.32batch/s]
Avg Loss : 1.0953 Validation Loss : 1.1730 Learning Late: 0.0001
Epoch 169: 100%|██████████| 391/391 [00:11<00:00, 32.70batch/s]
Avg Loss : 1.0955 Validation Loss : 1.1705 Learning Late: 0.0001
Epoch 170: 100%|██████████| 391/391 [00:12<00:00, 32.35batch/s]
Avg Loss : 1.0954 Validation Loss : 1.1697 Learning Late: 0.0001
Epoch 171: 100%|██████████| 391/391 [00:12<00:00, 31.81batch/s]
Avg Loss : 1.0948 Validation Loss : 1.1780 Learning Late: 0.0001
Epoch 172: 100%|██████████| 391/391 [00:12<00:00, 32.21batch/s]
Avg Loss : 1.0949 Validation Loss : 1.1684 Learning Late: 0.0001
Epoch 173: 100%|██████████| 391/391 [00:11<00:00, 32.74batch/s]
Avg Loss : 1.0948 Validation Loss : 1.1717 Learning Late: 0.0000
Epoch 174: 100%|██████████| 391/391 [00:12<00:00, 32.02batch/s]
Avg Loss : 1.0947 Validation Loss : 1.1744 Learning Late: 0.0000
Epoch 175: 100%|██████████| 391/391 [00:12<00:00, 32.19batch/s]
Avg Loss : 1.0945 Validation Loss : 1.1671 Learning Late: 0.0000
Epoch 176: 100%|██████████| 391/391 [00:12<00:00, 32.02batch/s]
Avg Loss : 1.0945 Validation Loss : 1.1671 Learning Late: 0.0000
Epoch 177: 100%|██████████| 391/391 [00:11<00:00, 32.84batch/s]
Avg Loss : 1.0943 Validation Loss : 1.1668 Learning Late: 0.0000
Epoch 178: 100%|██████████| 391/391 [00:11<00:00, 32.65batch/s]
Avg Loss : 1.0941 Validation Loss : 1.1680 Learning Late: 0.0000
Epoch 179: 100%|██████████| 391/391 [00:12<00:00, 32.22batch/s]
Avg Loss : 1.0940 Validation Loss : 1.1645 Learning Late: 0.0000
Epoch 180: 100%|██████████| 391/391 [00:12<00:00, 31.92batch/s]
Avg Loss : 1.0939 Validation Loss : 1.1669 Learning Late: 0.0000
Epoch 181: 100%|██████████| 391/391 [00:12<00:00, 32.30batch/s]
Avg Loss : 1.0939 Validation Loss : 1.1686 Learning Late: 0.0000
Epoch 182: 100%|██████████| 391/391 [00:12<00:00, 32.03batch/s]
Avg Loss : 1.0939 Validation Loss : 1.1673 Learning Late: 0.0000
Epoch 183: 100%|██████████| 391/391 [00:12<00:00, 31.76batch/s]
Avg Loss : 1.0936 Validation Loss : 1.1697 Learning Late: 0.0000
Epoch 184: 100%|██████████| 391/391 [00:12<00:00, 32.04batch/s]
Avg Loss : 1.0934 Validation Loss : 1.1716 Learning Late: 0.0000
Epoch 185: 100%|██████████| 391/391 [00:12<00:00, 31.86batch/s]
Avg Loss : 1.0933 Validation Loss : 1.1713 Learning Late: 0.0000
Epoch 186: 100%|██████████| 391/391 [00:12<00:00, 32.02batch/s]
Avg Loss : 1.0933 Validation Loss : 1.1680 Learning Late: 0.0000
Epoch 187: 100%|██████████| 391/391 [00:12<00:00, 31.75batch/s]
Avg Loss : 1.0931 Validation Loss : 1.1654 Learning Late: 0.0000
Epoch 188: 100%|██████████| 391/391 [00:12<00:00, 31.90batch/s]
Avg Loss : 1.0933 Validation Loss : 1.1698 Learning Late: 0.0000
Epoch 189: 100%|██████████| 391/391 [00:12<00:00, 32.00batch/s]
Avg Loss : 1.0930 Validation Loss : 1.1687 Learning Late: 0.0000
Epoch 190: 100%|██████████| 391/391 [00:12<00:00, 31.76batch/s]
Avg Loss : 1.0931 Validation Loss : 1.1659 Learning Late: 0.0000
Epoch 191: 100%|██████████| 391/391 [00:12<00:00, 31.24batch/s]
Avg Loss : 1.0931 Validation Loss : 1.1722 Learning Late: 0.0000
Epoch 192: 100%|██████████| 391/391 [00:12<00:00, 32.41batch/s]
Avg Loss : 1.0930 Validation Loss : 1.1698 Learning Late: 0.0000
Epoch 193: 100%|██████████| 391/391 [00:12<00:00, 32.22batch/s]
Avg Loss : 1.0930 Validation Loss : 1.1694 Learning Late: 0.0000
Epoch 194: 100%|██████████| 391/391 [00:12<00:00, 31.57batch/s]
Avg Loss : 1.0929 Validation Loss : 1.1795 Learning Late: 0.0000
Epoch 195: 100%|██████████| 391/391 [00:12<00:00, 31.89batch/s]
Avg Loss : 1.0929 Validation Loss : 1.1694 Learning Late: 0.0000
Epoch 196: 100%|██████████| 391/391 [00:12<00:00, 31.94batch/s]
Avg Loss : 1.0929 Validation Loss : 1.1691 Learning Late: 0.0000
Epoch 197: 100%|██████████| 391/391 [00:12<00:00, 32.13batch/s]
Avg Loss : 1.0928 Validation Loss : 1.1703 Learning Late: 0.0000
Epoch 198: 100%|██████████| 391/391 [00:12<00:00, 32.09batch/s]
Avg Loss : 1.0929 Validation Loss : 1.1630 Learning Late: 0.0000
Epoch 199: 100%|██████████| 391/391 [00:12<00:00, 31.91batch/s]
Avg Loss : 1.0926 Validation Loss : 1.1712 Learning Late: 0.0000
Epoch 200: 100%|██████████| 391/391 [00:12<00:00, 32.03batch/s]
Avg Loss : 1.0926 Validation Loss : 1.1726 Learning Late: 0.0000
실제 test
100%|██████████| 79/79 [00:02<00:00, 39.06batch/s]
총 개수 : 10000
top-1 맞춘 개수 : 5849 
 정확도: 58.49
top-5 맞춘 개수 : 9537 
 정확도: 95.37
Files already downloaded and verified
Files already downloaded and verified
Epoch 1: 100%|██████████| 98/98 [00:37<00:00,  2.62batch/s]
Avg Loss : 6.7488 Validation Loss : 6.3521 Learning Late: 1.6971
Epoch 2: 100%|██████████| 98/98 [00:37<00:00,  2.63batch/s]
Avg Loss : 6.3457 Validation Loss : 6.2658 Learning Late: 1.6971
Epoch 3: 100%|██████████| 98/98 [00:37<00:00,  2.58batch/s]
Avg Loss : 6.2789 Validation Loss : 6.0655 Learning Late: 1.6971
Epoch 4: 100%|██████████| 98/98 [00:37<00:00,  2.58batch/s]
Avg Loss : 6.2324 Validation Loss : 6.1047 Learning Late: 1.6971
Epoch 5: 100%|██████████| 98/98 [00:37<00:00,  2.61batch/s]
Avg Loss : 6.1951 Validation Loss : 6.2775 Learning Late: 1.6971
Epoch 6: 100%|██████████| 98/98 [00:37<00:00,  2.62batch/s]
Avg Loss : 5.8657 Validation Loss : 5.6034 Learning Late: 1.6971
Epoch 7: 100%|██████████| 98/98 [00:37<00:00,  2.58batch/s]
Avg Loss : 5.5469 Validation Loss : 5.6035 Learning Late: 1.6971
Epoch 8: 100%|██████████| 98/98 [00:37<00:00,  2.58batch/s]
Avg Loss : 5.4719 Validation Loss : 5.4408 Learning Late: 1.6971
Epoch 9: 100%|██████████| 98/98 [00:37<00:00,  2.59batch/s]
Avg Loss : 5.4322 Validation Loss : 5.4826 Learning Late: 1.6971
Epoch 10: 100%|██████████| 98/98 [00:37<00:00,  2.61batch/s]
Avg Loss : 5.4336 Validation Loss : 5.3477 Learning Late: 1.6971
Epoch 11: 100%|██████████| 98/98 [00:37<00:00,  2.59batch/s]
Avg Loss : 5.3696 Validation Loss : 5.4127 Learning Late: 1.6965
Epoch 12: 100%|██████████| 98/98 [00:38<00:00,  2.57batch/s]
Avg Loss : 5.2390 Validation Loss : 5.2356 Learning Late: 1.6950
Epoch 13: 100%|██████████| 98/98 [00:37<00:00,  2.60batch/s]
Avg Loss : 5.0796 Validation Loss : 4.7065 Learning Late: 1.6924
Epoch 14: 100%|██████████| 98/98 [00:37<00:00,  2.62batch/s]
Avg Loss : 4.7027 Validation Loss : 4.6492 Learning Late: 1.6888
Epoch 15: 100%|██████████| 98/98 [00:37<00:00,  2.62batch/s]
Avg Loss : 4.4373 Validation Loss : 4.2390 Learning Late: 1.6842
Epoch 16: 100%|██████████| 98/98 [00:38<00:00,  2.57batch/s]
Avg Loss : 4.4745 Validation Loss : 4.3682 Learning Late: 1.6785
Epoch 17: 100%|██████████| 98/98 [00:37<00:00,  2.58batch/s]
Avg Loss : 4.4861 Validation Loss : 4.2653 Learning Late: 1.6719
Epoch 18: 100%|██████████| 98/98 [00:37<00:00,  2.61batch/s]
Avg Loss : 4.2376 Validation Loss : 4.2270 Learning Late: 1.6642
Epoch 19: 100%|██████████| 98/98 [00:37<00:00,  2.60batch/s]
Avg Loss : 4.2977 Validation Loss : 4.0149 Learning Late: 1.6555
Epoch 20: 100%|██████████| 98/98 [00:38<00:00,  2.56batch/s]
Avg Loss : 4.2468 Validation Loss : 4.1045 Learning Late: 1.6459
Epoch 21: 100%|██████████| 98/98 [00:38<00:00,  2.55batch/s]
Avg Loss : 4.1420 Validation Loss : 4.1342 Learning Late: 1.6353
Epoch 22: 100%|██████████| 98/98 [00:38<00:00,  2.56batch/s]
Avg Loss : 4.1418 Validation Loss : 3.8952 Learning Late: 1.6237
Epoch 23: 100%|██████████| 98/98 [00:37<00:00,  2.59batch/s]
Avg Loss : 4.0692 Validation Loss : 4.2645 Learning Late: 1.6112
Epoch 24: 100%|██████████| 98/98 [00:37<00:00,  2.60batch/s]
Avg Loss : 4.1285 Validation Loss : 3.9118 Learning Late: 1.5977
Epoch 25: 100%|██████████| 98/98 [00:38<00:00,  2.55batch/s]
Avg Loss : 4.0180 Validation Loss : 3.9599 Learning Late: 1.5834
Epoch 26: 100%|██████████| 98/98 [00:38<00:00,  2.57batch/s]
Avg Loss : 4.1618 Validation Loss : 4.0239 Learning Late: 1.5681
Epoch 27: 100%|██████████| 98/98 [00:37<00:00,  2.60batch/s]
Avg Loss : 4.0277 Validation Loss : 4.1879 Learning Late: 1.5520
Epoch 28: 100%|██████████| 98/98 [00:37<00:00,  2.60batch/s]
Avg Loss : 3.9162 Validation Loss : 3.9181 Learning Late: 1.5350
Epoch 29: 100%|██████████| 98/98 [00:38<00:00,  2.56batch/s]
Avg Loss : 3.9177 Validation Loss : 3.4321 Learning Late: 1.5172
Epoch 30: 100%|██████████| 98/98 [00:38<00:00,  2.57batch/s]
Avg Loss : 3.6208 Validation Loss : 3.5350 Learning Late: 1.4985
Epoch 31: 100%|██████████| 98/98 [00:37<00:00,  2.60batch/s]
Avg Loss : 3.5110 Validation Loss : 3.2864 Learning Late: 1.4791
Epoch 32: 100%|██████████| 98/98 [00:37<00:00,  2.60batch/s]
Avg Loss : 3.4065 Validation Loss : 3.3201 Learning Late: 1.4589
Epoch 33: 100%|██████████| 98/98 [00:37<00:00,  2.59batch/s]
Avg Loss : 3.2399 Validation Loss : 3.0532 Learning Late: 1.4380
Epoch 34: 100%|██████████| 98/98 [00:38<00:00,  2.54batch/s]
Avg Loss : 2.9902 Validation Loss : 2.9430 Learning Late: 1.4163
Epoch 35: 100%|██████████| 98/98 [00:38<00:00,  2.56batch/s]
Avg Loss : 2.7105 Validation Loss : 2.5603 Learning Late: 1.3940
Epoch 36: 100%|██████████| 98/98 [00:38<00:00,  2.55batch/s]
Avg Loss : 2.6404 Validation Loss : 2.4283 Learning Late: 1.3709
Epoch 37: 100%|██████████| 98/98 [00:38<00:00,  2.56batch/s]
Avg Loss : 2.2798 Validation Loss : 2.7682 Learning Late: 1.3473
Epoch 38: 100%|██████████| 98/98 [00:37<00:00,  2.62batch/s]
Avg Loss : 2.2521 Validation Loss : 2.2572 Learning Late: 1.3230
Epoch 39: 100%|██████████| 98/98 [00:38<00:00,  2.58batch/s]
Avg Loss : 2.0368 Validation Loss : 1.9932 Learning Late: 1.2982
Epoch 40: 100%|██████████| 98/98 [00:37<00:00,  2.58batch/s]
Avg Loss : 2.0284 Validation Loss : 2.1296 Learning Late: 1.2728
Epoch 41: 100%|██████████| 98/98 [00:37<00:00,  2.61batch/s]
Avg Loss : 1.9831 Validation Loss : 1.9481 Learning Late: 1.2469
Epoch 42: 100%|██████████| 98/98 [00:37<00:00,  2.62batch/s]
Avg Loss : 1.9392 Validation Loss : 1.8295 Learning Late: 1.2205
Epoch 43: 100%|██████████| 98/98 [00:37<00:00,  2.58batch/s]
Avg Loss : 1.8390 Validation Loss : 1.8107 Learning Late: 1.1937
Epoch 44: 100%|██████████| 98/98 [00:38<00:00,  2.58batch/s]
Avg Loss : 1.8345 Validation Loss : 1.5591 Learning Late: 1.1664
Epoch 45: 100%|██████████| 98/98 [00:37<00:00,  2.60batch/s]
Avg Loss : 1.7392 Validation Loss : 1.5934 Learning Late: 1.1387
Epoch 46: 100%|██████████| 98/98 [00:37<00:00,  2.60batch/s]
Avg Loss : 1.7588 Validation Loss : 1.7010 Learning Late: 1.1107
Epoch 47: 100%|██████████| 98/98 [00:38<00:00,  2.57batch/s]
Avg Loss : 1.5883 Validation Loss : 1.4438 Learning Late: 1.0824
Epoch 48: 100%|██████████| 98/98 [00:37<00:00,  2.58batch/s]
Avg Loss : 1.4713 Validation Loss : 1.4720 Learning Late: 1.0538
Epoch 49: 100%|██████████| 98/98 [00:37<00:00,  2.60batch/s]
Avg Loss : 1.3051 Validation Loss : 1.4309 Learning Late: 1.0249
Epoch 50: 100%|██████████| 98/98 [00:37<00:00,  2.62batch/s]
Avg Loss : 1.3001 Validation Loss : 1.1465 Learning Late: 0.9959
Epoch 51: 100%|██████████| 98/98 [00:38<00:00,  2.58batch/s]
Avg Loss : 1.3244 Validation Loss : 1.3936 Learning Late: 0.9666
Epoch 52: 100%|██████████| 98/98 [00:38<00:00,  2.57batch/s]
Avg Loss : 1.2063 Validation Loss : 1.1546 Learning Late: 0.9372
Epoch 53: 100%|██████████| 98/98 [00:37<00:00,  2.61batch/s]
Avg Loss : 1.1464 Validation Loss : 1.1259 Learning Late: 0.9077
Epoch 54: 100%|██████████| 98/98 [00:37<00:00,  2.61batch/s]
Avg Loss : 1.2335 Validation Loss : 1.0645 Learning Late: 0.8781
Epoch 55: 100%|██████████| 98/98 [00:38<00:00,  2.57batch/s]
Avg Loss : 1.1348 Validation Loss : 1.0619 Learning Late: 0.8485
Epoch 56: 100%|██████████| 98/98 [00:38<00:00,  2.57batch/s]
Avg Loss : 1.1542 Validation Loss : 1.2089 Learning Late: 0.8189
Epoch 57: 100%|██████████| 98/98 [00:37<00:00,  2.58batch/s]
Avg Loss : 1.1009 Validation Loss : 1.0068 Learning Late: 0.7893
Epoch 58: 100%|██████████| 98/98 [00:37<00:00,  2.59batch/s]
Avg Loss : 1.0551 Validation Loss : 0.8651 Learning Late: 0.7598
Epoch 59: 100%|██████████| 98/98 [00:37<00:00,  2.61batch/s]
Avg Loss : 0.9784 Validation Loss : 0.8809 Learning Late: 0.7304
Epoch 60: 100%|██████████| 98/98 [00:38<00:00,  2.57batch/s]
Avg Loss : 0.9958 Validation Loss : 1.1599 Learning Late: 0.7012
Epoch 61: 100%|██████████| 98/98 [00:37<00:00,  2.58batch/s]
Avg Loss : 1.0094 Validation Loss : 0.9225 Learning Late: 0.6721
Epoch 62: 100%|██████████| 98/98 [00:37<00:00,  2.59batch/s]
Avg Loss : 0.8803 Validation Loss : 0.9095 Learning Late: 0.6433
Epoch 63: 100%|██████████| 98/98 [00:37<00:00,  2.61batch/s]
Avg Loss : 0.9420 Validation Loss : 0.9481 Learning Late: 0.6146
Epoch 64: 100%|██████████| 98/98 [00:38<00:00,  2.57batch/s]
Avg Loss : 0.8297 Validation Loss : 0.8119 Learning Late: 0.5863
Epoch 65: 100%|██████████| 98/98 [00:38<00:00,  2.57batch/s]
Avg Loss : 0.8801 Validation Loss : 0.8071 Learning Late: 0.5583
Epoch 66: 100%|██████████| 98/98 [00:37<00:00,  2.61batch/s]
Avg Loss : 0.8266 Validation Loss : 0.8867 Learning Late: 0.5307
Epoch 67: 100%|██████████| 98/98 [00:37<00:00,  2.62batch/s]
Avg Loss : 0.7944 Validation Loss : 0.8211 Learning Late: 0.5034
Epoch 68: 100%|██████████| 98/98 [00:38<00:00,  2.57batch/s]
Avg Loss : 0.7574 Validation Loss : 0.8390 Learning Late: 0.4766
Epoch 69: 100%|██████████| 98/98 [00:38<00:00,  2.57batch/s]
Avg Loss : 0.7956 Validation Loss : 0.8020 Learning Late: 0.4502
Epoch 70: 100%|██████████| 98/98 [00:37<00:00,  2.59batch/s]
Avg Loss : 0.7885 Validation Loss : 0.8532 Learning Late: 0.4243
Epoch 71: 100%|██████████| 98/98 [00:37<00:00,  2.61batch/s]
Avg Loss : 0.7238 Validation Loss : 0.7960 Learning Late: 0.3989
Epoch 72: 100%|██████████| 98/98 [00:38<00:00,  2.56batch/s]
Avg Loss : 0.7452 Validation Loss : 0.7002 Learning Late: 0.3740
Epoch 73: 100%|██████████| 98/98 [00:38<00:00,  2.56batch/s]
Avg Loss : 0.7530 Validation Loss : 0.6950 Learning Late: 0.3498
Epoch 74: 100%|██████████| 98/98 [00:37<00:00,  2.60batch/s]
Avg Loss : 0.7756 Validation Loss : 0.6649 Learning Late: 0.3261
Epoch 75: 100%|██████████| 98/98 [00:37<00:00,  2.61batch/s]
Avg Loss : 0.8126 Validation Loss : 0.7240 Learning Late: 0.3031
Epoch 76: 100%|██████████| 98/98 [00:38<00:00,  2.58batch/s]
Avg Loss : 0.7404 Validation Loss : 0.8040 Learning Late: 0.2808
Epoch 77: 100%|██████████| 98/98 [00:38<00:00,  2.57batch/s]
Avg Loss : 0.6722 Validation Loss : 0.8255 Learning Late: 0.2591
Epoch 78: 100%|██████████| 98/98 [00:37<00:00,  2.59batch/s]
Avg Loss : 0.6692 Validation Loss : 0.6784 Learning Late: 0.2381
Epoch 79: 100%|██████████| 98/98 [00:37<00:00,  2.61batch/s]
Avg Loss : 0.6903 Validation Loss : 0.6577 Learning Late: 0.2179
Epoch 80: 100%|██████████| 98/98 [00:37<00:00,  2.58batch/s]
Avg Loss : 0.6637 Validation Loss : 0.6454 Learning Late: 0.1985
Epoch 81: 100%|██████████| 98/98 [00:38<00:00,  2.55batch/s]
Avg Loss : 0.6611 Validation Loss : 0.6997 Learning Late: 0.1799
Epoch 82: 100%|██████████| 98/98 [00:37<00:00,  2.59batch/s]
Avg Loss : 0.6410 Validation Loss : 0.7144 Learning Late: 0.1621
Epoch 83: 100%|██████████| 98/98 [00:37<00:00,  2.62batch/s]
Avg Loss : 0.6405 Validation Loss : 0.6484 Learning Late: 0.1451
Epoch 84: 100%|██████████| 98/98 [00:37<00:00,  2.60batch/s]
Avg Loss : 0.6879 Validation Loss : 0.6353 Learning Late: 0.1289
Epoch 85: 100%|██████████| 98/98 [00:38<00:00,  2.57batch/s]
Avg Loss : 0.6431 Validation Loss : 0.7022 Learning Late: 0.1137
Epoch 86: 100%|██████████| 98/98 [00:37<00:00,  2.58batch/s]
Avg Loss : 0.6678 Validation Loss : 0.7154 Learning Late: 0.0993
Epoch 87: 100%|██████████| 98/98 [00:38<00:00,  2.57batch/s]
Avg Loss : 0.6420 Validation Loss : 0.6728 Learning Late: 0.0859
Epoch 88: 100%|██████████| 98/98 [00:37<00:00,  2.62batch/s]
Avg Loss : 0.6994 Validation Loss : 0.5899 Learning Late: 0.0734
Epoch 89: 100%|██████████| 98/98 [00:38<00:00,  2.57batch/s]
Avg Loss : 0.6617 Validation Loss : 0.6730 Learning Late: 0.0618
Epoch 90: 100%|██████████| 98/98 [00:38<00:00,  2.57batch/s]
Avg Loss : 0.6064 Validation Loss : 0.5814 Learning Late: 0.0512
Epoch 91: 100%|██████████| 98/98 [00:37<00:00,  2.59batch/s]
Avg Loss : 0.6388 Validation Loss : 0.7515 Learning Late: 0.0415
Epoch 92: 100%|██████████| 98/98 [00:38<00:00,  2.57batch/s]
Avg Loss : 0.6787 Validation Loss : 0.6063 Learning Late: 0.0329
Epoch 93: 100%|██████████| 98/98 [00:37<00:00,  2.61batch/s]
Avg Loss : 0.6339 Validation Loss : 0.6421 Learning Late: 0.0252
Epoch 94: 100%|██████████| 98/98 [00:38<00:00,  2.57batch/s]
Avg Loss : 0.6680 Validation Loss : 0.5270 Learning Late: 0.0185
Epoch 95: 100%|██████████| 98/98 [00:38<00:00,  2.57batch/s]
Avg Loss : 0.7141 Validation Loss : 0.6721 Learning Late: 0.0129
Epoch 96: 100%|██████████| 98/98 [00:37<00:00,  2.60batch/s]
Avg Loss : 0.6115 Validation Loss : 0.4881 Learning Late: 0.0083
Epoch 97: 100%|██████████| 98/98 [00:38<00:00,  2.57batch/s]
Avg Loss : 0.6464 Validation Loss : 0.5794 Learning Late: 0.0046
Epoch 98: 100%|██████████| 98/98 [00:38<00:00,  2.58batch/s]
Avg Loss : 0.6586 Validation Loss : 0.7928 Learning Late: 0.0021
Epoch 99: 100%|██████████| 98/98 [00:37<00:00,  2.59batch/s]
Avg Loss : 0.6005 Validation Loss : 0.6170 Learning Late: 0.0005
Epoch 100: 100%|██████████| 98/98 [00:37<00:00,  2.61batch/s]
Avg Loss : 0.6677 Validation Loss : 0.7497 Learning Late: 0.0000
FG 학습 완료. 이제 F의 output을 실제 dataset의 label과 연결.
Files already downloaded and verified
Files already downloaded and verified
Epoch 1: 100%|██████████| 391/391 [00:13<00:00, 29.19batch/s]
Avg Loss : 1.5049 Validation Loss : 1.4030 Learning Late: 0.0010
Epoch 2: 100%|██████████| 391/391 [00:13<00:00, 29.82batch/s]
Avg Loss : 1.3781 Validation Loss : 1.3524 Learning Late: 0.0010
Epoch 3: 100%|██████████| 391/391 [00:12<00:00, 30.69batch/s]
Avg Loss : 1.3415 Validation Loss : 1.3220 Learning Late: 0.0010
Epoch 4: 100%|██████████| 391/391 [00:12<00:00, 31.30batch/s]
Avg Loss : 1.3142 Validation Loss : 1.3033 Learning Late: 0.0010
Epoch 5: 100%|██████████| 391/391 [00:13<00:00, 28.41batch/s]
Avg Loss : 1.2912 Validation Loss : 1.2973 Learning Late: 0.0010
Epoch 6: 100%|██████████| 391/391 [00:12<00:00, 31.87batch/s]
Avg Loss : 1.2789 Validation Loss : 1.2814 Learning Late: 0.0010
Epoch 7: 100%|██████████| 391/391 [00:12<00:00, 31.30batch/s]
Avg Loss : 1.2650 Validation Loss : 1.2871 Learning Late: 0.0010
Epoch 8: 100%|██████████| 391/391 [00:12<00:00, 31.17batch/s]
Avg Loss : 1.2559 Validation Loss : 1.2678 Learning Late: 0.0010
Epoch 9: 100%|██████████| 391/391 [00:12<00:00, 30.71batch/s]
Avg Loss : 1.2453 Validation Loss : 1.2495 Learning Late: 0.0010
Epoch 10: 100%|██████████| 391/391 [00:12<00:00, 31.34batch/s]
Avg Loss : 1.2359 Validation Loss : 1.2498 Learning Late: 0.0010
Epoch 11: 100%|██████████| 391/391 [00:12<00:00, 30.49batch/s]
Avg Loss : 1.2311 Validation Loss : 1.2495 Learning Late: 0.0010
Epoch 12: 100%|██████████| 391/391 [00:12<00:00, 31.17batch/s]
Avg Loss : 1.2212 Validation Loss : 1.2463 Learning Late: 0.0010
Epoch 13: 100%|██████████| 391/391 [00:12<00:00, 30.87batch/s]
Avg Loss : 1.2168 Validation Loss : 1.2357 Learning Late: 0.0010
Epoch 14: 100%|██████████| 391/391 [00:12<00:00, 31.15batch/s]
Avg Loss : 1.2121 Validation Loss : 1.2526 Learning Late: 0.0010
Epoch 15: 100%|██████████| 391/391 [00:12<00:00, 30.25batch/s]
Avg Loss : 1.2091 Validation Loss : 1.2212 Learning Late: 0.0010
Epoch 16: 100%|██████████| 391/391 [00:12<00:00, 31.40batch/s]
Avg Loss : 1.2016 Validation Loss : 1.2277 Learning Late: 0.0010
Epoch 17: 100%|██████████| 391/391 [00:12<00:00, 30.87batch/s]
Avg Loss : 1.1990 Validation Loss : 1.2201 Learning Late: 0.0010
Epoch 18: 100%|██████████| 391/391 [00:12<00:00, 30.73batch/s]
Avg Loss : 1.1950 Validation Loss : 1.2250 Learning Late: 0.0010
Epoch 19: 100%|██████████| 391/391 [00:13<00:00, 29.57batch/s]
Avg Loss : 1.1903 Validation Loss : 1.2240 Learning Late: 0.0010
Epoch 20: 100%|██████████| 391/391 [00:12<00:00, 31.31batch/s]
Avg Loss : 1.1869 Validation Loss : 1.2323 Learning Late: 0.0010
Epoch 21: 100%|██████████| 391/391 [00:12<00:00, 30.88batch/s]
Avg Loss : 1.1854 Validation Loss : 1.2097 Learning Late: 0.0010
Epoch 22: 100%|██████████| 391/391 [00:12<00:00, 30.71batch/s]
Avg Loss : 1.1809 Validation Loss : 1.1991 Learning Late: 0.0010
Epoch 23: 100%|██████████| 391/391 [00:12<00:00, 30.89batch/s]
Avg Loss : 1.1788 Validation Loss : 1.2211 Learning Late: 0.0010
Epoch 24: 100%|██████████| 391/391 [00:12<00:00, 31.10batch/s]
Avg Loss : 1.1756 Validation Loss : 1.2098 Learning Late: 0.0010
Epoch 25: 100%|██████████| 391/391 [00:12<00:00, 31.20batch/s]
Avg Loss : 1.1728 Validation Loss : 1.2198 Learning Late: 0.0010
Epoch 26: 100%|██████████| 391/391 [00:12<00:00, 31.24batch/s]
Avg Loss : 1.1703 Validation Loss : 1.1981 Learning Late: 0.0010
Epoch 27: 100%|██████████| 391/391 [00:12<00:00, 30.63batch/s]
Avg Loss : 1.1677 Validation Loss : 1.2046 Learning Late: 0.0010
Epoch 28: 100%|██████████| 391/391 [00:12<00:00, 31.02batch/s]
Avg Loss : 1.1666 Validation Loss : 1.2047 Learning Late: 0.0010
Epoch 29: 100%|██████████| 391/391 [00:12<00:00, 30.82batch/s]
Avg Loss : 1.1621 Validation Loss : 1.2040 Learning Late: 0.0010
Epoch 30: 100%|██████████| 391/391 [00:12<00:00, 31.35batch/s]
Avg Loss : 1.1626 Validation Loss : 1.1976 Learning Late: 0.0010
Epoch 31: 100%|██████████| 391/391 [00:12<00:00, 31.13batch/s]
Avg Loss : 1.1595 Validation Loss : 1.2011 Learning Late: 0.0010
Epoch 32: 100%|██████████| 391/391 [00:15<00:00, 25.40batch/s]
Avg Loss : 1.1588 Validation Loss : 1.1949 Learning Late: 0.0010
Epoch 33: 100%|██████████| 391/391 [00:13<00:00, 30.01batch/s]
Avg Loss : 1.1575 Validation Loss : 1.2067 Learning Late: 0.0010
Epoch 34: 100%|██████████| 391/391 [00:13<00:00, 29.93batch/s]
Avg Loss : 1.1530 Validation Loss : 1.1837 Learning Late: 0.0010
Epoch 35: 100%|██████████| 391/391 [00:12<00:00, 30.91batch/s]
Avg Loss : 1.1523 Validation Loss : 1.1883 Learning Late: 0.0010
Epoch 36: 100%|██████████| 391/391 [00:12<00:00, 31.25batch/s]
Avg Loss : 1.1519 Validation Loss : 1.1858 Learning Late: 0.0010
Epoch 37: 100%|██████████| 391/391 [00:12<00:00, 31.12batch/s]
Avg Loss : 1.1495 Validation Loss : 1.1964 Learning Late: 0.0010
Epoch 38: 100%|██████████| 391/391 [00:12<00:00, 30.43batch/s]
Avg Loss : 1.1498 Validation Loss : 1.1755 Learning Late: 0.0009
Epoch 39: 100%|██████████| 391/391 [00:12<00:00, 30.91batch/s]
Avg Loss : 1.1469 Validation Loss : 1.1814 Learning Late: 0.0009
Epoch 40: 100%|██████████| 391/391 [00:12<00:00, 30.86batch/s]
Avg Loss : 1.1461 Validation Loss : 1.1871 Learning Late: 0.0009
Epoch 41: 100%|██████████| 391/391 [00:12<00:00, 31.23batch/s]
Avg Loss : 1.1442 Validation Loss : 1.1939 Learning Late: 0.0009
Epoch 42: 100%|██████████| 391/391 [00:12<00:00, 30.69batch/s]
Avg Loss : 1.1441 Validation Loss : 1.1890 Learning Late: 0.0009
Epoch 43: 100%|██████████| 391/391 [00:12<00:00, 31.31batch/s]
Avg Loss : 1.1437 Validation Loss : 1.1853 Learning Late: 0.0009
Epoch 44: 100%|██████████| 391/391 [00:12<00:00, 30.65batch/s]
Avg Loss : 1.1408 Validation Loss : 1.1852 Learning Late: 0.0009
Epoch 45: 100%|██████████| 391/391 [00:15<00:00, 26.02batch/s]
Avg Loss : 1.1408 Validation Loss : 1.1906 Learning Late: 0.0009
Epoch 46: 100%|██████████| 391/391 [00:13<00:00, 29.74batch/s]
Avg Loss : 1.1362 Validation Loss : 1.1898 Learning Late: 0.0009
Epoch 47: 100%|██████████| 391/391 [00:12<00:00, 30.44batch/s]
Avg Loss : 1.1383 Validation Loss : 1.1878 Learning Late: 0.0009
Epoch 48: 100%|██████████| 391/391 [00:12<00:00, 30.25batch/s]
Avg Loss : 1.1383 Validation Loss : 1.1882 Learning Late: 0.0009
Epoch 49: 100%|██████████| 391/391 [00:12<00:00, 30.99batch/s]
Avg Loss : 1.1351 Validation Loss : 1.1780 Learning Late: 0.0009
Epoch 50: 100%|██████████| 391/391 [00:12<00:00, 30.56batch/s]
Avg Loss : 1.1360 Validation Loss : 1.1797 Learning Late: 0.0009
Epoch 51: 100%|██████████| 391/391 [00:12<00:00, 30.91batch/s]
Avg Loss : 1.1345 Validation Loss : 1.1777 Learning Late: 0.0009
Epoch 52: 100%|██████████| 391/391 [00:12<00:00, 30.61batch/s]
Avg Loss : 1.1320 Validation Loss : 1.1693 Learning Late: 0.0009
Epoch 53: 100%|██████████| 391/391 [00:12<00:00, 30.76batch/s]
Avg Loss : 1.1308 Validation Loss : 1.1886 Learning Late: 0.0009
Epoch 54: 100%|██████████| 391/391 [00:12<00:00, 30.45batch/s]
Avg Loss : 1.1298 Validation Loss : 1.1847 Learning Late: 0.0009
Epoch 55: 100%|██████████| 391/391 [00:12<00:00, 30.73batch/s]
Avg Loss : 1.1286 Validation Loss : 1.1721 Learning Late: 0.0009
Epoch 56: 100%|██████████| 391/391 [00:12<00:00, 30.94batch/s]
Avg Loss : 1.1294 Validation Loss : 1.1807 Learning Late: 0.0009
Epoch 57: 100%|██████████| 391/391 [00:12<00:00, 30.21batch/s]
Avg Loss : 1.1284 Validation Loss : 1.1855 Learning Late: 0.0009
Epoch 58: 100%|██████████| 391/391 [00:13<00:00, 27.93batch/s]
Avg Loss : 1.1277 Validation Loss : 1.1892 Learning Late: 0.0009
Epoch 59: 100%|██████████| 391/391 [00:12<00:00, 30.80batch/s]
Avg Loss : 1.1282 Validation Loss : 1.1820 Learning Late: 0.0008
Epoch 60: 100%|██████████| 391/391 [00:12<00:00, 30.62batch/s]
Avg Loss : 1.1259 Validation Loss : 1.1737 Learning Late: 0.0008
Epoch 61: 100%|██████████| 391/391 [00:13<00:00, 30.01batch/s]
Avg Loss : 1.1233 Validation Loss : 1.1913 Learning Late: 0.0008
Epoch 62: 100%|██████████| 391/391 [00:12<00:00, 30.51batch/s]
Avg Loss : 1.1243 Validation Loss : 1.1728 Learning Late: 0.0008
Epoch 63: 100%|██████████| 391/391 [00:12<00:00, 30.56batch/s]
Avg Loss : 1.1247 Validation Loss : 1.1770 Learning Late: 0.0008
Epoch 64: 100%|██████████| 391/391 [00:12<00:00, 30.60batch/s]
Avg Loss : 1.1221 Validation Loss : 1.1893 Learning Late: 0.0008
Epoch 65: 100%|██████████| 391/391 [00:13<00:00, 29.94batch/s]
Avg Loss : 1.1227 Validation Loss : 1.1830 Learning Late: 0.0008
Epoch 66: 100%|██████████| 391/391 [00:12<00:00, 30.35batch/s]
Avg Loss : 1.1224 Validation Loss : 1.1797 Learning Late: 0.0008
Epoch 67: 100%|██████████| 391/391 [00:12<00:00, 30.52batch/s]
Avg Loss : 1.1211 Validation Loss : 1.1800 Learning Late: 0.0008
Epoch 68: 100%|██████████| 391/391 [00:12<00:00, 30.49batch/s]
Avg Loss : 1.1212 Validation Loss : 1.1712 Learning Late: 0.0008
Epoch 69: 100%|██████████| 391/391 [00:12<00:00, 30.25batch/s]
Avg Loss : 1.1184 Validation Loss : 1.1763 Learning Late: 0.0008
Epoch 70: 100%|██████████| 391/391 [00:12<00:00, 30.61batch/s]
Avg Loss : 1.1198 Validation Loss : 1.1808 Learning Late: 0.0008
Epoch 71: 100%|██████████| 391/391 [00:13<00:00, 28.16batch/s]
Avg Loss : 1.1188 Validation Loss : 1.1741 Learning Late: 0.0008
Epoch 72: 100%|██████████| 391/391 [00:12<00:00, 30.17batch/s]
Avg Loss : 1.1166 Validation Loss : 1.1794 Learning Late: 0.0008
Epoch 73: 100%|██████████| 391/391 [00:12<00:00, 30.20batch/s]
Avg Loss : 1.1168 Validation Loss : 1.1747 Learning Late: 0.0008
Epoch 74: 100%|██████████| 391/391 [00:12<00:00, 30.30batch/s]
Avg Loss : 1.1154 Validation Loss : 1.1756 Learning Late: 0.0007
Epoch 75: 100%|██████████| 391/391 [00:12<00:00, 30.90batch/s]
Avg Loss : 1.1149 Validation Loss : 1.1723 Learning Late: 0.0007
Epoch 76: 100%|██████████| 391/391 [00:12<00:00, 30.55batch/s]
Avg Loss : 1.1143 Validation Loss : 1.1727 Learning Late: 0.0007
Epoch 77: 100%|██████████| 391/391 [00:12<00:00, 30.59batch/s]
Avg Loss : 1.1146 Validation Loss : 1.1738 Learning Late: 0.0007
Epoch 78: 100%|██████████| 391/391 [00:13<00:00, 29.99batch/s]
Avg Loss : 1.1151 Validation Loss : 1.1769 Learning Late: 0.0007
Epoch 79: 100%|██████████| 391/391 [00:13<00:00, 30.01batch/s]
Avg Loss : 1.1125 Validation Loss : 1.1703 Learning Late: 0.0007
Epoch 80: 100%|██████████| 391/391 [00:12<00:00, 30.25batch/s]
Avg Loss : 1.1131 Validation Loss : 1.1707 Learning Late: 0.0007
Epoch 81: 100%|██████████| 391/391 [00:12<00:00, 30.31batch/s]
Avg Loss : 1.1122 Validation Loss : 1.1693 Learning Late: 0.0007
Epoch 82: 100%|██████████| 391/391 [00:12<00:00, 30.75batch/s]
Avg Loss : 1.1108 Validation Loss : 1.1759 Learning Late: 0.0007
Epoch 83: 100%|██████████| 391/391 [00:12<00:00, 30.85batch/s]
Avg Loss : 1.1107 Validation Loss : 1.1684 Learning Late: 0.0007
Epoch 84: 100%|██████████| 391/391 [00:13<00:00, 29.86batch/s]
Avg Loss : 1.1099 Validation Loss : 1.1695 Learning Late: 0.0007
Epoch 85: 100%|██████████| 391/391 [00:13<00:00, 29.29batch/s]
Avg Loss : 1.1104 Validation Loss : 1.1657 Learning Late: 0.0007
Epoch 86: 100%|██████████| 391/391 [00:12<00:00, 30.68batch/s]
Avg Loss : 1.1089 Validation Loss : 1.1743 Learning Late: 0.0007
Epoch 87: 100%|██████████| 391/391 [00:12<00:00, 30.67batch/s]
Avg Loss : 1.1076 Validation Loss : 1.1712 Learning Late: 0.0006
Epoch 88: 100%|██████████| 391/391 [00:12<00:00, 30.39batch/s]
Avg Loss : 1.1084 Validation Loss : 1.1655 Learning Late: 0.0006
Epoch 89: 100%|██████████| 391/391 [00:12<00:00, 30.45batch/s]
Avg Loss : 1.1101 Validation Loss : 1.1729 Learning Late: 0.0006
Epoch 90: 100%|██████████| 391/391 [00:12<00:00, 30.29batch/s]
Avg Loss : 1.1074 Validation Loss : 1.1638 Learning Late: 0.0006
Epoch 91: 100%|██████████| 391/391 [00:13<00:00, 30.02batch/s]
Avg Loss : 1.1071 Validation Loss : 1.1599 Learning Late: 0.0006
Epoch 92: 100%|██████████| 391/391 [00:12<00:00, 30.17batch/s]
Avg Loss : 1.1062 Validation Loss : 1.1651 Learning Late: 0.0006
Epoch 93: 100%|██████████| 391/391 [00:12<00:00, 30.17batch/s]
Avg Loss : 1.1060 Validation Loss : 1.1579 Learning Late: 0.0006
Epoch 94: 100%|██████████| 391/391 [00:13<00:00, 29.82batch/s]
Avg Loss : 1.1052 Validation Loss : 1.1695 Learning Late: 0.0006
Epoch 95: 100%|██████████| 391/391 [00:12<00:00, 30.17batch/s]
Avg Loss : 1.1052 Validation Loss : 1.1646 Learning Late: 0.0006
Epoch 96: 100%|██████████| 391/391 [00:12<00:00, 30.20batch/s]
Avg Loss : 1.1045 Validation Loss : 1.1586 Learning Late: 0.0006
Epoch 97: 100%|██████████| 391/391 [00:12<00:00, 30.42batch/s]
Avg Loss : 1.1031 Validation Loss : 1.1572 Learning Late: 0.0006
Epoch 98: 100%|██████████| 391/391 [00:14<00:00, 27.57batch/s]
Avg Loss : 1.1034 Validation Loss : 1.1668 Learning Late: 0.0006
Epoch 99: 100%|██████████| 391/391 [00:12<00:00, 30.22batch/s]
Avg Loss : 1.1019 Validation Loss : 1.1626 Learning Late: 0.0005
Epoch 100: 100%|██████████| 391/391 [00:12<00:00, 30.08batch/s]
Avg Loss : 1.1036 Validation Loss : 1.1679 Learning Late: 0.0005
Epoch 101: 100%|██████████| 391/391 [00:12<00:00, 30.37batch/s]
Avg Loss : 1.1022 Validation Loss : 1.1608 Learning Late: 0.0005
Epoch 102: 100%|██████████| 391/391 [00:12<00:00, 30.40batch/s]
Avg Loss : 1.1021 Validation Loss : 1.1661 Learning Late: 0.0005
Epoch 103: 100%|██████████| 391/391 [00:13<00:00, 30.06batch/s]
Avg Loss : 1.1029 Validation Loss : 1.1583 Learning Late: 0.0005
Epoch 104: 100%|██████████| 391/391 [00:13<00:00, 29.70batch/s]
Avg Loss : 1.1017 Validation Loss : 1.1619 Learning Late: 0.0005
Epoch 105: 100%|██████████| 391/391 [00:13<00:00, 29.93batch/s]
Avg Loss : 1.0999 Validation Loss : 1.1630 Learning Late: 0.0005
Epoch 106: 100%|██████████| 391/391 [00:12<00:00, 30.09batch/s]
Avg Loss : 1.1003 Validation Loss : 1.1694 Learning Late: 0.0005
Epoch 107: 100%|██████████| 391/391 [00:12<00:00, 30.11batch/s]
Avg Loss : 1.0990 Validation Loss : 1.1658 Learning Late: 0.0005
Epoch 108: 100%|██████████| 391/391 [00:12<00:00, 30.11batch/s]
Avg Loss : 1.0987 Validation Loss : 1.1570 Learning Late: 0.0005
Epoch 109: 100%|██████████| 391/391 [00:13<00:00, 30.01batch/s]
Avg Loss : 1.0981 Validation Loss : 1.1699 Learning Late: 0.0005
Epoch 110: 100%|██████████| 391/391 [00:13<00:00, 29.29batch/s]
Avg Loss : 1.0990 Validation Loss : 1.1535 Learning Late: 0.0005
Epoch 111: 100%|██████████| 391/391 [00:14<00:00, 27.04batch/s]
Avg Loss : 1.0981 Validation Loss : 1.1583 Learning Late: 0.0005
Epoch 112: 100%|██████████| 391/391 [00:13<00:00, 29.93batch/s]
Avg Loss : 1.0971 Validation Loss : 1.1564 Learning Late: 0.0004
Epoch 113: 100%|██████████| 391/391 [00:12<00:00, 30.29batch/s]
Avg Loss : 1.0974 Validation Loss : 1.1644 Learning Late: 0.0004
Epoch 114: 100%|██████████| 391/391 [00:13<00:00, 29.95batch/s]
Avg Loss : 1.0976 Validation Loss : 1.1533 Learning Late: 0.0004
Epoch 115: 100%|██████████| 391/391 [00:13<00:00, 29.95batch/s]
Avg Loss : 1.0973 Validation Loss : 1.1759 Learning Late: 0.0004
Epoch 116: 100%|██████████| 391/391 [00:13<00:00, 29.56batch/s]
Avg Loss : 1.0962 Validation Loss : 1.1503 Learning Late: 0.0004
Epoch 117: 100%|██████████| 391/391 [00:13<00:00, 29.70batch/s]
Avg Loss : 1.0947 Validation Loss : 1.1539 Learning Late: 0.0004
Epoch 118: 100%|██████████| 391/391 [00:13<00:00, 29.91batch/s]
Avg Loss : 1.0945 Validation Loss : 1.1642 Learning Late: 0.0004
Epoch 119: 100%|██████████| 391/391 [00:13<00:00, 29.99batch/s]
Avg Loss : 1.0953 Validation Loss : 1.1563 Learning Late: 0.0004
Epoch 120: 100%|██████████| 391/391 [00:12<00:00, 30.29batch/s]
Avg Loss : 1.0947 Validation Loss : 1.1548 Learning Late: 0.0004
Epoch 121: 100%|██████████| 391/391 [00:13<00:00, 29.83batch/s]
Avg Loss : 1.0942 Validation Loss : 1.1616 Learning Late: 0.0004
Epoch 122: 100%|██████████| 391/391 [00:12<00:00, 30.42batch/s]
Avg Loss : 1.0929 Validation Loss : 1.1501 Learning Late: 0.0004
Epoch 123: 100%|██████████| 391/391 [00:13<00:00, 30.06batch/s]
Avg Loss : 1.0926 Validation Loss : 1.1566 Learning Late: 0.0004
Epoch 124: 100%|██████████| 391/391 [00:15<00:00, 25.61batch/s]
Avg Loss : 1.0934 Validation Loss : 1.1539 Learning Late: 0.0003
Epoch 125: 100%|██████████| 391/391 [00:13<00:00, 29.64batch/s]
Avg Loss : 1.0931 Validation Loss : 1.1566 Learning Late: 0.0003
Epoch 126: 100%|██████████| 391/391 [00:13<00:00, 29.97batch/s]
Avg Loss : 1.0928 Validation Loss : 1.1634 Learning Late: 0.0003
Epoch 127: 100%|██████████| 391/391 [00:12<00:00, 30.18batch/s]
Avg Loss : 1.0925 Validation Loss : 1.1566 Learning Late: 0.0003
Epoch 128: 100%|██████████| 391/391 [00:13<00:00, 30.06batch/s]
Avg Loss : 1.0914 Validation Loss : 1.1477 Learning Late: 0.0003
Epoch 129: 100%|██████████| 391/391 [00:13<00:00, 29.79batch/s]
Avg Loss : 1.0913 Validation Loss : 1.1583 Learning Late: 0.0003
Epoch 130: 100%|██████████| 391/391 [00:13<00:00, 29.77batch/s]
Avg Loss : 1.0917 Validation Loss : 1.1609 Learning Late: 0.0003
Epoch 131: 100%|██████████| 391/391 [00:13<00:00, 30.06batch/s]
Avg Loss : 1.0904 Validation Loss : 1.1602 Learning Late: 0.0003
Epoch 132: 100%|██████████| 391/391 [00:13<00:00, 29.94batch/s]
Avg Loss : 1.0899 Validation Loss : 1.1556 Learning Late: 0.0003
Epoch 133: 100%|██████████| 391/391 [00:13<00:00, 30.06batch/s]
Avg Loss : 1.0897 Validation Loss : 1.1508 Learning Late: 0.0003
Epoch 134: 100%|██████████| 391/391 [00:13<00:00, 30.03batch/s]
Avg Loss : 1.0897 Validation Loss : 1.1556 Learning Late: 0.0003
Epoch 135: 100%|██████████| 391/391 [00:12<00:00, 30.52batch/s]
Avg Loss : 1.0892 Validation Loss : 1.1536 Learning Late: 0.0003
Epoch 136: 100%|██████████| 391/391 [00:13<00:00, 29.22batch/s]
Avg Loss : 1.0888 Validation Loss : 1.1567 Learning Late: 0.0003
Epoch 137: 100%|██████████| 391/391 [00:15<00:00, 25.64batch/s]
Avg Loss : 1.0893 Validation Loss : 1.1499 Learning Late: 0.0002
Epoch 138: 100%|██████████| 391/391 [00:13<00:00, 29.98batch/s]
Avg Loss : 1.0887 Validation Loss : 1.1535 Learning Late: 0.0002
Epoch 139: 100%|██████████| 391/391 [00:13<00:00, 29.99batch/s]
Avg Loss : 1.0885 Validation Loss : 1.1513 Learning Late: 0.0002
Epoch 140: 100%|██████████| 391/391 [00:13<00:00, 29.53batch/s]
Avg Loss : 1.0883 Validation Loss : 1.1574 Learning Late: 0.0002
Epoch 141: 100%|██████████| 391/391 [00:13<00:00, 30.06batch/s]
Avg Loss : 1.0888 Validation Loss : 1.1519 Learning Late: 0.0002
Epoch 142: 100%|██████████| 391/391 [00:13<00:00, 29.86batch/s]
Avg Loss : 1.0874 Validation Loss : 1.1521 Learning Late: 0.0002
Epoch 143: 100%|██████████| 391/391 [00:13<00:00, 30.00batch/s]
Avg Loss : 1.0876 Validation Loss : 1.1488 Learning Late: 0.0002
Epoch 144: 100%|██████████| 391/391 [00:13<00:00, 29.77batch/s]
Avg Loss : 1.0873 Validation Loss : 1.1476 Learning Late: 0.0002
Epoch 145: 100%|██████████| 391/391 [00:13<00:00, 29.83batch/s]
Avg Loss : 1.0869 Validation Loss : 1.1497 Learning Late: 0.0002
Epoch 146: 100%|██████████| 391/391 [00:12<00:00, 30.14batch/s]
Avg Loss : 1.0872 Validation Loss : 1.1518 Learning Late: 0.0002
Epoch 147: 100%|██████████| 391/391 [00:13<00:00, 29.22batch/s]
Avg Loss : 1.0865 Validation Loss : 1.1588 Learning Late: 0.0002
Epoch 148: 100%|██████████| 391/391 [00:12<00:00, 30.12batch/s]
Avg Loss : 1.0864 Validation Loss : 1.1517 Learning Late: 0.0002
Epoch 149: 100%|██████████| 391/391 [00:13<00:00, 29.74batch/s]
Avg Loss : 1.0856 Validation Loss : 1.1501 Learning Late: 0.0002
Epoch 150: 100%|██████████| 391/391 [00:15<00:00, 24.99batch/s]
Avg Loss : 1.0859 Validation Loss : 1.1552 Learning Late: 0.0002
Epoch 151: 100%|██████████| 391/391 [00:13<00:00, 28.75batch/s]
Avg Loss : 1.0852 Validation Loss : 1.1549 Learning Late: 0.0002
Epoch 152: 100%|██████████| 391/391 [00:13<00:00, 29.49batch/s]
Avg Loss : 1.0849 Validation Loss : 1.1505 Learning Late: 0.0001
Epoch 153: 100%|██████████| 391/391 [00:13<00:00, 29.85batch/s]
Avg Loss : 1.0846 Validation Loss : 1.1508 Learning Late: 0.0001
Epoch 154: 100%|██████████| 391/391 [00:12<00:00, 30.16batch/s]
Avg Loss : 1.0847 Validation Loss : 1.1512 Learning Late: 0.0001
Epoch 155: 100%|██████████| 391/391 [00:13<00:00, 29.71batch/s]
Avg Loss : 1.0844 Validation Loss : 1.1545 Learning Late: 0.0001
Epoch 156: 100%|██████████| 391/391 [00:13<00:00, 29.88batch/s]
Avg Loss : 1.0840 Validation Loss : 1.1487 Learning Late: 0.0001
Epoch 157: 100%|██████████| 391/391 [00:13<00:00, 30.02batch/s]
Avg Loss : 1.0844 Validation Loss : 1.1593 Learning Late: 0.0001
Epoch 158: 100%|██████████| 391/391 [00:13<00:00, 29.81batch/s]
Avg Loss : 1.0838 Validation Loss : 1.1518 Learning Late: 0.0001
Epoch 159: 100%|██████████| 391/391 [00:13<00:00, 29.70batch/s]
Avg Loss : 1.0837 Validation Loss : 1.1578 Learning Late: 0.0001
Epoch 160: 100%|██████████| 391/391 [00:13<00:00, 30.05batch/s]
Avg Loss : 1.0832 Validation Loss : 1.1524 Learning Late: 0.0001
Epoch 161: 100%|██████████| 391/391 [00:12<00:00, 30.11batch/s]
Avg Loss : 1.0834 Validation Loss : 1.1503 Learning Late: 0.0001
Epoch 162: 100%|██████████| 391/391 [00:13<00:00, 29.41batch/s]
Avg Loss : 1.0832 Validation Loss : 1.1569 Learning Late: 0.0001
Epoch 163: 100%|██████████| 391/391 [00:15<00:00, 25.40batch/s]
Avg Loss : 1.0827 Validation Loss : 1.1546 Learning Late: 0.0001
Epoch 164: 100%|██████████| 391/391 [00:13<00:00, 29.26batch/s]
Avg Loss : 1.0828 Validation Loss : 1.1497 Learning Late: 0.0001
Epoch 165: 100%|██████████| 391/391 [00:13<00:00, 29.86batch/s]
Avg Loss : 1.0827 Validation Loss : 1.1511 Learning Late: 0.0001
Epoch 166: 100%|██████████| 391/391 [00:13<00:00, 29.23batch/s]
Avg Loss : 1.0822 Validation Loss : 1.1499 Learning Late: 0.0001
Epoch 167: 100%|██████████| 391/391 [00:13<00:00, 29.86batch/s]
Avg Loss : 1.0824 Validation Loss : 1.1523 Learning Late: 0.0001
Epoch 168: 100%|██████████| 391/391 [00:13<00:00, 29.50batch/s]
Avg Loss : 1.0820 Validation Loss : 1.1523 Learning Late: 0.0001
Epoch 169: 100%|██████████| 391/391 [00:13<00:00, 29.56batch/s]
Avg Loss : 1.0821 Validation Loss : 1.1481 Learning Late: 0.0001
Epoch 170: 100%|██████████| 391/391 [00:13<00:00, 29.52batch/s]
Avg Loss : 1.0814 Validation Loss : 1.1446 Learning Late: 0.0001
Epoch 171: 100%|██████████| 391/391 [00:13<00:00, 29.88batch/s]
Avg Loss : 1.0817 Validation Loss : 1.1564 Learning Late: 0.0001
Epoch 172: 100%|██████████| 391/391 [00:13<00:00, 29.42batch/s]
Avg Loss : 1.0813 Validation Loss : 1.1518 Learning Late: 0.0001
Epoch 173: 100%|██████████| 391/391 [00:13<00:00, 29.77batch/s]
Avg Loss : 1.0811 Validation Loss : 1.1465 Learning Late: 0.0000
Epoch 174: 100%|██████████| 391/391 [00:13<00:00, 29.54batch/s]
Avg Loss : 1.0814 Validation Loss : 1.1518 Learning Late: 0.0000
Epoch 175: 100%|██████████| 391/391 [00:13<00:00, 29.38batch/s]
Avg Loss : 1.0812 Validation Loss : 1.1534 Learning Late: 0.0000
Epoch 176: 100%|██████████| 391/391 [00:15<00:00, 24.67batch/s]
Avg Loss : 1.0810 Validation Loss : 1.1520 Learning Late: 0.0000
Epoch 177: 100%|██████████| 391/391 [00:13<00:00, 28.45batch/s]
Avg Loss : 1.0807 Validation Loss : 1.1504 Learning Late: 0.0000
Epoch 178: 100%|██████████| 391/391 [00:13<00:00, 29.46batch/s]
Avg Loss : 1.0808 Validation Loss : 1.1465 Learning Late: 0.0000
Epoch 179: 100%|██████████| 391/391 [00:13<00:00, 29.30batch/s]
Avg Loss : 1.0805 Validation Loss : 1.1537 Learning Late: 0.0000
Epoch 180: 100%|██████████| 391/391 [00:13<00:00, 29.81batch/s]
Avg Loss : 1.0804 Validation Loss : 1.1470 Learning Late: 0.0000
Epoch 181: 100%|██████████| 391/391 [00:13<00:00, 29.56batch/s]
Avg Loss : 1.0802 Validation Loss : 1.1540 Learning Late: 0.0000
Epoch 182: 100%|██████████| 391/391 [00:13<00:00, 29.51batch/s]
Avg Loss : 1.0802 Validation Loss : 1.1485 Learning Late: 0.0000
Epoch 183: 100%|██████████| 391/391 [00:13<00:00, 29.47batch/s]
Avg Loss : 1.0801 Validation Loss : 1.1551 Learning Late: 0.0000
Epoch 184: 100%|██████████| 391/391 [00:13<00:00, 28.63batch/s]
Avg Loss : 1.0800 Validation Loss : 1.1474 Learning Late: 0.0000
Epoch 185: 100%|██████████| 391/391 [00:13<00:00, 29.77batch/s]
Avg Loss : 1.0800 Validation Loss : 1.1482 Learning Late: 0.0000
Epoch 186: 100%|██████████| 391/391 [00:13<00:00, 29.39batch/s]
Avg Loss : 1.0798 Validation Loss : 1.1510 Learning Late: 0.0000
Epoch 187: 100%|██████████| 391/391 [00:13<00:00, 29.66batch/s]
Avg Loss : 1.0799 Validation Loss : 1.1486 Learning Late: 0.0000
Epoch 188: 100%|██████████| 391/391 [00:13<00:00, 29.12batch/s]
Avg Loss : 1.0796 Validation Loss : 1.1498 Learning Late: 0.0000
Epoch 189: 100%|██████████| 391/391 [00:15<00:00, 25.52batch/s]
Avg Loss : 1.0797 Validation Loss : 1.1500 Learning Late: 0.0000
Epoch 190: 100%|██████████| 391/391 [00:13<00:00, 28.87batch/s]
Avg Loss : 1.0796 Validation Loss : 1.1471 Learning Late: 0.0000
Epoch 191: 100%|██████████| 391/391 [00:13<00:00, 29.36batch/s]
Avg Loss : 1.0793 Validation Loss : 1.1505 Learning Late: 0.0000
Epoch 192: 100%|██████████| 391/391 [00:13<00:00, 28.90batch/s]
Avg Loss : 1.0793 Validation Loss : 1.1498 Learning Late: 0.0000
Epoch 193: 100%|██████████| 391/391 [00:13<00:00, 29.48batch/s]
Avg Loss : 1.0795 Validation Loss : 1.1476 Learning Late: 0.0000
Epoch 194: 100%|██████████| 391/391 [00:13<00:00, 29.05batch/s]
Avg Loss : 1.0793 Validation Loss : 1.1516 Learning Late: 0.0000
Epoch 195: 100%|██████████| 391/391 [00:13<00:00, 29.12batch/s]
Avg Loss : 1.0794 Validation Loss : 1.1564 Learning Late: 0.0000
Epoch 196: 100%|██████████| 391/391 [00:13<00:00, 29.24batch/s]
Avg Loss : 1.0794 Validation Loss : 1.1520 Learning Late: 0.0000
Epoch 197: 100%|██████████| 391/391 [00:13<00:00, 29.24batch/s]
Avg Loss : 1.0792 Validation Loss : 1.1475 Learning Late: 0.0000
Epoch 198: 100%|██████████| 391/391 [00:13<00:00, 29.72batch/s]
Avg Loss : 1.0793 Validation Loss : 1.1504 Learning Late: 0.0000
Epoch 199: 100%|██████████| 391/391 [00:13<00:00, 29.12batch/s]
Avg Loss : 1.0792 Validation Loss : 1.1459 Learning Late: 0.0000
Epoch 200: 100%|██████████| 391/391 [00:13<00:00, 29.44batch/s]
Avg Loss : 1.0790 Validation Loss : 1.1472 Learning Late: 0.0000
실제 test
100%|██████████| 79/79 [00:02<00:00, 36.61batch/s]
총 개수 : 10000
top-1 맞춘 개수 : 5905 
 정확도: 59.05
top-5 맞춘 개수 : 9583 
 정확도: 95.83
Files already downloaded and verified
Files already downloaded and verified
Epoch 1: 100%|██████████| 98/98 [00:38<00:00,  2.56batch/s]
Avg Loss : 6.5183 Validation Loss : 6.2630 Learning Late: 1.6971
Epoch 2: 100%|██████████| 98/98 [00:37<00:00,  2.61batch/s]
Avg Loss : 6.2662 Validation Loss : 6.1865 Learning Late: 1.6971
Epoch 3: 100%|██████████| 98/98 [00:38<00:00,  2.57batch/s]
Avg Loss : 6.2471 Validation Loss : 5.9313 Learning Late: 1.6971
Epoch 4: 100%|██████████| 98/98 [00:37<00:00,  2.59batch/s]
Avg Loss : 5.8702 Validation Loss : 5.5694 Learning Late: 1.6971
Epoch 5: 100%|██████████| 98/98 [00:37<00:00,  2.60batch/s]
Avg Loss : 5.5470 Validation Loss : 6.0346 Learning Late: 1.6971
Epoch 6: 100%|██████████| 98/98 [00:38<00:00,  2.56batch/s]
Avg Loss : 5.5759 Validation Loss : 5.2963 Learning Late: 1.6971
Epoch 7: 100%|██████████| 98/98 [00:37<00:00,  2.59batch/s]
Avg Loss : 5.4727 Validation Loss : 5.4160 Learning Late: 1.6971
Epoch 8: 100%|██████████| 98/98 [00:38<00:00,  2.55batch/s]
Avg Loss : 5.3539 Validation Loss : 5.3219 Learning Late: 1.6971
Epoch 9: 100%|██████████| 98/98 [00:37<00:00,  2.59batch/s]
Avg Loss : 5.3261 Validation Loss : 5.1862 Learning Late: 1.6971
Epoch 10: 100%|██████████| 98/98 [00:37<00:00,  2.61batch/s]
Avg Loss : 5.2444 Validation Loss : 5.0807 Learning Late: 1.6971
Epoch 11: 100%|██████████| 98/98 [00:38<00:00,  2.58batch/s]
Avg Loss : 4.7344 Validation Loss : 4.3524 Learning Late: 1.6965
Epoch 12: 100%|██████████| 98/98 [00:38<00:00,  2.57batch/s]
Avg Loss : 4.5681 Validation Loss : 4.5599 Learning Late: 1.6950
Epoch 13: 100%|██████████| 98/98 [00:38<00:00,  2.57batch/s]
Avg Loss : 4.4752 Validation Loss : 5.2065 Learning Late: 1.6924
Epoch 14: 100%|██████████| 98/98 [00:37<00:00,  2.59batch/s]
Avg Loss : 4.5158 Validation Loss : 4.6220 Learning Late: 1.6888
Epoch 15: 100%|██████████| 98/98 [00:37<00:00,  2.61batch/s]
Avg Loss : 4.3740 Validation Loss : 4.0718 Learning Late: 1.6842
Epoch 16: 100%|██████████| 98/98 [00:38<00:00,  2.54batch/s]
Avg Loss : 4.1683 Validation Loss : 4.2262 Learning Late: 1.6785
Epoch 17: 100%|██████████| 98/98 [00:38<00:00,  2.56batch/s]
Avg Loss : 4.1514 Validation Loss : 4.0241 Learning Late: 1.6719
Epoch 18: 100%|██████████| 98/98 [00:37<00:00,  2.60batch/s]
Avg Loss : 3.8776 Validation Loss : 4.6402 Learning Late: 1.6642
Epoch 19: 100%|██████████| 98/98 [00:37<00:00,  2.60batch/s]
Avg Loss : 3.8360 Validation Loss : 3.7677 Learning Late: 1.6555
Epoch 20: 100%|██████████| 98/98 [00:37<00:00,  2.62batch/s]
Avg Loss : 3.9545 Validation Loss : 3.5887 Learning Late: 1.6459
Epoch 21: 100%|██████████| 98/98 [00:38<00:00,  2.54batch/s]
Avg Loss : 3.5601 Validation Loss : 3.3679 Learning Late: 1.6353
Epoch 22: 100%|██████████| 98/98 [00:37<00:00,  2.58batch/s]
Avg Loss : 3.5814 Validation Loss : 3.1434 Learning Late: 1.6237
Epoch 23: 100%|██████████| 98/98 [00:37<00:00,  2.60batch/s]
Avg Loss : 3.3856 Validation Loss : 3.2284 Learning Late: 1.6112
Epoch 24: 100%|██████████| 98/98 [00:37<00:00,  2.61batch/s]
Avg Loss : 3.2732 Validation Loss : 2.9726 Learning Late: 1.5977
Epoch 25: 100%|██████████| 98/98 [00:37<00:00,  2.58batch/s]
Avg Loss : 2.8955 Validation Loss : 2.7293 Learning Late: 1.5834
Epoch 26: 100%|██████████| 98/98 [00:38<00:00,  2.54batch/s]
Avg Loss : 2.7411 Validation Loss : 2.6604 Learning Late: 1.5681
Epoch 27: 100%|██████████| 98/98 [00:37<00:00,  2.62batch/s]
Avg Loss : 2.7642 Validation Loss : 2.5307 Learning Late: 1.5520
Epoch 28: 100%|██████████| 98/98 [00:37<00:00,  2.61batch/s]
Avg Loss : 2.6374 Validation Loss : 2.5167 Learning Late: 1.5350
Epoch 29: 100%|██████████| 98/98 [00:38<00:00,  2.57batch/s]
Avg Loss : 2.3650 Validation Loss : 2.2005 Learning Late: 1.5172
Epoch 30: 100%|██████████| 98/98 [00:37<00:00,  2.58batch/s]
Avg Loss : 2.2494 Validation Loss : 2.1251 Learning Late: 1.4985
Epoch 31: 100%|██████████| 98/98 [00:38<00:00,  2.57batch/s]
Avg Loss : 2.1339 Validation Loss : 2.3407 Learning Late: 1.4791
Epoch 32: 100%|██████████| 98/98 [00:37<00:00,  2.61batch/s]
Avg Loss : 2.0956 Validation Loss : 1.8776 Learning Late: 1.4589
Epoch 33: 100%|██████████| 98/98 [00:37<00:00,  2.59batch/s]
Avg Loss : 2.1236 Validation Loss : 2.1257 Learning Late: 1.4380
Epoch 34: 100%|██████████| 98/98 [00:38<00:00,  2.58batch/s]
Avg Loss : 1.8243 Validation Loss : 1.8069 Learning Late: 1.4163
Epoch 35: 100%|██████████| 98/98 [00:37<00:00,  2.60batch/s]
Avg Loss : 1.7658 Validation Loss : 1.6700 Learning Late: 1.3940
Epoch 36: 100%|██████████| 98/98 [00:37<00:00,  2.60batch/s]
Avg Loss : 1.6579 Validation Loss : 1.6641 Learning Late: 1.3709
Epoch 37: 100%|██████████| 98/98 [00:38<00:00,  2.57batch/s]
Avg Loss : 1.5716 Validation Loss : 1.5184 Learning Late: 1.3473
Epoch 38: 100%|██████████| 98/98 [00:37<00:00,  2.58batch/s]
Avg Loss : 1.6082 Validation Loss : 1.7213 Learning Late: 1.3230
Epoch 39: 100%|██████████| 98/98 [00:37<00:00,  2.59batch/s]
Avg Loss : 1.5991 Validation Loss : 1.6811 Learning Late: 1.2982
Epoch 40: 100%|██████████| 98/98 [00:37<00:00,  2.61batch/s]
Avg Loss : 1.4382 Validation Loss : 1.4038 Learning Late: 1.2728
Epoch 41: 100%|██████████| 98/98 [00:38<00:00,  2.57batch/s]
Avg Loss : 1.3897 Validation Loss : 1.3974 Learning Late: 1.2469
Epoch 42: 100%|██████████| 98/98 [00:38<00:00,  2.53batch/s]
Avg Loss : 1.3252 Validation Loss : 1.1953 Learning Late: 1.2205
Epoch 43: 100%|██████████| 98/98 [00:38<00:00,  2.57batch/s]
Avg Loss : 1.2861 Validation Loss : 1.1050 Learning Late: 1.1937
Epoch 44: 100%|██████████| 98/98 [00:37<00:00,  2.59batch/s]
Avg Loss : 1.1815 Validation Loss : 1.0922 Learning Late: 1.1664
Epoch 45: 100%|██████████| 98/98 [00:37<00:00,  2.60batch/s]
Avg Loss : 1.1477 Validation Loss : 1.1406 Learning Late: 1.1387
Epoch 46: 100%|██████████| 98/98 [00:38<00:00,  2.54batch/s]
Avg Loss : 1.2775 Validation Loss : 1.1170 Learning Late: 1.1107
Epoch 47: 100%|██████████| 98/98 [00:38<00:00,  2.54batch/s]
Avg Loss : 1.1589 Validation Loss : 1.0579 Learning Late: 1.0824
Epoch 48: 100%|██████████| 98/98 [00:37<00:00,  2.61batch/s]
Avg Loss : 1.0712 Validation Loss : 1.0334 Learning Late: 1.0538
Epoch 49: 100%|██████████| 98/98 [00:37<00:00,  2.59batch/s]
Avg Loss : 1.0159 Validation Loss : 0.9755 Learning Late: 1.0249
Epoch 50: 100%|██████████| 98/98 [00:38<00:00,  2.57batch/s]
Avg Loss : 0.9677 Validation Loss : 0.9113 Learning Late: 0.9959
Epoch 51: 100%|██████████| 98/98 [00:38<00:00,  2.57batch/s]
Avg Loss : 0.9572 Validation Loss : 1.0425 Learning Late: 0.9666
Epoch 52: 100%|██████████| 98/98 [00:38<00:00,  2.54batch/s]
Avg Loss : 0.9264 Validation Loss : 0.8075 Learning Late: 0.9372
Epoch 53: 100%|██████████| 98/98 [00:37<00:00,  2.61batch/s]
Avg Loss : 0.9612 Validation Loss : 0.8633 Learning Late: 0.9077
Epoch 54: 100%|██████████| 98/98 [00:38<00:00,  2.57batch/s]
Avg Loss : 0.8665 Validation Loss : 1.0469 Learning Late: 0.8781
Epoch 55: 100%|██████████| 98/98 [00:38<00:00,  2.54batch/s]
Avg Loss : 0.8564 Validation Loss : 0.7808 Learning Late: 0.8485
Epoch 56: 100%|██████████| 98/98 [00:37<00:00,  2.58batch/s]
Avg Loss : 0.8965 Validation Loss : 0.8798 Learning Late: 0.8189
Epoch 57: 100%|██████████| 98/98 [00:38<00:00,  2.52batch/s]
Avg Loss : 0.8105 Validation Loss : 0.8318 Learning Late: 0.7893
Epoch 58: 100%|██████████| 98/98 [00:38<00:00,  2.53batch/s]
Avg Loss : 0.8188 Validation Loss : 0.6880 Learning Late: 0.7598
Epoch 59: 100%|██████████| 98/98 [00:38<00:00,  2.55batch/s]
Avg Loss : 0.7612 Validation Loss : 0.6707 Learning Late: 0.7304
Epoch 60: 100%|██████████| 98/98 [00:37<00:00,  2.58batch/s]
Avg Loss : 0.8343 Validation Loss : 0.8038 Learning Late: 0.7012
Epoch 61: 100%|██████████| 98/98 [00:37<00:00,  2.62batch/s]
Avg Loss : 0.7950 Validation Loss : 0.7309 Learning Late: 0.6721
Epoch 62: 100%|██████████| 98/98 [00:38<00:00,  2.55batch/s]
Avg Loss : 0.8011 Validation Loss : 0.8216 Learning Late: 0.6433
Epoch 63: 100%|██████████| 98/98 [00:38<00:00,  2.56batch/s]
Avg Loss : 0.7234 Validation Loss : 0.8176 Learning Late: 0.6146
Epoch 64: 100%|██████████| 98/98 [00:37<00:00,  2.58batch/s]
Avg Loss : 0.7077 Validation Loss : 0.7494 Learning Late: 0.5863
Epoch 65: 100%|██████████| 98/98 [00:37<00:00,  2.60batch/s]
Avg Loss : 0.6973 Validation Loss : 0.6797 Learning Late: 0.5583
Epoch 66: 100%|██████████| 98/98 [00:37<00:00,  2.61batch/s]
Avg Loss : 0.6662 Validation Loss : 0.6040 Learning Late: 0.5307
Epoch 67: 100%|██████████| 98/98 [00:39<00:00,  2.51batch/s]
Avg Loss : 0.6838 Validation Loss : 0.6875 Learning Late: 0.5034
Epoch 68: 100%|██████████| 98/98 [00:37<00:00,  2.61batch/s]
Avg Loss : 0.6576 Validation Loss : 0.6258 Learning Late: 0.4766
Epoch 69: 100%|██████████| 98/98 [00:37<00:00,  2.61batch/s]
Avg Loss : 0.6617 Validation Loss : 0.6295 Learning Late: 0.4502
Epoch 70: 100%|██████████| 98/98 [00:38<00:00,  2.57batch/s]
Avg Loss : 0.6278 Validation Loss : 0.6879 Learning Late: 0.4243
Epoch 71: 100%|██████████| 98/98 [00:38<00:00,  2.56batch/s]
Avg Loss : 0.6287 Validation Loss : 0.6088 Learning Late: 0.3989
Epoch 72: 100%|██████████| 98/98 [00:38<00:00,  2.55batch/s]
Avg Loss : 0.6491 Validation Loss : 0.6055 Learning Late: 0.3740
Epoch 73: 100%|██████████| 98/98 [00:37<00:00,  2.61batch/s]
Avg Loss : 0.6842 Validation Loss : 0.5337 Learning Late: 0.3498
Epoch 74: 100%|██████████| 98/98 [00:38<00:00,  2.56batch/s]
Avg Loss : 0.6054 Validation Loss : 0.6665 Learning Late: 0.3261
Epoch 75: 100%|██████████| 98/98 [00:38<00:00,  2.57batch/s]
Avg Loss : 0.6353 Validation Loss : 0.5471 Learning Late: 0.3031
Epoch 76: 100%|██████████| 98/98 [00:37<00:00,  2.60batch/s]
Avg Loss : 0.6639 Validation Loss : 0.6519 Learning Late: 0.2808
Epoch 77: 100%|██████████| 98/98 [00:38<00:00,  2.55batch/s]
Avg Loss : 0.6384 Validation Loss : 0.5133 Learning Late: 0.2591
Epoch 78: 100%|██████████| 98/98 [00:38<00:00,  2.56batch/s]
Avg Loss : 0.6285 Validation Loss : 0.6023 Learning Late: 0.2381
Epoch 79: 100%|██████████| 98/98 [00:38<00:00,  2.57batch/s]
Avg Loss : 0.5843 Validation Loss : 0.5244 Learning Late: 0.2179
Epoch 80: 100%|██████████| 98/98 [00:37<00:00,  2.60batch/s]
Avg Loss : 0.6125 Validation Loss : 0.5526 Learning Late: 0.1985
Epoch 81: 100%|██████████| 98/98 [00:37<00:00,  2.61batch/s]
Avg Loss : 0.5346 Validation Loss : 0.4699 Learning Late: 0.1799
Epoch 82: 100%|██████████| 98/98 [00:38<00:00,  2.54batch/s]
Avg Loss : 0.5370 Validation Loss : 0.6370 Learning Late: 0.1621
Epoch 83: 100%|██████████| 98/98 [00:38<00:00,  2.55batch/s]
Avg Loss : 0.5632 Validation Loss : 0.5495 Learning Late: 0.1451
Epoch 84: 100%|██████████| 98/98 [00:38<00:00,  2.57batch/s]
Avg Loss : 0.5830 Validation Loss : 0.6064 Learning Late: 0.1289
Epoch 85: 100%|██████████| 98/98 [00:37<00:00,  2.61batch/s]
Avg Loss : 0.5478 Validation Loss : 0.4511 Learning Late: 0.1137
Epoch 86: 100%|██████████| 98/98 [00:37<00:00,  2.62batch/s]
Avg Loss : 0.5967 Validation Loss : 0.5207 Learning Late: 0.0993
Epoch 87: 100%|██████████| 98/98 [00:38<00:00,  2.56batch/s]
Avg Loss : 0.5515 Validation Loss : 0.4960 Learning Late: 0.0859
Epoch 88: 100%|██████████| 98/98 [00:38<00:00,  2.54batch/s]
Avg Loss : 0.5910 Validation Loss : 0.4901 Learning Late: 0.0734
Epoch 89: 100%|██████████| 98/98 [00:37<00:00,  2.60batch/s]
Avg Loss : 0.5832 Validation Loss : 0.5558 Learning Late: 0.0618
Epoch 90: 100%|██████████| 98/98 [00:37<00:00,  2.61batch/s]
Avg Loss : 0.5323 Validation Loss : 0.5612 Learning Late: 0.0512
Epoch 91: 100%|██████████| 98/98 [00:38<00:00,  2.57batch/s]
Avg Loss : 0.5584 Validation Loss : 0.6517 Learning Late: 0.0415
Epoch 92: 100%|██████████| 98/98 [00:38<00:00,  2.58batch/s]
Avg Loss : 0.5649 Validation Loss : 0.6087 Learning Late: 0.0329
Epoch 93: 100%|██████████| 98/98 [00:38<00:00,  2.55batch/s]
Avg Loss : 0.5277 Validation Loss : 0.5638 Learning Late: 0.0252
Epoch 94: 100%|██████████| 98/98 [00:37<00:00,  2.60batch/s]
Avg Loss : 0.5765 Validation Loss : 0.5334 Learning Late: 0.0185
Epoch 95: 100%|██████████| 98/98 [00:38<00:00,  2.56batch/s]
Avg Loss : 0.5912 Validation Loss : 0.4842 Learning Late: 0.0129
Epoch 96: 100%|██████████| 98/98 [00:37<00:00,  2.58batch/s]
Avg Loss : 0.5394 Validation Loss : 0.5107 Learning Late: 0.0083
Epoch 97: 100%|██████████| 98/98 [00:37<00:00,  2.61batch/s]
Avg Loss : 0.5707 Validation Loss : 0.6691 Learning Late: 0.0046
Epoch 98: 100%|██████████| 98/98 [00:37<00:00,  2.59batch/s]
Avg Loss : 0.5627 Validation Loss : 0.5228 Learning Late: 0.0021
Epoch 99: 100%|██████████| 98/98 [00:37<00:00,  2.59batch/s]
Avg Loss : 0.5673 Validation Loss : 0.6311 Learning Late: 0.0005
Epoch 100: 100%|██████████| 98/98 [00:37<00:00,  2.58batch/s]
Avg Loss : 0.5345 Validation Loss : 0.6043 Learning Late: 0.0000
FG 학습 완료. 이제 F의 output을 실제 dataset의 label과 연결.
Files already downloaded and verified
Files already downloaded and verified
Epoch 1: 100%|██████████| 391/391 [00:14<00:00, 27.03batch/s]
Avg Loss : 1.4985 Validation Loss : 1.3866 Learning Late: 0.0010
Epoch 2: 100%|██████████| 391/391 [00:14<00:00, 26.76batch/s]
Avg Loss : 1.3624 Validation Loss : 1.3377 Learning Late: 0.0010
Epoch 3: 100%|██████████| 391/391 [00:14<00:00, 26.78batch/s]
Avg Loss : 1.3244 Validation Loss : 1.3168 Learning Late: 0.0010
Epoch 4: 100%|██████████| 391/391 [00:14<00:00, 26.79batch/s]
Avg Loss : 1.2983 Validation Loss : 1.2936 Learning Late: 0.0010
Epoch 5: 100%|██████████| 391/391 [00:14<00:00, 26.86batch/s]
Avg Loss : 1.2807 Validation Loss : 1.2924 Learning Late: 0.0010
Epoch 6: 100%|██████████| 391/391 [00:14<00:00, 26.62batch/s]
Avg Loss : 1.2643 Validation Loss : 1.2801 Learning Late: 0.0010
Epoch 7: 100%|██████████| 391/391 [00:15<00:00, 24.79batch/s]
Avg Loss : 1.2532 Validation Loss : 1.2549 Learning Late: 0.0010
Epoch 8: 100%|██████████| 391/391 [00:14<00:00, 26.83batch/s]
Avg Loss : 1.2425 Validation Loss : 1.2462 Learning Late: 0.0010
Epoch 9: 100%|██████████| 391/391 [00:14<00:00, 26.63batch/s]
Avg Loss : 1.2348 Validation Loss : 1.2685 Learning Late: 0.0010
Epoch 10: 100%|██████████| 391/391 [00:14<00:00, 26.87batch/s]
Avg Loss : 1.2254 Validation Loss : 1.2534 Learning Late: 0.0010
Epoch 11: 100%|██████████| 391/391 [00:14<00:00, 26.79batch/s]
Avg Loss : 1.2198 Validation Loss : 1.2466 Learning Late: 0.0010
Epoch 12: 100%|██████████| 391/391 [00:14<00:00, 26.77batch/s]
Avg Loss : 1.2117 Validation Loss : 1.2439 Learning Late: 0.0010
Epoch 13: 100%|██████████| 391/391 [00:14<00:00, 26.59batch/s]
Avg Loss : 1.2055 Validation Loss : 1.2318 Learning Late: 0.0010
Epoch 14: 100%|██████████| 391/391 [00:14<00:00, 27.56batch/s]
Avg Loss : 1.1999 Validation Loss : 1.2320 Learning Late: 0.0010
Epoch 15: 100%|██████████| 391/391 [00:14<00:00, 27.22batch/s]
Avg Loss : 1.1960 Validation Loss : 1.2309 Learning Late: 0.0010
Epoch 16: 100%|██████████| 391/391 [00:14<00:00, 26.58batch/s]
Avg Loss : 1.1902 Validation Loss : 1.2269 Learning Late: 0.0010
Epoch 17: 100%|██████████| 391/391 [00:14<00:00, 26.49batch/s]
Avg Loss : 1.1872 Validation Loss : 1.2294 Learning Late: 0.0010
Epoch 18: 100%|██████████| 391/391 [00:14<00:00, 26.84batch/s]
Avg Loss : 1.1832 Validation Loss : 1.2148 Learning Late: 0.0010
Epoch 19: 100%|██████████| 391/391 [00:14<00:00, 26.51batch/s]
Avg Loss : 1.1785 Validation Loss : 1.2045 Learning Late: 0.0010
Epoch 20: 100%|██████████| 391/391 [00:15<00:00, 24.53batch/s]
Avg Loss : 1.1763 Validation Loss : 1.2045 Learning Late: 0.0010
Epoch 21: 100%|██████████| 391/391 [00:14<00:00, 26.70batch/s]
Avg Loss : 1.1734 Validation Loss : 1.2038 Learning Late: 0.0010
Epoch 22: 100%|██████████| 391/391 [00:14<00:00, 26.58batch/s]
Avg Loss : 1.1708 Validation Loss : 1.1920 Learning Late: 0.0010
Epoch 23: 100%|██████████| 391/391 [00:15<00:00, 26.04batch/s]
Avg Loss : 1.1666 Validation Loss : 1.2010 Learning Late: 0.0010
Epoch 24: 100%|██████████| 391/391 [00:14<00:00, 26.52batch/s]
Avg Loss : 1.1634 Validation Loss : 1.2019 Learning Late: 0.0010
Epoch 25: 100%|██████████| 391/391 [00:14<00:00, 26.70batch/s]
Avg Loss : 1.1591 Validation Loss : 1.2157 Learning Late: 0.0010
Epoch 26: 100%|██████████| 391/391 [00:14<00:00, 26.51batch/s]
Avg Loss : 1.1598 Validation Loss : 1.1911 Learning Late: 0.0010
Epoch 27: 100%|██████████| 391/391 [00:14<00:00, 26.55batch/s]
Avg Loss : 1.1562 Validation Loss : 1.1992 Learning Late: 0.0010
Epoch 28: 100%|██████████| 391/391 [00:14<00:00, 26.70batch/s]
Avg Loss : 1.1537 Validation Loss : 1.1903 Learning Late: 0.0010
Epoch 29: 100%|██████████| 391/391 [00:14<00:00, 26.97batch/s]
Avg Loss : 1.1525 Validation Loss : 1.2204 Learning Late: 0.0010
Epoch 30: 100%|██████████| 391/391 [00:14<00:00, 26.31batch/s]
Avg Loss : 1.1499 Validation Loss : 1.1954 Learning Late: 0.0010
Epoch 31: 100%|██████████| 391/391 [00:14<00:00, 26.83batch/s]
Avg Loss : 1.1487 Validation Loss : 1.2031 Learning Late: 0.0010
Epoch 32: 100%|██████████| 391/391 [00:14<00:00, 27.36batch/s]
Avg Loss : 1.1465 Validation Loss : 1.1954 Learning Late: 0.0010
Epoch 33: 100%|██████████| 391/391 [00:15<00:00, 25.21batch/s]
Avg Loss : 1.1448 Validation Loss : 1.1959 Learning Late: 0.0010
Epoch 34: 100%|██████████| 391/391 [00:15<00:00, 25.78batch/s]
Avg Loss : 1.1421 Validation Loss : 1.1870 Learning Late: 0.0010
Epoch 35: 100%|██████████| 391/391 [00:15<00:00, 24.79batch/s]
Avg Loss : 1.1426 Validation Loss : 1.1800 Learning Late: 0.0010
Epoch 36: 100%|██████████| 391/391 [00:15<00:00, 25.59batch/s]
Avg Loss : 1.1385 Validation Loss : 1.1858 Learning Late: 0.0010
Epoch 37: 100%|██████████| 391/391 [00:15<00:00, 26.05batch/s]
Avg Loss : 1.1369 Validation Loss : 1.1850 Learning Late: 0.0010
Epoch 38: 100%|██████████| 391/391 [00:14<00:00, 26.65batch/s]
Avg Loss : 1.1373 Validation Loss : 1.1870 Learning Late: 0.0009
Epoch 39: 100%|██████████| 391/391 [00:14<00:00, 26.60batch/s]
Avg Loss : 1.1346 Validation Loss : 1.1869 Learning Late: 0.0009
Epoch 40: 100%|██████████| 391/391 [00:14<00:00, 26.58batch/s]
Avg Loss : 1.1341 Validation Loss : 1.1795 Learning Late: 0.0009
Epoch 41: 100%|██████████| 391/391 [00:14<00:00, 26.25batch/s]
Avg Loss : 1.1326 Validation Loss : 1.1820 Learning Late: 0.0009
Epoch 42: 100%|██████████| 391/391 [00:14<00:00, 26.20batch/s]
Avg Loss : 1.1312 Validation Loss : 1.1796 Learning Late: 0.0009
Epoch 43: 100%|██████████| 391/391 [00:14<00:00, 27.02batch/s]
Avg Loss : 1.1284 Validation Loss : 1.1857 Learning Late: 0.0009
Epoch 44: 100%|██████████| 391/391 [00:14<00:00, 26.49batch/s]
Avg Loss : 1.1285 Validation Loss : 1.1741 Learning Late: 0.0009
Epoch 45: 100%|██████████| 391/391 [00:14<00:00, 26.54batch/s]
Avg Loss : 1.1281 Validation Loss : 1.1827 Learning Late: 0.0009
Epoch 46: 100%|██████████| 391/391 [00:14<00:00, 26.94batch/s]
Avg Loss : 1.1257 Validation Loss : 1.1752 Learning Late: 0.0009
Epoch 47: 100%|██████████| 391/391 [00:14<00:00, 26.34batch/s]
Avg Loss : 1.1255 Validation Loss : 1.1755 Learning Late: 0.0009
Epoch 48: 100%|██████████| 391/391 [00:14<00:00, 26.45batch/s]
Avg Loss : 1.1264 Validation Loss : 1.1755 Learning Late: 0.0009
Epoch 49: 100%|██████████| 391/391 [00:14<00:00, 26.12batch/s]
Avg Loss : 1.1235 Validation Loss : 1.1809 Learning Late: 0.0009
Epoch 50: 100%|██████████| 391/391 [00:14<00:00, 26.57batch/s]
Avg Loss : 1.1220 Validation Loss : 1.1793 Learning Late: 0.0009
Epoch 51: 100%|██████████| 391/391 [00:14<00:00, 26.34batch/s]
Avg Loss : 1.1207 Validation Loss : 1.1678 Learning Late: 0.0009
Epoch 52: 100%|██████████| 391/391 [00:14<00:00, 26.74batch/s]
Avg Loss : 1.1194 Validation Loss : 1.1705 Learning Late: 0.0009
Epoch 53: 100%|██████████| 391/391 [00:14<00:00, 26.55batch/s]
Avg Loss : 1.1191 Validation Loss : 1.1726 Learning Late: 0.0009
Epoch 54: 100%|██████████| 391/391 [00:14<00:00, 26.55batch/s]
Avg Loss : 1.1180 Validation Loss : 1.1743 Learning Late: 0.0009
Epoch 55: 100%|██████████| 391/391 [00:14<00:00, 26.15batch/s]
Avg Loss : 1.1183 Validation Loss : 1.1698 Learning Late: 0.0009
Epoch 56: 100%|██████████| 391/391 [00:15<00:00, 26.04batch/s]
Avg Loss : 1.1169 Validation Loss : 1.1661 Learning Late: 0.0009
Epoch 57: 100%|██████████| 391/391 [00:14<00:00, 26.51batch/s]
Avg Loss : 1.1159 Validation Loss : 1.1803 Learning Late: 0.0009
Epoch 58: 100%|██████████| 391/391 [00:16<00:00, 23.74batch/s]
Avg Loss : 1.1162 Validation Loss : 1.1784 Learning Late: 0.0009
Epoch 59: 100%|██████████| 391/391 [00:14<00:00, 26.66batch/s]
Avg Loss : 1.1141 Validation Loss : 1.1769 Learning Late: 0.0008
Epoch 60: 100%|██████████| 391/391 [00:14<00:00, 26.27batch/s]
Avg Loss : 1.1121 Validation Loss : 1.1747 Learning Late: 0.0008
Epoch 61: 100%|██████████| 391/391 [00:14<00:00, 26.28batch/s]
Avg Loss : 1.1120 Validation Loss : 1.1677 Learning Late: 0.0008
Epoch 62: 100%|██████████| 391/391 [00:14<00:00, 26.39batch/s]
Avg Loss : 1.1104 Validation Loss : 1.1843 Learning Late: 0.0008
Epoch 63: 100%|██████████| 391/391 [00:14<00:00, 26.13batch/s]
Avg Loss : 1.1114 Validation Loss : 1.1856 Learning Late: 0.0008
Epoch 64: 100%|██████████| 391/391 [00:14<00:00, 26.13batch/s]
Avg Loss : 1.1091 Validation Loss : 1.1706 Learning Late: 0.0008
Epoch 65: 100%|██████████| 391/391 [00:15<00:00, 25.76batch/s]
Avg Loss : 1.1087 Validation Loss : 1.1748 Learning Late: 0.0008
Epoch 66: 100%|██████████| 391/391 [00:14<00:00, 26.28batch/s]
Avg Loss : 1.1089 Validation Loss : 1.1819 Learning Late: 0.0008
Epoch 67: 100%|██████████| 391/391 [00:14<00:00, 26.13batch/s]
Avg Loss : 1.1083 Validation Loss : 1.1632 Learning Late: 0.0008
Epoch 68: 100%|██████████| 391/391 [00:14<00:00, 26.38batch/s]
Avg Loss : 1.1060 Validation Loss : 1.1743 Learning Late: 0.0008
Epoch 69: 100%|██████████| 391/391 [00:14<00:00, 26.07batch/s]
Avg Loss : 1.1060 Validation Loss : 1.1736 Learning Late: 0.0008
Epoch 70: 100%|██████████| 391/391 [00:14<00:00, 26.11batch/s]
Avg Loss : 1.1059 Validation Loss : 1.1612 Learning Late: 0.0008
Epoch 71: 100%|██████████| 391/391 [00:14<00:00, 26.83batch/s]
Avg Loss : 1.1042 Validation Loss : 1.1740 Learning Late: 0.0008
Epoch 72: 100%|██████████| 391/391 [00:14<00:00, 26.59batch/s]
Avg Loss : 1.1051 Validation Loss : 1.1655 Learning Late: 0.0008
Epoch 73: 100%|██████████| 391/391 [00:14<00:00, 26.65batch/s]
Avg Loss : 1.1041 Validation Loss : 1.1645 Learning Late: 0.0008
Epoch 74: 100%|██████████| 391/391 [00:14<00:00, 26.20batch/s]
Avg Loss : 1.1036 Validation Loss : 1.1583 Learning Late: 0.0007
Epoch 75: 100%|██████████| 391/391 [00:14<00:00, 26.37batch/s]
Avg Loss : 1.1028 Validation Loss : 1.1643 Learning Late: 0.0007
Epoch 76: 100%|██████████| 391/391 [00:15<00:00, 26.06batch/s]
Avg Loss : 1.1011 Validation Loss : 1.1659 Learning Late: 0.0007
Epoch 77: 100%|██████████| 391/391 [00:14<00:00, 26.29batch/s]
Avg Loss : 1.1006 Validation Loss : 1.1615 Learning Late: 0.0007
Epoch 78: 100%|██████████| 391/391 [00:14<00:00, 26.22batch/s]
Avg Loss : 1.1012 Validation Loss : 1.1614 Learning Late: 0.0007
Epoch 79: 100%|██████████| 391/391 [00:15<00:00, 26.06batch/s]
Avg Loss : 1.0980 Validation Loss : 1.1650 Learning Late: 0.0007
Epoch 80: 100%|██████████| 391/391 [00:14<00:00, 26.39batch/s]
Avg Loss : 1.0997 Validation Loss : 1.1638 Learning Late: 0.0007
Epoch 81: 100%|██████████| 391/391 [00:14<00:00, 26.31batch/s]
Avg Loss : 1.1000 Validation Loss : 1.1610 Learning Late: 0.0007
Epoch 82: 100%|██████████| 391/391 [00:14<00:00, 26.99batch/s]
Avg Loss : 1.0977 Validation Loss : 1.1667 Learning Late: 0.0007
Epoch 83: 100%|██████████| 391/391 [00:15<00:00, 25.03batch/s]
Avg Loss : 1.0980 Validation Loss : 1.1586 Learning Late: 0.0007
Epoch 84: 100%|██████████| 391/391 [00:14<00:00, 26.58batch/s]
Avg Loss : 1.0969 Validation Loss : 1.1638 Learning Late: 0.0007
Epoch 85: 100%|██████████| 391/391 [00:14<00:00, 26.44batch/s]
Avg Loss : 1.0963 Validation Loss : 1.1572 Learning Late: 0.0007
Epoch 86: 100%|██████████| 391/391 [00:15<00:00, 25.79batch/s]
Avg Loss : 1.0959 Validation Loss : 1.1598 Learning Late: 0.0007
Epoch 87: 100%|██████████| 391/391 [00:14<00:00, 26.29batch/s]
Avg Loss : 1.0961 Validation Loss : 1.1686 Learning Late: 0.0006
Epoch 88: 100%|██████████| 391/391 [00:14<00:00, 26.34batch/s]
Avg Loss : 1.0948 Validation Loss : 1.1592 Learning Late: 0.0006
Epoch 89: 100%|██████████| 391/391 [00:14<00:00, 26.36batch/s]
Avg Loss : 1.0940 Validation Loss : 1.1543 Learning Late: 0.0006
Epoch 90: 100%|██████████| 391/391 [00:15<00:00, 25.98batch/s]
Avg Loss : 1.0943 Validation Loss : 1.1658 Learning Late: 0.0006
Epoch 91: 100%|██████████| 391/391 [00:14<00:00, 26.44batch/s]
Avg Loss : 1.0944 Validation Loss : 1.1610 Learning Late: 0.0006
Epoch 92: 100%|██████████| 391/391 [00:15<00:00, 25.90batch/s]
Avg Loss : 1.0935 Validation Loss : 1.1599 Learning Late: 0.0006
Epoch 93: 100%|██████████| 391/391 [00:15<00:00, 25.58batch/s]
Avg Loss : 1.0919 Validation Loss : 1.1619 Learning Late: 0.0006
Epoch 94: 100%|██████████| 391/391 [00:14<00:00, 26.56batch/s]
Avg Loss : 1.0920 Validation Loss : 1.1636 Learning Late: 0.0006
Epoch 95: 100%|██████████| 391/391 [00:14<00:00, 26.39batch/s]
Avg Loss : 1.0921 Validation Loss : 1.1635 Learning Late: 0.0006
Epoch 96: 100%|██████████| 391/391 [00:16<00:00, 23.67batch/s]
Avg Loss : 1.0914 Validation Loss : 1.1621 Learning Late: 0.0006
Epoch 97: 100%|██████████| 391/391 [00:15<00:00, 26.03batch/s]
Avg Loss : 1.0916 Validation Loss : 1.1600 Learning Late: 0.0006
Epoch 98: 100%|██████████| 391/391 [00:14<00:00, 26.10batch/s]
Avg Loss : 1.0910 Validation Loss : 1.1605 Learning Late: 0.0006
Epoch 99: 100%|██████████| 391/391 [00:15<00:00, 25.90batch/s]
Avg Loss : 1.0893 Validation Loss : 1.1686 Learning Late: 0.0005
Epoch 100: 100%|██████████| 391/391 [00:15<00:00, 25.91batch/s]
Avg Loss : 1.0900 Validation Loss : 1.1572 Learning Late: 0.0005
Epoch 101: 100%|██████████| 391/391 [00:14<00:00, 26.27batch/s]
Avg Loss : 1.0903 Validation Loss : 1.1575 Learning Late: 0.0005
Epoch 102: 100%|██████████| 391/391 [00:14<00:00, 26.18batch/s]
Avg Loss : 1.0891 Validation Loss : 1.1590 Learning Late: 0.0005
Epoch 103: 100%|██████████| 391/391 [00:15<00:00, 25.98batch/s]
Avg Loss : 1.0888 Validation Loss : 1.1576 Learning Late: 0.0005
Epoch 104: 100%|██████████| 391/391 [00:14<00:00, 26.46batch/s]
Avg Loss : 1.0878 Validation Loss : 1.1666 Learning Late: 0.0005
Epoch 105: 100%|██████████| 391/391 [00:14<00:00, 26.89batch/s]
Avg Loss : 1.0871 Validation Loss : 1.1556 Learning Late: 0.0005
Epoch 106: 100%|██████████| 391/391 [00:14<00:00, 26.14batch/s]
Avg Loss : 1.0869 Validation Loss : 1.1614 Learning Late: 0.0005
Epoch 107: 100%|██████████| 391/391 [00:14<00:00, 26.16batch/s]
Avg Loss : 1.0874 Validation Loss : 1.1608 Learning Late: 0.0005
Epoch 108: 100%|██████████| 391/391 [00:15<00:00, 24.96batch/s]
Avg Loss : 1.0863 Validation Loss : 1.1581 Learning Late: 0.0005
Epoch 109: 100%|██████████| 391/391 [00:14<00:00, 26.09batch/s]
Avg Loss : 1.0858 Validation Loss : 1.1557 Learning Late: 0.0005
Epoch 110: 100%|██████████| 391/391 [00:15<00:00, 25.96batch/s]
Avg Loss : 1.0845 Validation Loss : 1.1561 Learning Late: 0.0005
Epoch 111: 100%|██████████| 391/391 [00:15<00:00, 25.92batch/s]
Avg Loss : 1.0845 Validation Loss : 1.1574 Learning Late: 0.0005
Epoch 112: 100%|██████████| 391/391 [00:14<00:00, 26.23batch/s]
Avg Loss : 1.0850 Validation Loss : 1.1641 Learning Late: 0.0004
Epoch 113: 100%|██████████| 391/391 [00:15<00:00, 25.77batch/s]
Avg Loss : 1.0841 Validation Loss : 1.1517 Learning Late: 0.0004
Epoch 114: 100%|██████████| 391/391 [00:15<00:00, 25.72batch/s]
Avg Loss : 1.0841 Validation Loss : 1.1595 Learning Late: 0.0004
Epoch 115: 100%|██████████| 391/391 [00:14<00:00, 26.07batch/s]
Avg Loss : 1.0836 Validation Loss : 1.1498 Learning Late: 0.0004
Epoch 116: 100%|██████████| 391/391 [00:15<00:00, 26.01batch/s]
Avg Loss : 1.0831 Validation Loss : 1.1573 Learning Late: 0.0004
Epoch 117: 100%|██████████| 391/391 [00:14<00:00, 26.60batch/s]
Avg Loss : 1.0828 Validation Loss : 1.1535 Learning Late: 0.0004
Epoch 118: 100%|██████████| 391/391 [00:14<00:00, 26.32batch/s]
Avg Loss : 1.0831 Validation Loss : 1.1624 Learning Late: 0.0004
Epoch 119: 100%|██████████| 391/391 [00:14<00:00, 26.38batch/s]
Avg Loss : 1.0819 Validation Loss : 1.1584 Learning Late: 0.0004
Epoch 120: 100%|██████████| 391/391 [00:15<00:00, 25.98batch/s]
Avg Loss : 1.0816 Validation Loss : 1.1573 Learning Late: 0.0004
Epoch 121: 100%|██████████| 391/391 [00:16<00:00, 23.79batch/s]
Avg Loss : 1.0809 Validation Loss : 1.1550 Learning Late: 0.0004
Epoch 122: 100%|██████████| 391/391 [00:15<00:00, 26.04batch/s]
Avg Loss : 1.0814 Validation Loss : 1.1557 Learning Late: 0.0004
Epoch 123: 100%|██████████| 391/391 [00:14<00:00, 26.16batch/s]
Avg Loss : 1.0801 Validation Loss : 1.1573 Learning Late: 0.0004
Epoch 124: 100%|██████████| 391/391 [00:15<00:00, 26.03batch/s]
Avg Loss : 1.0805 Validation Loss : 1.1499 Learning Late: 0.0003
Epoch 125: 100%|██████████| 391/391 [00:15<00:00, 25.93batch/s]
Avg Loss : 1.0804 Validation Loss : 1.1541 Learning Late: 0.0003
Epoch 126: 100%|██████████| 391/391 [00:14<00:00, 26.76batch/s]
Avg Loss : 1.0796 Validation Loss : 1.1580 Learning Late: 0.0003
Epoch 127: 100%|██████████| 391/391 [00:14<00:00, 26.07batch/s]
Avg Loss : 1.0804 Validation Loss : 1.1556 Learning Late: 0.0003
Epoch 128: 100%|██████████| 391/391 [00:15<00:00, 25.72batch/s]
Avg Loss : 1.0794 Validation Loss : 1.1564 Learning Late: 0.0003
Epoch 129: 100%|██████████| 391/391 [00:15<00:00, 26.01batch/s]
Avg Loss : 1.0794 Validation Loss : 1.1558 Learning Late: 0.0003
Epoch 130: 100%|██████████| 391/391 [00:15<00:00, 26.06batch/s]
Avg Loss : 1.0786 Validation Loss : 1.1555 Learning Late: 0.0003
Epoch 131: 100%|██████████| 391/391 [00:15<00:00, 25.83batch/s]
Avg Loss : 1.0782 Validation Loss : 1.1580 Learning Late: 0.0003
Epoch 132: 100%|██████████| 391/391 [00:15<00:00, 25.74batch/s]
Avg Loss : 1.0787 Validation Loss : 1.1513 Learning Late: 0.0003
Epoch 133: 100%|██████████| 391/391 [00:16<00:00, 23.95batch/s]
Avg Loss : 1.0787 Validation Loss : 1.1509 Learning Late: 0.0003
Epoch 134: 100%|██████████| 391/391 [00:15<00:00, 25.57batch/s]
Avg Loss : 1.0768 Validation Loss : 1.1565 Learning Late: 0.0003
Epoch 135: 100%|██████████| 391/391 [00:15<00:00, 25.74batch/s]
Avg Loss : 1.0771 Validation Loss : 1.1527 Learning Late: 0.0003
Epoch 136: 100%|██████████| 391/391 [00:15<00:00, 25.91batch/s]
Avg Loss : 1.0772 Validation Loss : 1.1505 Learning Late: 0.0003
Epoch 137: 100%|██████████| 391/391 [00:14<00:00, 26.48batch/s]
Avg Loss : 1.0764 Validation Loss : 1.1517 Learning Late: 0.0002
Epoch 138: 100%|██████████| 391/391 [00:15<00:00, 25.86batch/s]
Avg Loss : 1.0763 Validation Loss : 1.1500 Learning Late: 0.0002
Epoch 139: 100%|██████████| 391/391 [00:15<00:00, 25.63batch/s]
Avg Loss : 1.0757 Validation Loss : 1.1506 Learning Late: 0.0002
Epoch 140: 100%|██████████| 391/391 [00:15<00:00, 26.04batch/s]
Avg Loss : 1.0767 Validation Loss : 1.1508 Learning Late: 0.0002
Epoch 141: 100%|██████████| 391/391 [00:15<00:00, 25.58batch/s]
Avg Loss : 1.0760 Validation Loss : 1.1503 Learning Late: 0.0002
Epoch 142: 100%|██████████| 391/391 [00:15<00:00, 25.78batch/s]
Avg Loss : 1.0755 Validation Loss : 1.1515 Learning Late: 0.0002
Epoch 143: 100%|██████████| 391/391 [00:15<00:00, 25.93batch/s]
Avg Loss : 1.0750 Validation Loss : 1.1526 Learning Late: 0.0002
Epoch 144: 100%|██████████| 391/391 [00:15<00:00, 25.61batch/s]
Avg Loss : 1.0744 Validation Loss : 1.1559 Learning Late: 0.0002
Epoch 145: 100%|██████████| 391/391 [00:15<00:00, 25.74batch/s]
Avg Loss : 1.0749 Validation Loss : 1.1485 Learning Late: 0.0002
Epoch 146: 100%|██████████| 391/391 [00:15<00:00, 24.98batch/s]
Avg Loss : 1.0746 Validation Loss : 1.1495 Learning Late: 0.0002
Epoch 147: 100%|██████████| 391/391 [00:14<00:00, 26.52batch/s]
Avg Loss : 1.0734 Validation Loss : 1.1595 Learning Late: 0.0002
Epoch 148: 100%|██████████| 391/391 [00:15<00:00, 25.78batch/s]
Avg Loss : 1.0744 Validation Loss : 1.1555 Learning Late: 0.0002
Epoch 149: 100%|██████████| 391/391 [00:15<00:00, 25.59batch/s]
Avg Loss : 1.0737 Validation Loss : 1.1529 Learning Late: 0.0002
Epoch 150: 100%|██████████| 391/391 [00:15<00:00, 25.95batch/s]
Avg Loss : 1.0736 Validation Loss : 1.1493 Learning Late: 0.0002
Epoch 151: 100%|██████████| 391/391 [00:15<00:00, 25.84batch/s]
Avg Loss : 1.0730 Validation Loss : 1.1502 Learning Late: 0.0002
Epoch 152: 100%|██████████| 391/391 [00:15<00:00, 25.74batch/s]
Avg Loss : 1.0732 Validation Loss : 1.1521 Learning Late: 0.0001
Epoch 153: 100%|██████████| 391/391 [00:15<00:00, 25.69batch/s]
Avg Loss : 1.0729 Validation Loss : 1.1509 Learning Late: 0.0001
Epoch 154: 100%|██████████| 391/391 [00:14<00:00, 26.20batch/s]
Avg Loss : 1.0727 Validation Loss : 1.1464 Learning Late: 0.0001
Epoch 155: 100%|██████████| 391/391 [00:15<00:00, 25.60batch/s]
Avg Loss : 1.0721 Validation Loss : 1.1496 Learning Late: 0.0001
Epoch 156: 100%|██████████| 391/391 [00:15<00:00, 25.82batch/s]
Avg Loss : 1.0719 Validation Loss : 1.1457 Learning Late: 0.0001
Epoch 157: 100%|██████████| 391/391 [00:14<00:00, 26.36batch/s]
Avg Loss : 1.0723 Validation Loss : 1.1585 Learning Late: 0.0001
Epoch 158: 100%|██████████| 391/391 [00:16<00:00, 24.34batch/s]
Avg Loss : 1.0720 Validation Loss : 1.1533 Learning Late: 0.0001
Epoch 159: 100%|██████████| 391/391 [00:15<00:00, 25.94batch/s]
Avg Loss : 1.0720 Validation Loss : 1.1546 Learning Late: 0.0001
Epoch 160: 100%|██████████| 391/391 [00:15<00:00, 25.68batch/s]
Avg Loss : 1.0712 Validation Loss : 1.1501 Learning Late: 0.0001
Epoch 161: 100%|██████████| 391/391 [00:15<00:00, 25.74batch/s]
Avg Loss : 1.0712 Validation Loss : 1.1524 Learning Late: 0.0001
Epoch 162: 100%|██████████| 391/391 [00:15<00:00, 25.07batch/s]
Avg Loss : 1.0715 Validation Loss : 1.1493 Learning Late: 0.0001
Epoch 163: 100%|██████████| 391/391 [00:15<00:00, 25.80batch/s]
Avg Loss : 1.0711 Validation Loss : 1.1480 Learning Late: 0.0001
Epoch 164: 100%|██████████| 391/391 [00:15<00:00, 25.84batch/s]
Avg Loss : 1.0708 Validation Loss : 1.1459 Learning Late: 0.0001
Epoch 165: 100%|██████████| 391/391 [00:15<00:00, 25.88batch/s]
Avg Loss : 1.0706 Validation Loss : 1.1494 Learning Late: 0.0001
Epoch 166: 100%|██████████| 391/391 [00:15<00:00, 25.76batch/s]
Avg Loss : 1.0705 Validation Loss : 1.1513 Learning Late: 0.0001
Epoch 167: 100%|██████████| 391/391 [00:15<00:00, 25.33batch/s]
Avg Loss : 1.0701 Validation Loss : 1.1575 Learning Late: 0.0001
Epoch 168: 100%|██████████| 391/391 [00:15<00:00, 25.76batch/s]
Avg Loss : 1.0701 Validation Loss : 1.1479 Learning Late: 0.0001
Epoch 169: 100%|██████████| 391/391 [00:15<00:00, 25.61batch/s]
Avg Loss : 1.0700 Validation Loss : 1.1491 Learning Late: 0.0001
Epoch 170: 100%|██████████| 391/391 [00:15<00:00, 24.58batch/s]
Avg Loss : 1.0696 Validation Loss : 1.1491 Learning Late: 0.0001
Epoch 171: 100%|██████████| 391/391 [00:15<00:00, 25.74batch/s]
Avg Loss : 1.0699 Validation Loss : 1.1468 Learning Late: 0.0001
Epoch 172: 100%|██████████| 391/391 [00:15<00:00, 25.51batch/s]
Avg Loss : 1.0695 Validation Loss : 1.1500 Learning Late: 0.0001
Epoch 173: 100%|██████████| 391/391 [00:14<00:00, 26.49batch/s]
Avg Loss : 1.0696 Validation Loss : 1.1512 Learning Late: 0.0000
Epoch 174: 100%|██████████| 391/391 [00:15<00:00, 25.94batch/s]
Avg Loss : 1.0692 Validation Loss : 1.1505 Learning Late: 0.0000
Epoch 175: 100%|██████████| 391/391 [00:15<00:00, 25.52batch/s]
Avg Loss : 1.0693 Validation Loss : 1.1501 Learning Late: 0.0000
Epoch 176: 100%|██████████| 391/391 [00:15<00:00, 25.94batch/s]
Avg Loss : 1.0689 Validation Loss : 1.1456 Learning Late: 0.0000
Epoch 177: 100%|██████████| 391/391 [00:15<00:00, 25.69batch/s]
Avg Loss : 1.0690 Validation Loss : 1.1478 Learning Late: 0.0000
Epoch 178: 100%|██████████| 391/391 [00:15<00:00, 25.81batch/s]
Avg Loss : 1.0689 Validation Loss : 1.1506 Learning Late: 0.0000
Epoch 179: 100%|██████████| 391/391 [00:15<00:00, 25.37batch/s]
Avg Loss : 1.0689 Validation Loss : 1.1526 Learning Late: 0.0000
Epoch 180: 100%|██████████| 391/391 [00:15<00:00, 25.84batch/s]
Avg Loss : 1.0684 Validation Loss : 1.1524 Learning Late: 0.0000
Epoch 181: 100%|██████████| 391/391 [00:15<00:00, 25.58batch/s]
Avg Loss : 1.0685 Validation Loss : 1.1513 Learning Late: 0.0000
Epoch 182: 100%|██████████| 391/391 [00:15<00:00, 25.75batch/s]
Avg Loss : 1.0684 Validation Loss : 1.1472 Learning Late: 0.0000
Epoch 183: 100%|██████████| 391/391 [00:16<00:00, 23.73batch/s]
Avg Loss : 1.0682 Validation Loss : 1.1510 Learning Late: 0.0000
Epoch 184: 100%|██████████| 391/391 [00:15<00:00, 26.05batch/s]
Avg Loss : 1.0682 Validation Loss : 1.1473 Learning Late: 0.0000
Epoch 185: 100%|██████████| 391/391 [00:15<00:00, 25.65batch/s]
Avg Loss : 1.0683 Validation Loss : 1.1535 Learning Late: 0.0000
Epoch 186: 100%|██████████| 391/391 [00:15<00:00, 25.74batch/s]
Avg Loss : 1.0681 Validation Loss : 1.1468 Learning Late: 0.0000
Epoch 187: 100%|██████████| 391/391 [00:15<00:00, 25.67batch/s]
Avg Loss : 1.0681 Validation Loss : 1.1511 Learning Late: 0.0000
Epoch 188: 100%|██████████| 391/391 [00:15<00:00, 25.65batch/s]
Avg Loss : 1.0679 Validation Loss : 1.1449 Learning Late: 0.0000
Epoch 189: 100%|██████████| 391/391 [00:15<00:00, 25.41batch/s]
Avg Loss : 1.0678 Validation Loss : 1.1538 Learning Late: 0.0000
Epoch 190: 100%|██████████| 391/391 [00:15<00:00, 25.56batch/s]
Avg Loss : 1.0679 Validation Loss : 1.1491 Learning Late: 0.0000
Epoch 191: 100%|██████████| 391/391 [00:15<00:00, 26.04batch/s]
Avg Loss : 1.0679 Validation Loss : 1.1464 Learning Late: 0.0000
Epoch 192: 100%|██████████| 391/391 [00:14<00:00, 26.23batch/s]
Avg Loss : 1.0678 Validation Loss : 1.1500 Learning Late: 0.0000
Epoch 193: 100%|██████████| 391/391 [00:15<00:00, 25.86batch/s]
Avg Loss : 1.0675 Validation Loss : 1.1519 Learning Late: 0.0000
Epoch 194: 100%|██████████| 391/391 [00:15<00:00, 25.57batch/s]
Avg Loss : 1.0676 Validation Loss : 1.1482 Learning Late: 0.0000
Epoch 195: 100%|██████████| 391/391 [00:15<00:00, 24.86batch/s]
Avg Loss : 1.0675 Validation Loss : 1.1436 Learning Late: 0.0000
Epoch 196: 100%|██████████| 391/391 [00:15<00:00, 25.10batch/s]
Avg Loss : 1.0675 Validation Loss : 1.1508 Learning Late: 0.0000
Epoch 197: 100%|██████████| 391/391 [00:15<00:00, 25.57batch/s]
Avg Loss : 1.0675 Validation Loss : 1.1485 Learning Late: 0.0000
Epoch 198: 100%|██████████| 391/391 [00:15<00:00, 25.54batch/s]
Avg Loss : 1.0675 Validation Loss : 1.1471 Learning Late: 0.0000
Epoch 199: 100%|██████████| 391/391 [00:15<00:00, 25.79batch/s]
Avg Loss : 1.0675 Validation Loss : 1.1517 Learning Late: 0.0000
Epoch 200: 100%|██████████| 391/391 [00:14<00:00, 26.28batch/s]
Avg Loss : 1.0676 Validation Loss : 1.1495 Learning Late: 0.0000
실제 test
100%|██████████| 79/79 [00:02<00:00, 34.08batch/s]
총 개수 : 10000
top-1 맞춘 개수 : 5929 
 정확도: 59.29
top-5 맞춘 개수 : 9531 
 정확도: 95.31

top-1 SAM : 5849 LARS : 5905 SGD : 5929
top-5 SAM : 9537 LARS : 9583 SGD : 9531