C:\Users\kimJuhwan\anaconda3\envs\pytorch\python.exe E:\github\simclrExe\main_correct.py
Files already downloaded and verified
Files already downloaded and verified
  0%|          | 0/391 [00:00<?, ?batch/s]===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
SimCLR                                        [128, 512]                --
├─ResNet: 1-1                                 [128, 512]                --
│    └─Conv2d: 2-1                            [128, 64, 32, 32]         1,728
│    └─BatchNorm2d: 2-2                       [128, 64, 32, 32]         128
│    └─ReLU: 2-3                              [128, 64, 32, 32]         --
│    └─Identity: 2-4                          [128, 64, 32, 32]         --
│    └─Sequential: 2-5                        [128, 64, 32, 32]         --
│    │    └─BasicBlock: 3-1                   [128, 64, 32, 32]         73,984
│    │    └─BasicBlock: 3-2                   [128, 64, 32, 32]         73,984
│    └─Sequential: 2-6                        [128, 128, 16, 16]        --
│    │    └─BasicBlock: 3-3                   [128, 128, 16, 16]        230,144
│    │    └─BasicBlock: 3-4                   [128, 128, 16, 16]        295,424
│    └─Sequential: 2-7                        [128, 256, 8, 8]          --
│    │    └─BasicBlock: 3-5                   [128, 256, 8, 8]          919,040
│    │    └─BasicBlock: 3-6                   [128, 256, 8, 8]          1,180,672
│    └─Sequential: 2-8                        [128, 512, 4, 4]          --
│    │    └─BasicBlock: 3-7                   [128, 512, 4, 4]          3,673,088
│    │    └─BasicBlock: 3-8                   [128, 512, 4, 4]          4,720,640
│    └─AdaptiveAvgPool2d: 2-9                 [128, 512, 1, 1]          --
│    └─Identity: 2-10                         [128, 512]                --
├─Sequential: 1-2                             [128, 128]                --
│    └─Linear: 2-11                           [128, 512]                262,144
│    └─ReLU: 2-12                             [128, 512]                --
│    └─Linear: 2-13                           [128, 128]                65,536
===============================================================================================
Total params: 11,496,512
Trainable params: 11,496,512
Non-trainable params: 0
Total mult-adds (Units.GIGABYTES): 71.14
===============================================================================================
Input size (MB): 1.57
Forward/backward pass size (MB): 1258.95
Params size (MB): 45.99
Estimated Total Size (MB): 1306.51
===============================================================================================
Epoch 1: 100%|██████████| 391/391 [02:14<00:00,  2.91batch/s]
Avg Loss : 4.3836 Validation Loss : 3.8016 Learning Late: 0.8485
Epoch 2: 100%|██████████| 391/391 [02:09<00:00,  3.01batch/s]
Avg Loss : 3.4751 Validation Loss : 3.2286 Learning Late: 0.8485
Epoch 3: 100%|██████████| 391/391 [02:09<00:00,  3.01batch/s]
Avg Loss : 2.9487 Validation Loss : 2.5010 Learning Late: 0.8485
Epoch 4: 100%|██████████| 391/391 [02:08<00:00,  3.03batch/s]
Avg Loss : 2.4990 Validation Loss : 2.4428 Learning Late: 0.8485
Epoch 5: 100%|██████████| 391/391 [02:08<00:00,  3.03batch/s]
Avg Loss : 1.8121 Validation Loss : 1.5295 Learning Late: 0.8485
Epoch 6: 100%|██████████| 391/391 [02:08<00:00,  3.03batch/s]
Avg Loss : 1.6333 Validation Loss : 1.4305 Learning Late: 0.8485
Epoch 7: 100%|██████████| 391/391 [02:09<00:00,  3.03batch/s]
Avg Loss : 1.2977 Validation Loss : 1.1304 Learning Late: 0.8485
Epoch 8: 100%|██████████| 391/391 [02:08<00:00,  3.03batch/s]
Avg Loss : 1.0168 Validation Loss : 0.9903 Learning Late: 0.8485
Epoch 9: 100%|██████████| 391/391 [02:08<00:00,  3.03batch/s]
Avg Loss : 0.8544 Validation Loss : 0.7451 Learning Late: 0.8485
Epoch 10: 100%|██████████| 391/391 [02:08<00:00,  3.04batch/s]
Avg Loss : 0.7222 Validation Loss : 0.5983 Learning Late: 0.8485
Epoch 11: 100%|██████████| 391/391 [02:08<00:00,  3.03batch/s]
Avg Loss : 0.5839 Validation Loss : 0.4957 Learning Late: 0.8483
Epoch 12: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.5187 Validation Loss : 0.4570 Learning Late: 0.8475
Epoch 13: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.5255 Validation Loss : 0.4364 Learning Late: 0.8462
Epoch 14: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.4194 Validation Loss : 0.4276 Learning Late: 0.8444
Epoch 15: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.3908 Validation Loss : 0.2993 Learning Late: 0.8421
Epoch 16: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.3280 Validation Loss : 0.3243 Learning Late: 0.8393
Epoch 17: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.3460 Validation Loss : 0.2663 Learning Late: 0.8359
Epoch 18: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.2837 Validation Loss : 0.2743 Learning Late: 0.8321
Epoch 19: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.2887 Validation Loss : 0.2887 Learning Late: 0.8278
Epoch 20: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.2961 Validation Loss : 0.2736 Learning Late: 0.8229
Epoch 21: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.2564 Validation Loss : 0.2746 Learning Late: 0.8176
Epoch 22: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.2720 Validation Loss : 0.2352 Learning Late: 0.8118
Epoch 23: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.2338 Validation Loss : 0.2700 Learning Late: 0.8056
Epoch 24: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.2285 Validation Loss : 0.2369 Learning Late: 0.7989
Epoch 25: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.2373 Validation Loss : 0.2871 Learning Late: 0.7917
Epoch 26: 100%|██████████| 391/391 [02:08<00:00,  3.04batch/s]
Avg Loss : 0.2319 Validation Loss : 0.1965 Learning Late: 0.7841
Epoch 27: 100%|██████████| 391/391 [02:10<00:00,  2.99batch/s]
Avg Loss : 0.2087 Validation Loss : 0.1924 Learning Late: 0.7760
Epoch 28: 100%|██████████| 391/391 [02:08<00:00,  3.03batch/s]
Avg Loss : 0.1981 Validation Loss : 0.2055 Learning Late: 0.7675
Epoch 29: 100%|██████████| 391/391 [02:08<00:00,  3.03batch/s]
Avg Loss : 0.1840 Validation Loss : 0.2278 Learning Late: 0.7586
Epoch 30: 100%|██████████| 391/391 [02:08<00:00,  3.04batch/s]
Avg Loss : 0.1892 Validation Loss : 0.1838 Learning Late: 0.7493
Epoch 31: 100%|██████████| 391/391 [02:08<00:00,  3.03batch/s]
Avg Loss : 0.1863 Validation Loss : 0.1827 Learning Late: 0.7396
Epoch 32: 100%|██████████| 391/391 [02:08<00:00,  3.03batch/s]
Avg Loss : 0.1864 Validation Loss : 0.2121 Learning Late: 0.7295
Epoch 33: 100%|██████████| 391/391 [02:09<00:00,  3.03batch/s]
Avg Loss : 0.1669 Validation Loss : 0.2134 Learning Late: 0.7190
Epoch 34: 100%|██████████| 391/391 [02:08<00:00,  3.03batch/s]
Avg Loss : 0.1654 Validation Loss : 0.1968 Learning Late: 0.7082
Epoch 35: 100%|██████████| 391/391 [02:08<00:00,  3.03batch/s]
Avg Loss : 0.1813 Validation Loss : 0.1824 Learning Late: 0.6970
Epoch 36: 100%|██████████| 391/391 [02:08<00:00,  3.03batch/s]
Avg Loss : 0.1666 Validation Loss : 0.1653 Learning Late: 0.6855
Epoch 37: 100%|██████████| 391/391 [02:08<00:00,  3.04batch/s]
Avg Loss : 0.1593 Validation Loss : 0.1411 Learning Late: 0.6736
Epoch 38: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1708 Validation Loss : 0.1457 Learning Late: 0.6615
Epoch 39: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1641 Validation Loss : 0.1538 Learning Late: 0.6491
Epoch 40: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1547 Validation Loss : 0.1471 Learning Late: 0.6364
Epoch 41: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1609 Validation Loss : 0.1918 Learning Late: 0.6234
Epoch 42: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1522 Validation Loss : 0.1480 Learning Late: 0.6102
Epoch 43: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1550 Validation Loss : 0.1491 Learning Late: 0.5968
Epoch 44: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1448 Validation Loss : 0.1422 Learning Late: 0.5832
Epoch 45: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1437 Validation Loss : 0.1466 Learning Late: 0.5694
Epoch 46: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1429 Validation Loss : 0.1241 Learning Late: 0.5554
Epoch 47: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1589 Validation Loss : 0.1392 Learning Late: 0.5412
Epoch 48: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1382 Validation Loss : 0.1373 Learning Late: 0.5269
Epoch 49: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1376 Validation Loss : 0.1235 Learning Late: 0.5125
Epoch 50: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1260 Validation Loss : 0.1155 Learning Late: 0.4979
Epoch 51: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1269 Validation Loss : 0.2164 Learning Late: 0.4833
Epoch 52: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1241 Validation Loss : 0.1410 Learning Late: 0.4686
Epoch 53: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1278 Validation Loss : 0.1151 Learning Late: 0.4539
Epoch 54: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1217 Validation Loss : 0.1173 Learning Late: 0.4391
Epoch 55: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1291 Validation Loss : 0.1010 Learning Late: 0.4243
Epoch 56: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1349 Validation Loss : 0.1371 Learning Late: 0.4095
Epoch 57: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1280 Validation Loss : 0.1267 Learning Late: 0.3947
Epoch 58: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1202 Validation Loss : 0.1264 Learning Late: 0.3799
Epoch 59: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1172 Validation Loss : 0.1072 Learning Late: 0.3652
Epoch 60: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1156 Validation Loss : 0.1240 Learning Late: 0.3506
Epoch 61: 100%|██████████| 391/391 [02:09<00:00,  3.01batch/s]
Avg Loss : 0.1105 Validation Loss : 0.1345 Learning Late: 0.3361
Epoch 62: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1188 Validation Loss : 0.1054 Learning Late: 0.3216
Epoch 63: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1157 Validation Loss : 0.1166 Learning Late: 0.3073
Epoch 64: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1181 Validation Loss : 0.1027 Learning Late: 0.2932
Epoch 65: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1029 Validation Loss : 0.1399 Learning Late: 0.2792
Epoch 66: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1010 Validation Loss : 0.1008 Learning Late: 0.2653
Epoch 67: 100%|██████████| 391/391 [02:07<00:00,  3.07batch/s]
Avg Loss : 0.1081 Validation Loss : 0.1168 Learning Late: 0.2517
Epoch 68: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1069 Validation Loss : 0.1075 Learning Late: 0.2383
Epoch 69: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1041 Validation Loss : 0.1134 Learning Late: 0.2251
Epoch 70: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1101 Validation Loss : 0.1094 Learning Late: 0.2121
Epoch 71: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1089 Validation Loss : 0.1117 Learning Late: 0.1994
Epoch 72: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1074 Validation Loss : 0.1127 Learning Late: 0.1870
Epoch 73: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1049 Validation Loss : 0.1118 Learning Late: 0.1749
Epoch 74: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1091 Validation Loss : 0.1159 Learning Late: 0.1631
Epoch 75: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1059 Validation Loss : 0.1089 Learning Late: 0.1516
Epoch 76: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1041 Validation Loss : 0.1069 Learning Late: 0.1404
Epoch 77: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.0993 Validation Loss : 0.1004 Learning Late: 0.1295
Epoch 78: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.0976 Validation Loss : 0.1196 Learning Late: 0.1191
Epoch 79: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.0990 Validation Loss : 0.0939 Learning Late: 0.1090
Epoch 80: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1003 Validation Loss : 0.0940 Learning Late: 0.0993
Epoch 81: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1103 Validation Loss : 0.1106 Learning Late: 0.0899
Epoch 82: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.0955 Validation Loss : 0.0875 Learning Late: 0.0810
Epoch 83: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1038 Validation Loss : 0.1200 Learning Late: 0.0725
Epoch 84: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.0901 Validation Loss : 0.1259 Learning Late: 0.0645
Epoch 85: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.0942 Validation Loss : 0.1017 Learning Late: 0.0568
Epoch 86: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.0956 Validation Loss : 0.0956 Learning Late: 0.0497
Epoch 87: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.0946 Validation Loss : 0.1075 Learning Late: 0.0429
Epoch 88: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.0958 Validation Loss : 0.1211 Learning Late: 0.0367
Epoch 89: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1052 Validation Loss : 0.1096 Learning Late: 0.0309
Epoch 90: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1006 Validation Loss : 0.0835 Learning Late: 0.0256
Epoch 91: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.0971 Validation Loss : 0.1028 Learning Late: 0.0208
Epoch 92: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.0998 Validation Loss : 0.1033 Learning Late: 0.0164
Epoch 93: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1028 Validation Loss : 0.0828 Learning Late: 0.0126
Epoch 94: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1011 Validation Loss : 0.1050 Learning Late: 0.0093
Epoch 95: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.0980 Validation Loss : 0.0858 Learning Late: 0.0064
Epoch 96: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1011 Validation Loss : 0.1186 Learning Late: 0.0041
Epoch 97: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.0999 Validation Loss : 0.1072 Learning Late: 0.0023
Epoch 98: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.0970 Validation Loss : 0.1034 Learning Late: 0.0010
Epoch 99: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.1047 Validation Loss : 0.1033 Learning Late: 0.0003
Epoch 100: 100%|██████████| 391/391 [02:07<00:00,  3.06batch/s]
Avg Loss : 0.0959 Validation Loss : 0.0964 Learning Late: 0.0000
FG 학습 완료. 이제 F의 output을 실제 dataset의 label과 연결.
Files already downloaded and verified
Files already downloaded and verified
Epoch 1: 100%|██████████| 391/391 [00:24<00:00, 15.95batch/s]
Avg Loss : 1.4029 Validation Loss : 1.3152 Learning Late: 0.0010
Epoch 2: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.2674 Validation Loss : 1.2568 Learning Late: 0.0010
Epoch 3: 100%|██████████| 391/391 [00:24<00:00, 16.00batch/s]
Avg Loss : 1.2274 Validation Loss : 1.2320 Learning Late: 0.0010
Epoch 4: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.2019 Validation Loss : 1.2342 Learning Late: 0.0010
Epoch 5: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.1827 Validation Loss : 1.2102 Learning Late: 0.0010
Epoch 6: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.1685 Validation Loss : 1.1963 Learning Late: 0.0010
Epoch 7: 100%|██████████| 391/391 [00:24<00:00, 16.00batch/s]
Avg Loss : 1.1601 Validation Loss : 1.1753 Learning Late: 0.0010
Epoch 8: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.1488 Validation Loss : 1.1858 Learning Late: 0.0010
Epoch 9: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.1401 Validation Loss : 1.1877 Learning Late: 0.0010
Epoch 10: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.1317 Validation Loss : 1.1644 Learning Late: 0.0010
Epoch 11: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.1244 Validation Loss : 1.1717 Learning Late: 0.0010
Epoch 12: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.1222 Validation Loss : 1.1649 Learning Late: 0.0010
Epoch 13: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.1157 Validation Loss : 1.1651 Learning Late: 0.0010
Epoch 14: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.1103 Validation Loss : 1.1433 Learning Late: 0.0010
Epoch 15: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.1051 Validation Loss : 1.1524 Learning Late: 0.0010
Epoch 16: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.1005 Validation Loss : 1.1541 Learning Late: 0.0010
Epoch 17: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0993 Validation Loss : 1.1458 Learning Late: 0.0010
Epoch 18: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.0967 Validation Loss : 1.1435 Learning Late: 0.0010
Epoch 19: 100%|██████████| 391/391 [00:24<00:00, 16.00batch/s]
Avg Loss : 1.0921 Validation Loss : 1.1444 Learning Late: 0.0010
Epoch 20: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.0905 Validation Loss : 1.1375 Learning Late: 0.0010
Epoch 21: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0869 Validation Loss : 1.1605 Learning Late: 0.0010
Epoch 22: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0828 Validation Loss : 1.1256 Learning Late: 0.0010
Epoch 23: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0821 Validation Loss : 1.1212 Learning Late: 0.0010
Epoch 24: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.0790 Validation Loss : 1.1267 Learning Late: 0.0010
Epoch 25: 100%|██████████| 391/391 [00:24<00:00, 16.00batch/s]
Avg Loss : 1.0758 Validation Loss : 1.1122 Learning Late: 0.0010
Epoch 26: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0738 Validation Loss : 1.1244 Learning Late: 0.0010
Epoch 27: 100%|██████████| 391/391 [00:24<00:00, 16.00batch/s]
Avg Loss : 1.0736 Validation Loss : 1.1088 Learning Late: 0.0010
Epoch 28: 100%|██████████| 391/391 [00:24<00:00, 16.00batch/s]
Avg Loss : 1.0704 Validation Loss : 1.1193 Learning Late: 0.0010
Epoch 29: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.0711 Validation Loss : 1.1365 Learning Late: 0.0010
Epoch 30: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0668 Validation Loss : 1.1155 Learning Late: 0.0010
Epoch 31: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0632 Validation Loss : 1.1174 Learning Late: 0.0010
Epoch 32: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.0654 Validation Loss : 1.1073 Learning Late: 0.0010
Epoch 33: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0635 Validation Loss : 1.1212 Learning Late: 0.0010
Epoch 34: 100%|██████████| 391/391 [00:24<00:00, 16.03batch/s]
Avg Loss : 1.0609 Validation Loss : 1.1148 Learning Late: 0.0010
Epoch 35: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0588 Validation Loss : 1.1143 Learning Late: 0.0010
Epoch 36: 100%|██████████| 391/391 [00:24<00:00, 16.03batch/s]
Avg Loss : 1.0579 Validation Loss : 1.1131 Learning Late: 0.0010
Epoch 37: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.0559 Validation Loss : 1.1139 Learning Late: 0.0010
Epoch 38: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0561 Validation Loss : 1.1071 Learning Late: 0.0009
Epoch 39: 100%|██████████| 391/391 [00:24<00:00, 16.00batch/s]
Avg Loss : 1.0555 Validation Loss : 1.1128 Learning Late: 0.0009
Epoch 40: 100%|██████████| 391/391 [00:24<00:00, 15.99batch/s]
Avg Loss : 1.0529 Validation Loss : 1.1138 Learning Late: 0.0009
Epoch 41: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.0527 Validation Loss : 1.1058 Learning Late: 0.0009
Epoch 42: 100%|██████████| 391/391 [00:24<00:00, 16.00batch/s]
Avg Loss : 1.0513 Validation Loss : 1.1019 Learning Late: 0.0009
Epoch 43: 100%|██████████| 391/391 [00:24<00:00, 16.00batch/s]
Avg Loss : 1.0516 Validation Loss : 1.1119 Learning Late: 0.0009
Epoch 44: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.0495 Validation Loss : 1.1143 Learning Late: 0.0009
Epoch 45: 100%|██████████| 391/391 [00:24<00:00, 16.03batch/s]
Avg Loss : 1.0478 Validation Loss : 1.1271 Learning Late: 0.0009
Epoch 46: 100%|██████████| 391/391 [00:24<00:00, 15.99batch/s]
Avg Loss : 1.0484 Validation Loss : 1.0995 Learning Late: 0.0009
Epoch 47: 100%|██████████| 391/391 [00:24<00:00, 15.99batch/s]
Avg Loss : 1.0458 Validation Loss : 1.1068 Learning Late: 0.0009
Epoch 48: 100%|██████████| 391/391 [00:24<00:00, 16.03batch/s]
Avg Loss : 1.0464 Validation Loss : 1.1011 Learning Late: 0.0009
Epoch 49: 100%|██████████| 391/391 [00:24<00:00, 16.03batch/s]
Avg Loss : 1.0456 Validation Loss : 1.1058 Learning Late: 0.0009
Epoch 50: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0444 Validation Loss : 1.1017 Learning Late: 0.0009
Epoch 51: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.0426 Validation Loss : 1.1019 Learning Late: 0.0009
Epoch 52: 100%|██████████| 391/391 [00:24<00:00, 16.00batch/s]
Avg Loss : 1.0420 Validation Loss : 1.1092 Learning Late: 0.0009
Epoch 53: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.0421 Validation Loss : 1.1002 Learning Late: 0.0009
Epoch 54: 100%|██████████| 391/391 [00:24<00:00, 16.03batch/s]
Avg Loss : 1.0411 Validation Loss : 1.1114 Learning Late: 0.0009
Epoch 55: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.0408 Validation Loss : 1.0983 Learning Late: 0.0009
Epoch 56: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.0383 Validation Loss : 1.0982 Learning Late: 0.0009
Epoch 57: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0378 Validation Loss : 1.1001 Learning Late: 0.0009
Epoch 58: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0386 Validation Loss : 1.0963 Learning Late: 0.0009
Epoch 59: 100%|██████████| 391/391 [00:24<00:00, 15.88batch/s]
Avg Loss : 1.0365 Validation Loss : 1.0967 Learning Late: 0.0008
Epoch 60: 100%|██████████| 391/391 [00:24<00:00, 16.00batch/s]
Avg Loss : 1.0367 Validation Loss : 1.0993 Learning Late: 0.0008
Epoch 61: 100%|██████████| 391/391 [00:24<00:00, 16.00batch/s]
Avg Loss : 1.0350 Validation Loss : 1.0938 Learning Late: 0.0008
Epoch 62: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0333 Validation Loss : 1.1010 Learning Late: 0.0008
Epoch 63: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.0348 Validation Loss : 1.0902 Learning Late: 0.0008
Epoch 64: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0331 Validation Loss : 1.0979 Learning Late: 0.0008
Epoch 65: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0323 Validation Loss : 1.1023 Learning Late: 0.0008
Epoch 66: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0337 Validation Loss : 1.1032 Learning Late: 0.0008
Epoch 67: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0319 Validation Loss : 1.0959 Learning Late: 0.0008
Epoch 68: 100%|██████████| 391/391 [00:24<00:00, 16.00batch/s]
Avg Loss : 1.0300 Validation Loss : 1.0940 Learning Late: 0.0008
Epoch 69: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0307 Validation Loss : 1.0935 Learning Late: 0.0008
Epoch 70: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.0310 Validation Loss : 1.1100 Learning Late: 0.0008
Epoch 71: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0315 Validation Loss : 1.1003 Learning Late: 0.0008
Epoch 72: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.0283 Validation Loss : 1.1007 Learning Late: 0.0008
Epoch 73: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0284 Validation Loss : 1.0903 Learning Late: 0.0008
Epoch 74: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.0276 Validation Loss : 1.0973 Learning Late: 0.0007
Epoch 75: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.0268 Validation Loss : 1.0920 Learning Late: 0.0007
Epoch 76: 100%|██████████| 391/391 [00:24<00:00, 16.00batch/s]
Avg Loss : 1.0275 Validation Loss : 1.0923 Learning Late: 0.0007
Epoch 77: 100%|██████████| 391/391 [00:24<00:00, 16.04batch/s]
Avg Loss : 1.0266 Validation Loss : 1.0887 Learning Late: 0.0007
Epoch 78: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0256 Validation Loss : 1.0863 Learning Late: 0.0007
Epoch 79: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0255 Validation Loss : 1.0970 Learning Late: 0.0007
Epoch 80: 100%|██████████| 391/391 [00:24<00:00, 16.03batch/s]
Avg Loss : 1.0244 Validation Loss : 1.0954 Learning Late: 0.0007
Epoch 81: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0255 Validation Loss : 1.1016 Learning Late: 0.0007
Epoch 82: 100%|██████████| 391/391 [00:24<00:00, 16.00batch/s]
Avg Loss : 1.0241 Validation Loss : 1.0996 Learning Late: 0.0007
Epoch 83: 100%|██████████| 391/391 [00:24<00:00, 16.03batch/s]
Avg Loss : 1.0235 Validation Loss : 1.0857 Learning Late: 0.0007
Epoch 84: 100%|██████████| 391/391 [00:24<00:00, 16.03batch/s]
Avg Loss : 1.0229 Validation Loss : 1.0870 Learning Late: 0.0007
Epoch 85: 100%|██████████| 391/391 [00:24<00:00, 16.00batch/s]
Avg Loss : 1.0226 Validation Loss : 1.0892 Learning Late: 0.0007
Epoch 86: 100%|██████████| 391/391 [00:24<00:00, 16.00batch/s]
Avg Loss : 1.0218 Validation Loss : 1.0961 Learning Late: 0.0007
Epoch 87: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0224 Validation Loss : 1.1052 Learning Late: 0.0006
Epoch 88: 100%|██████████| 391/391 [00:24<00:00, 16.03batch/s]
Avg Loss : 1.0214 Validation Loss : 1.0908 Learning Late: 0.0006
Epoch 89: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.0212 Validation Loss : 1.0930 Learning Late: 0.0006
Epoch 90: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.0206 Validation Loss : 1.0917 Learning Late: 0.0006
Epoch 91: 100%|██████████| 391/391 [00:24<00:00, 16.03batch/s]
Avg Loss : 1.0198 Validation Loss : 1.0865 Learning Late: 0.0006
Epoch 92: 100%|██████████| 391/391 [00:24<00:00, 16.00batch/s]
Avg Loss : 1.0194 Validation Loss : 1.0965 Learning Late: 0.0006
Epoch 93: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0196 Validation Loss : 1.0817 Learning Late: 0.0006
Epoch 94: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0199 Validation Loss : 1.0886 Learning Late: 0.0006
Epoch 95: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.0173 Validation Loss : 1.0809 Learning Late: 0.0006
Epoch 96: 100%|██████████| 391/391 [00:24<00:00, 16.04batch/s]
Avg Loss : 1.0186 Validation Loss : 1.0889 Learning Late: 0.0006
Epoch 97: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.0179 Validation Loss : 1.0858 Learning Late: 0.0006
Epoch 98: 100%|██████████| 391/391 [00:24<00:00, 16.00batch/s]
Avg Loss : 1.0169 Validation Loss : 1.0995 Learning Late: 0.0006
Epoch 99: 100%|██████████| 391/391 [00:24<00:00, 16.00batch/s]
Avg Loss : 1.0176 Validation Loss : 1.0870 Learning Late: 0.0005
Epoch 100: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0167 Validation Loss : 1.0861 Learning Late: 0.0005
Epoch 101: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0158 Validation Loss : 1.0860 Learning Late: 0.0005
Epoch 102: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0150 Validation Loss : 1.0892 Learning Late: 0.0005
Epoch 103: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.0157 Validation Loss : 1.0909 Learning Late: 0.0005
Epoch 104: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0157 Validation Loss : 1.0920 Learning Late: 0.0005
Epoch 105: 100%|██████████| 391/391 [00:24<00:00, 16.00batch/s]
Avg Loss : 1.0145 Validation Loss : 1.0910 Learning Late: 0.0005
Epoch 106: 100%|██████████| 391/391 [00:24<00:00, 16.00batch/s]
Avg Loss : 1.0137 Validation Loss : 1.0864 Learning Late: 0.0005
Epoch 107: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.0124 Validation Loss : 1.0831 Learning Late: 0.0005
Epoch 108: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0139 Validation Loss : 1.0787 Learning Late: 0.0005
Epoch 109: 100%|██████████| 391/391 [00:24<00:00, 16.00batch/s]
Avg Loss : 1.0127 Validation Loss : 1.0897 Learning Late: 0.0005
Epoch 110: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0133 Validation Loss : 1.0852 Learning Late: 0.0005
Epoch 111: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0127 Validation Loss : 1.0823 Learning Late: 0.0005
Epoch 112: 100%|██████████| 391/391 [00:24<00:00, 15.90batch/s]
Avg Loss : 1.0124 Validation Loss : 1.0791 Learning Late: 0.0004
Epoch 113: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.0117 Validation Loss : 1.0824 Learning Late: 0.0004
Epoch 114: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.0124 Validation Loss : 1.0869 Learning Late: 0.0004
Epoch 115: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0110 Validation Loss : 1.0848 Learning Late: 0.0004
Epoch 116: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.0114 Validation Loss : 1.0819 Learning Late: 0.0004
Epoch 117: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0102 Validation Loss : 1.0849 Learning Late: 0.0004
Epoch 118: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.0103 Validation Loss : 1.0837 Learning Late: 0.0004
Epoch 119: 100%|██████████| 391/391 [00:24<00:00, 16.00batch/s]
Avg Loss : 1.0105 Validation Loss : 1.0815 Learning Late: 0.0004
Epoch 120: 100%|██████████| 391/391 [00:24<00:00, 16.00batch/s]
Avg Loss : 1.0097 Validation Loss : 1.0859 Learning Late: 0.0004
Epoch 121: 100%|██████████| 391/391 [00:24<00:00, 15.99batch/s]
Avg Loss : 1.0100 Validation Loss : 1.0856 Learning Late: 0.0004
Epoch 122: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0091 Validation Loss : 1.0870 Learning Late: 0.0004
Epoch 123: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.0091 Validation Loss : 1.0802 Learning Late: 0.0004
Epoch 124: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.0085 Validation Loss : 1.0850 Learning Late: 0.0003
Epoch 125: 100%|██████████| 391/391 [00:24<00:00, 15.99batch/s]
Avg Loss : 1.0089 Validation Loss : 1.0927 Learning Late: 0.0003
Epoch 126: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.0082 Validation Loss : 1.0849 Learning Late: 0.0003
Epoch 127: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.0075 Validation Loss : 1.0778 Learning Late: 0.0003
Epoch 128: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0075 Validation Loss : 1.0845 Learning Late: 0.0003
Epoch 129: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0066 Validation Loss : 1.0820 Learning Late: 0.0003
Epoch 130: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.0063 Validation Loss : 1.0805 Learning Late: 0.0003
Epoch 131: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.0072 Validation Loss : 1.0868 Learning Late: 0.0003
Epoch 132: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0060 Validation Loss : 1.0877 Learning Late: 0.0003
Epoch 133: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.0057 Validation Loss : 1.0850 Learning Late: 0.0003
Epoch 134: 100%|██████████| 391/391 [00:24<00:00, 16.03batch/s]
Avg Loss : 1.0052 Validation Loss : 1.0781 Learning Late: 0.0003
Epoch 135: 100%|██████████| 391/391 [00:24<00:00, 16.00batch/s]
Avg Loss : 1.0057 Validation Loss : 1.0888 Learning Late: 0.0003
Epoch 136: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0058 Validation Loss : 1.0764 Learning Late: 0.0003
Epoch 137: 100%|██████████| 391/391 [00:24<00:00, 15.99batch/s]
Avg Loss : 1.0051 Validation Loss : 1.0791 Learning Late: 0.0002
Epoch 138: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0046 Validation Loss : 1.0816 Learning Late: 0.0002
Epoch 139: 100%|██████████| 391/391 [00:24<00:00, 15.89batch/s]
Avg Loss : 1.0041 Validation Loss : 1.0787 Learning Late: 0.0002
Epoch 140: 100%|██████████| 391/391 [00:24<00:00, 16.00batch/s]
Avg Loss : 1.0041 Validation Loss : 1.0869 Learning Late: 0.0002
Epoch 141: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0035 Validation Loss : 1.0821 Learning Late: 0.0002
Epoch 142: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.0034 Validation Loss : 1.0720 Learning Late: 0.0002
Epoch 143: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0031 Validation Loss : 1.0810 Learning Late: 0.0002
Epoch 144: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0028 Validation Loss : 1.0846 Learning Late: 0.0002
Epoch 145: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.0028 Validation Loss : 1.0781 Learning Late: 0.0002
Epoch 146: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.0021 Validation Loss : 1.0853 Learning Late: 0.0002
Epoch 147: 100%|██████████| 391/391 [00:24<00:00, 16.04batch/s]
Avg Loss : 1.0022 Validation Loss : 1.0833 Learning Late: 0.0002
Epoch 148: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0019 Validation Loss : 1.0735 Learning Late: 0.0002
Epoch 149: 100%|██████████| 391/391 [00:24<00:00, 16.00batch/s]
Avg Loss : 1.0018 Validation Loss : 1.0832 Learning Late: 0.0002
Epoch 150: 100%|██████████| 391/391 [00:24<00:00, 16.00batch/s]
Avg Loss : 1.0013 Validation Loss : 1.0788 Learning Late: 0.0002
Epoch 151: 100%|██████████| 391/391 [00:24<00:00, 15.98batch/s]
Avg Loss : 1.0017 Validation Loss : 1.0802 Learning Late: 0.0002
Epoch 152: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0011 Validation Loss : 1.0789 Learning Late: 0.0001
Epoch 153: 100%|██████████| 391/391 [00:24<00:00, 16.00batch/s]
Avg Loss : 1.0011 Validation Loss : 1.0789 Learning Late: 0.0001
Epoch 154: 100%|██████████| 391/391 [00:24<00:00, 16.00batch/s]
Avg Loss : 1.0009 Validation Loss : 1.0775 Learning Late: 0.0001
Epoch 155: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0003 Validation Loss : 1.0846 Learning Late: 0.0001
Epoch 156: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 1.0002 Validation Loss : 1.0752 Learning Late: 0.0001
Epoch 157: 100%|██████████| 391/391 [00:24<00:00, 16.03batch/s]
Avg Loss : 1.0005 Validation Loss : 1.0790 Learning Late: 0.0001
Epoch 158: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 1.0003 Validation Loss : 1.0781 Learning Late: 0.0001
Epoch 159: 100%|██████████| 391/391 [00:24<00:00, 16.03batch/s]
Avg Loss : 0.9999 Validation Loss : 1.0776 Learning Late: 0.0001
Epoch 160: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 0.9995 Validation Loss : 1.0775 Learning Late: 0.0001
Epoch 161: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 0.9994 Validation Loss : 1.0762 Learning Late: 0.0001
Epoch 162: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 0.9992 Validation Loss : 1.0745 Learning Late: 0.0001
Epoch 163: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 0.9994 Validation Loss : 1.0817 Learning Late: 0.0001
Epoch 164: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 0.9991 Validation Loss : 1.0733 Learning Late: 0.0001
Epoch 165: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 0.9988 Validation Loss : 1.0853 Learning Late: 0.0001
Epoch 166: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 0.9987 Validation Loss : 1.0848 Learning Late: 0.0001
Epoch 167: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 0.9987 Validation Loss : 1.0777 Learning Late: 0.0001
Epoch 168: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 0.9984 Validation Loss : 1.0745 Learning Late: 0.0001
Epoch 169: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 0.9982 Validation Loss : 1.0765 Learning Late: 0.0001
Epoch 170: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 0.9981 Validation Loss : 1.0773 Learning Late: 0.0001
Epoch 171: 100%|██████████| 391/391 [00:24<00:00, 15.99batch/s]
Avg Loss : 0.9980 Validation Loss : 1.0842 Learning Late: 0.0001
Epoch 172: 100%|██████████| 391/391 [00:24<00:00, 16.03batch/s]
Avg Loss : 0.9979 Validation Loss : 1.0776 Learning Late: 0.0001
Epoch 173: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 0.9977 Validation Loss : 1.0775 Learning Late: 0.0000
Epoch 174: 100%|██████████| 391/391 [00:24<00:00, 15.99batch/s]
Avg Loss : 0.9976 Validation Loss : 1.0739 Learning Late: 0.0000
Epoch 175: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 0.9973 Validation Loss : 1.0767 Learning Late: 0.0000
Epoch 176: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 0.9975 Validation Loss : 1.0759 Learning Late: 0.0000
Epoch 177: 100%|██████████| 391/391 [00:24<00:00, 16.00batch/s]
Avg Loss : 0.9972 Validation Loss : 1.0736 Learning Late: 0.0000
Epoch 178: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 0.9972 Validation Loss : 1.0760 Learning Late: 0.0000
Epoch 179: 100%|██████████| 391/391 [00:24<00:00, 16.00batch/s]
Avg Loss : 0.9970 Validation Loss : 1.0777 Learning Late: 0.0000
Epoch 180: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 0.9968 Validation Loss : 1.0752 Learning Late: 0.0000
Epoch 181: 100%|██████████| 391/391 [00:24<00:00, 16.03batch/s]
Avg Loss : 0.9968 Validation Loss : 1.0726 Learning Late: 0.0000
Epoch 182: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 0.9970 Validation Loss : 1.0777 Learning Late: 0.0000
Epoch 183: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 0.9968 Validation Loss : 1.0778 Learning Late: 0.0000
Epoch 184: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 0.9965 Validation Loss : 1.0797 Learning Late: 0.0000
Epoch 185: 100%|██████████| 391/391 [00:24<00:00, 16.03batch/s]
Avg Loss : 0.9964 Validation Loss : 1.0847 Learning Late: 0.0000
Epoch 186: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 0.9964 Validation Loss : 1.0750 Learning Late: 0.0000
Epoch 187: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 0.9961 Validation Loss : 1.0794 Learning Late: 0.0000
Epoch 188: 100%|██████████| 391/391 [00:24<00:00, 15.99batch/s]
Avg Loss : 0.9959 Validation Loss : 1.0764 Learning Late: 0.0000
Epoch 189: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 0.9961 Validation Loss : 1.0752 Learning Late: 0.0000
Epoch 190: 100%|██████████| 391/391 [00:24<00:00, 16.00batch/s]
Avg Loss : 0.9961 Validation Loss : 1.0756 Learning Late: 0.0000
Epoch 191: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 0.9959 Validation Loss : 1.0801 Learning Late: 0.0000
Epoch 192: 100%|██████████| 391/391 [00:24<00:00, 16.00batch/s]
Avg Loss : 0.9961 Validation Loss : 1.0776 Learning Late: 0.0000
Epoch 193: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 0.9958 Validation Loss : 1.0807 Learning Late: 0.0000
Epoch 194: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 0.9957 Validation Loss : 1.0756 Learning Late: 0.0000
Epoch 195: 100%|██████████| 391/391 [00:24<00:00, 16.02batch/s]
Avg Loss : 0.9958 Validation Loss : 1.0772 Learning Late: 0.0000
Epoch 196: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 0.9957 Validation Loss : 1.0789 Learning Late: 0.0000
Epoch 197: 100%|██████████| 391/391 [00:24<00:00, 16.03batch/s]
Avg Loss : 0.9959 Validation Loss : 1.0774 Learning Late: 0.0000
Epoch 198: 100%|██████████| 391/391 [00:24<00:00, 16.01batch/s]
Avg Loss : 0.9956 Validation Loss : 1.0760 Learning Late: 0.0000
Epoch 199: 100%|██████████| 391/391 [00:24<00:00, 16.00batch/s]
Avg Loss : 0.9956 Validation Loss : 1.0766 Learning Late: 0.0000
Epoch 200: 100%|██████████| 391/391 [00:24<00:00, 15.66batch/s]
Avg Loss : 0.9956 Validation Loss : 1.0766 Learning Late: 0.0000
  0%|          | 0/79 [00:00<?, ?batch/s]실제 test
100%|██████████| 79/79 [00:16<00:00,  4.75batch/s]
총 개수 : 10000
top-1 맞춘 개수 : 6219
 정확도: 62.19
top-5 맞춘 개수 : 9630
 정확도: 96.3

종료 코드 0(으)로 완료된 프로세스
