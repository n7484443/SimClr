C:\Users\kimJuhwan\anaconda3\envs\pytorch\python.exe E:\github\simclrExe\main_with_originalres.py
Files already downloaded and verified
Files already downloaded and verified
===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
SimCLR                                        [512, 512]                --
├─ResNet: 1-1                                 [512, 512]                --
│    └─Conv2d: 2-1                            [512, 64, 32, 32]         1,728
│    └─BatchNorm2d: 2-2                       [512, 64, 32, 32]         128
│    └─ReLU: 2-3                              [512, 64, 32, 32]         --
│    └─Identity: 2-4                          [512, 64, 32, 32]         --
│    └─Sequential: 2-5                        [512, 64, 32, 32]         --
│    │    └─BasicBlock: 3-1                   [512, 64, 32, 32]         73,984
│    │    └─BasicBlock: 3-2                   [512, 64, 32, 32]         73,984
│    └─Sequential: 2-6                        [512, 128, 16, 16]        --
│    │    └─BasicBlock: 3-3                   [512, 128, 16, 16]        230,144
│    │    └─BasicBlock: 3-4                   [512, 128, 16, 16]        295,424
│    └─Sequential: 2-7                        [512, 256, 8, 8]          --
│    │    └─BasicBlock: 3-5                   [512, 256, 8, 8]          919,040
│    │    └─BasicBlock: 3-6                   [512, 256, 8, 8]          1,180,672
│    └─Sequential: 2-8                        [512, 512, 4, 4]          --
│    │    └─BasicBlock: 3-7                   [512, 512, 4, 4]          3,673,088
│    │    └─BasicBlock: 3-8                   [512, 512, 4, 4]          4,720,640
│    └─AdaptiveAvgPool2d: 2-9                 [512, 512, 1, 1]          --
│    └─Identity: 2-10                         [512, 512]                --
├─Sequential: 1-2                             [512, 128]                --
│    └─Linear: 2-11                           [512, 512]                262,144
│    └─ReLU: 2-12                             [512, 512]                --
│    └─Linear: 2-13                           [512, 128]                65,536
===============================================================================================
Total params: 11,496,512
Trainable params: 11,496,512
Non-trainable params: 0
Total mult-adds (Units.GIGABYTES): 284.55
===============================================================================================
Input size (MB): 6.29
Forward/backward pass size (MB): 5035.79
Params size (MB): 45.99
Estimated Total Size (MB): 5088.06
===============================================================================================
Epoch 1: 100%|██████████| 98/98 [04:29<00:00,  2.75s/batch]
Avg Loss : 6.3927 Validation Loss : 6.2823 Learning Late: 1.6971
Epoch 2: 100%|██████████| 98/98 [04:26<00:00,  2.72s/batch]
Avg Loss : 6.1951 Validation Loss : 6.0354 Learning Late: 1.6971
Epoch 3: 100%|██████████| 98/98 [04:26<00:00,  2.72s/batch]
Avg Loss : 6.2547 Validation Loss : 6.1675 Learning Late: 1.6971
Epoch 4: 100%|██████████| 98/98 [04:26<00:00,  2.72s/batch]
Avg Loss : 5.8109 Validation Loss : 5.5003 Learning Late: 1.6971
Epoch 5: 100%|██████████| 98/98 [04:28<00:00,  2.74s/batch]
Avg Loss : 5.5880 Validation Loss : 5.3241 Learning Late: 1.6971
Epoch 6: 100%|██████████| 98/98 [04:26<00:00,  2.72s/batch]
Avg Loss : 5.4428 Validation Loss : 5.4166 Learning Late: 1.6971
Epoch 7: 100%|██████████| 98/98 [04:26<00:00,  2.72s/batch]
Avg Loss : 5.3610 Validation Loss : 5.0450 Learning Late: 1.6971
Epoch 8: 100%|██████████| 98/98 [04:27<00:00,  2.73s/batch]
Avg Loss : 5.2584 Validation Loss : 5.1707 Learning Late: 1.6971
Epoch 9: 100%|██████████| 98/98 [04:26<00:00,  2.72s/batch]
Avg Loss : 5.1263 Validation Loss : 4.7194 Learning Late: 1.6971
Epoch 10: 100%|██████████| 98/98 [04:27<00:00,  2.73s/batch]
Avg Loss : 4.8647 Validation Loss : 4.6036 Learning Late: 1.6971
Epoch 11: 100%|██████████| 98/98 [04:24<00:00,  2.70s/batch]
Avg Loss : 4.6275 Validation Loss : 4.3810 Learning Late: 1.6965
Epoch 12: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 4.3193 Validation Loss : 4.1704 Learning Late: 1.6950
Epoch 13: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 3.9885 Validation Loss : 3.8063 Learning Late: 1.6924
Epoch 14: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 3.7703 Validation Loss : 3.6027 Learning Late: 1.6888
Epoch 15: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 3.5731 Validation Loss : 3.6175 Learning Late: 1.6842
Epoch 16: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 3.4527 Validation Loss : 3.1394 Learning Late: 1.6785
Epoch 17: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 3.0425 Validation Loss : 3.0815 Learning Late: 1.6719
Epoch 18: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 3.1139 Validation Loss : 2.7383 Learning Late: 1.6642
Epoch 19: 100%|██████████| 98/98 [04:24<00:00,  2.69s/batch]
Avg Loss : 2.9939 Validation Loss : 2.6075 Learning Late: 1.6555
Epoch 20: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 2.5923 Validation Loss : 2.5334 Learning Late: 1.6459
Epoch 21: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 2.2388 Validation Loss : 2.0768 Learning Late: 1.6353
Epoch 22: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 2.1841 Validation Loss : 2.2532 Learning Late: 1.6237
Epoch 23: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 1.8799 Validation Loss : 1.7834 Learning Late: 1.6112
Epoch 24: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 1.7237 Validation Loss : 1.9764 Learning Late: 1.5977
Epoch 25: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 1.7279 Validation Loss : 1.5886 Learning Late: 1.5834
Epoch 26: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 1.6479 Validation Loss : 1.4332 Learning Late: 1.5681
Epoch 27: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 1.4474 Validation Loss : 1.2212 Learning Late: 1.5520
Epoch 28: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 1.3397 Validation Loss : 1.4175 Learning Late: 1.5350
Epoch 29: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 1.3007 Validation Loss : 1.2119 Learning Late: 1.5172
Epoch 30: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 1.2941 Validation Loss : 1.1694 Learning Late: 1.4985
Epoch 31: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 1.6254 Validation Loss : 1.2760 Learning Late: 1.4791
Epoch 32: 100%|██████████| 98/98 [04:24<00:00,  2.70s/batch]
Avg Loss : 1.1082 Validation Loss : 1.1523 Learning Late: 1.4589
Epoch 33: 100%|██████████| 98/98 [04:24<00:00,  2.70s/batch]
Avg Loss : 1.1306 Validation Loss : 1.1078 Learning Late: 1.4380
Epoch 34: 100%|██████████| 98/98 [04:24<00:00,  2.69s/batch]
Avg Loss : 1.3865 Validation Loss : 1.2432 Learning Late: 1.4163
Epoch 35: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 1.0761 Validation Loss : 1.4708 Learning Late: 1.3940
Epoch 36: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 0.9892 Validation Loss : 1.1723 Learning Late: 1.3709
Epoch 37: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 1.0400 Validation Loss : 0.9337 Learning Late: 1.3473
Epoch 38: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 0.9909 Validation Loss : 0.8998 Learning Late: 1.3230
Epoch 39: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 1.0454 Validation Loss : 0.8990 Learning Late: 1.2982
Epoch 40: 100%|██████████| 98/98 [04:24<00:00,  2.69s/batch]
Avg Loss : 0.9662 Validation Loss : 0.8241 Learning Late: 1.2728
Epoch 41: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 0.9668 Validation Loss : 0.8885 Learning Late: 1.2469
Epoch 42: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 0.8673 Validation Loss : 0.7843 Learning Late: 1.2205
Epoch 43: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 0.9015 Validation Loss : 0.9501 Learning Late: 1.1937
Epoch 44: 100%|██████████| 98/98 [04:24<00:00,  2.69s/batch]
Avg Loss : 0.7929 Validation Loss : 0.8439 Learning Late: 1.1664
Epoch 45: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 0.8213 Validation Loss : 0.9203 Learning Late: 1.1387
Epoch 46: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 0.7655 Validation Loss : 0.8221 Learning Late: 1.1107
Epoch 47: 100%|██████████| 98/98 [04:24<00:00,  2.69s/batch]
Avg Loss : 0.7771 Validation Loss : 0.8030 Learning Late: 1.0824
Epoch 48: 100%|██████████| 98/98 [04:24<00:00,  2.70s/batch]
Avg Loss : 0.8886 Validation Loss : 0.7879 Learning Late: 1.0538
Epoch 49: 100%|██████████| 98/98 [04:24<00:00,  2.70s/batch]
Avg Loss : 0.8127 Validation Loss : 0.6434 Learning Late: 1.0249
Epoch 50: 100%|██████████| 98/98 [04:24<00:00,  2.69s/batch]
Avg Loss : 0.7268 Validation Loss : 0.8900 Learning Late: 0.9959
Epoch 51: 100%|██████████| 98/98 [04:24<00:00,  2.69s/batch]
Avg Loss : 0.7577 Validation Loss : 0.6757 Learning Late: 0.9666
Epoch 52: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 0.7134 Validation Loss : 0.6513 Learning Late: 0.9372
Epoch 53: 100%|██████████| 98/98 [04:24<00:00,  2.69s/batch]
Avg Loss : 0.7059 Validation Loss : 0.6335 Learning Late: 0.9077
Epoch 54: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 0.7115 Validation Loss : 0.7575 Learning Late: 0.8781
Epoch 55: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 0.6917 Validation Loss : 0.7069 Learning Late: 0.8485
Epoch 56: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 0.5857 Validation Loss : 0.5347 Learning Late: 0.8189
Epoch 57: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 0.6357 Validation Loss : 0.6981 Learning Late: 0.7893
Epoch 58: 100%|██████████| 98/98 [04:24<00:00,  2.69s/batch]
Avg Loss : 0.6321 Validation Loss : 0.7970 Learning Late: 0.7598
Epoch 59: 100%|██████████| 98/98 [04:24<00:00,  2.69s/batch]
Avg Loss : 0.6613 Validation Loss : 0.5756 Learning Late: 0.7304
Epoch 60: 100%|██████████| 98/98 [04:24<00:00,  2.69s/batch]
Avg Loss : 0.6850 Validation Loss : 0.5225 Learning Late: 0.7012
Epoch 61: 100%|██████████| 98/98 [04:24<00:00,  2.69s/batch]
Avg Loss : 0.5420 Validation Loss : 0.5675 Learning Late: 0.6721
Epoch 62: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 0.5230 Validation Loss : 0.5505 Learning Late: 0.6433
Epoch 63: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 0.6063 Validation Loss : 0.6052 Learning Late: 0.6146
Epoch 64: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 0.6215 Validation Loss : 0.6156 Learning Late: 0.5863
Epoch 65: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 0.5698 Validation Loss : 0.6648 Learning Late: 0.5583
Epoch 66: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 0.6015 Validation Loss : 0.6262 Learning Late: 0.5307
Epoch 67: 100%|██████████| 98/98 [04:24<00:00,  2.69s/batch]
Avg Loss : 0.5862 Validation Loss : 0.4646 Learning Late: 0.5034
Epoch 68: 100%|██████████| 98/98 [04:24<00:00,  2.69s/batch]
Avg Loss : 0.5431 Validation Loss : 0.5486 Learning Late: 0.4766
Epoch 69: 100%|██████████| 98/98 [04:24<00:00,  2.70s/batch]
Avg Loss : 0.5016 Validation Loss : 0.7592 Learning Late: 0.4502
Epoch 70: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 0.5985 Validation Loss : 0.5325 Learning Late: 0.4243
Epoch 71: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 0.5884 Validation Loss : 0.5931 Learning Late: 0.3989
Epoch 72: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 0.5254 Validation Loss : 0.5591 Learning Late: 0.3740
Epoch 73: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 0.5594 Validation Loss : 0.6787 Learning Late: 0.3498
Epoch 74: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 0.4821 Validation Loss : 0.5893 Learning Late: 0.3261
Epoch 75: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 0.5248 Validation Loss : 0.5922 Learning Late: 0.3031
Epoch 76: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 0.5043 Validation Loss : 0.4987 Learning Late: 0.2808
Epoch 77: 100%|██████████| 98/98 [04:24<00:00,  2.69s/batch]
Avg Loss : 0.5039 Validation Loss : 0.5631 Learning Late: 0.2591
Epoch 78: 100%|██████████| 98/98 [04:24<00:00,  2.70s/batch]
Avg Loss : 0.4754 Validation Loss : 0.4928 Learning Late: 0.2381
Epoch 79: 100%|██████████| 98/98 [04:24<00:00,  2.69s/batch]
Avg Loss : 0.4638 Validation Loss : 0.5084 Learning Late: 0.2179
Epoch 80: 100%|██████████| 98/98 [04:24<00:00,  2.70s/batch]
Avg Loss : 0.5025 Validation Loss : 0.4065 Learning Late: 0.1985
Epoch 81: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 0.5135 Validation Loss : 0.5761 Learning Late: 0.1799
Epoch 82: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 0.4342 Validation Loss : 0.5091 Learning Late: 0.1621
Epoch 83: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 0.5299 Validation Loss : 0.5837 Learning Late: 0.1451
Epoch 84: 100%|██████████| 98/98 [04:24<00:00,  2.69s/batch]
Avg Loss : 0.4809 Validation Loss : 0.4572 Learning Late: 0.1289
Epoch 85: 100%|██████████| 98/98 [04:24<00:00,  2.70s/batch]
Avg Loss : 0.4642 Validation Loss : 0.4133 Learning Late: 0.1137
Epoch 86: 100%|██████████| 98/98 [04:24<00:00,  2.70s/batch]
Avg Loss : 0.5090 Validation Loss : 0.4208 Learning Late: 0.0993
Epoch 87: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 0.5242 Validation Loss : 0.4943 Learning Late: 0.0859
Epoch 88: 100%|██████████| 98/98 [04:24<00:00,  2.69s/batch]
Avg Loss : 0.4470 Validation Loss : 0.4822 Learning Late: 0.0734
Epoch 89: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 0.4581 Validation Loss : 0.5981 Learning Late: 0.0618
Epoch 90: 100%|██████████| 98/98 [04:24<00:00,  2.70s/batch]
Avg Loss : 0.4434 Validation Loss : 0.4123 Learning Late: 0.0512
Epoch 91: 100%|██████████| 98/98 [04:24<00:00,  2.70s/batch]
Avg Loss : 0.4407 Validation Loss : 0.5264 Learning Late: 0.0415
Epoch 92: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 0.4383 Validation Loss : 0.4155 Learning Late: 0.0329
Epoch 93: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 0.4253 Validation Loss : 0.4925 Learning Late: 0.0252
Epoch 94: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 0.4813 Validation Loss : 0.6548 Learning Late: 0.0185
Epoch 95: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 0.4302 Validation Loss : 0.4141 Learning Late: 0.0129
Epoch 96: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 0.4689 Validation Loss : 0.3948 Learning Late: 0.0083
Epoch 97: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 0.4429 Validation Loss : 0.4528 Learning Late: 0.0046
Epoch 98: 100%|██████████| 98/98 [04:23<00:00,  2.69s/batch]
Avg Loss : 0.4732 Validation Loss : 0.3892 Learning Late: 0.0021
Epoch 99: 100%|██████████| 98/98 [04:24<00:00,  2.69s/batch]
Avg Loss : 0.4321 Validation Loss : 0.3655 Learning Late: 0.0005
Epoch 100: 100%|██████████| 98/98 [04:24<00:00,  2.69s/batch]
Avg Loss : 0.4278 Validation Loss : 0.5488 Learning Late: 0.0000
FG 학습 완료. 이제 F의 output을 실제 dataset의 label과 연결.
Files already downloaded and verified
Files already downloaded and verified
Epoch 1: 100%|██████████| 391/391 [00:16<00:00, 23.95batch/s]
Avg Loss : 8.2133 Validation Loss : 4.7173 Learning Late: 0.0010
Epoch 2: 100%|██████████| 391/391 [00:16<00:00, 23.74batch/s]
Avg Loss : 4.2786 Validation Loss : 3.6950 Learning Late: 0.0010
Epoch 3: 100%|██████████| 391/391 [00:16<00:00, 24.19batch/s]
Avg Loss : 3.5222 Validation Loss : 3.7308 Learning Late: 0.0010
Epoch 4: 100%|██████████| 391/391 [00:16<00:00, 23.76batch/s]
Avg Loss : 3.1835 Validation Loss : 3.0220 Learning Late: 0.0010
Epoch 5: 100%|██████████| 391/391 [00:16<00:00, 23.88batch/s]
Avg Loss : 3.1313 Validation Loss : 2.7910 Learning Late: 0.0010
Epoch 6: 100%|██████████| 391/391 [00:16<00:00, 23.83batch/s]
Avg Loss : 2.9793 Validation Loss : 3.0410 Learning Late: 0.0010
Epoch 7: 100%|██████████| 391/391 [00:16<00:00, 23.76batch/s]
Avg Loss : 2.9186 Validation Loss : 2.8006 Learning Late: 0.0010
Epoch 8: 100%|██████████| 391/391 [00:16<00:00, 23.81batch/s]
Avg Loss : 2.8290 Validation Loss : 3.1480 Learning Late: 0.0010
Epoch 9: 100%|██████████| 391/391 [00:16<00:00, 24.23batch/s]
Avg Loss : 2.9908 Validation Loss : 2.9710 Learning Late: 0.0010
Epoch 10: 100%|██████████| 391/391 [00:16<00:00, 23.91batch/s]
Avg Loss : 2.8325 Validation Loss : 2.9236 Learning Late: 0.0010
Epoch 11: 100%|██████████| 391/391 [00:16<00:00, 24.16batch/s]
Avg Loss : 2.7716 Validation Loss : 2.7431 Learning Late: 0.0010
Epoch 12: 100%|██████████| 391/391 [00:16<00:00, 23.75batch/s]
Avg Loss : 2.9288 Validation Loss : 2.5901 Learning Late: 0.0010
Epoch 13: 100%|██████████| 391/391 [00:16<00:00, 23.81batch/s]
Avg Loss : 2.9763 Validation Loss : 2.9506 Learning Late: 0.0010
Epoch 14: 100%|██████████| 391/391 [00:16<00:00, 23.80batch/s]
Avg Loss : 2.8994 Validation Loss : 2.8498 Learning Late: 0.0010
Epoch 15: 100%|██████████| 391/391 [00:16<00:00, 23.84batch/s]
Avg Loss : 2.8589 Validation Loss : 2.7139 Learning Late: 0.0010
Epoch 16: 100%|██████████| 391/391 [00:16<00:00, 23.77batch/s]
Avg Loss : 2.8621 Validation Loss : 2.7732 Learning Late: 0.0010
Epoch 17: 100%|██████████| 391/391 [00:16<00:00, 23.80batch/s]
Avg Loss : 2.8056 Validation Loss : 2.9397 Learning Late: 0.0010
Epoch 18: 100%|██████████| 391/391 [00:16<00:00, 23.77batch/s]
Avg Loss : 2.7096 Validation Loss : 2.8519 Learning Late: 0.0010
Epoch 19: 100%|██████████| 391/391 [00:16<00:00, 23.77batch/s]
Avg Loss : 2.7532 Validation Loss : 2.6248 Learning Late: 0.0010
Epoch 20: 100%|██████████| 391/391 [00:16<00:00, 23.79batch/s]
Avg Loss : 2.6886 Validation Loss : 3.1945 Learning Late: 0.0010
Epoch 21: 100%|██████████| 391/391 [00:16<00:00, 23.79batch/s]
Avg Loss : 2.7819 Validation Loss : 3.3176 Learning Late: 0.0010
Epoch 22: 100%|██████████| 391/391 [00:16<00:00, 23.81batch/s]
Avg Loss : 2.9189 Validation Loss : 3.2486 Learning Late: 0.0010
Epoch 23: 100%|██████████| 391/391 [00:16<00:00, 23.81batch/s]
Avg Loss : 2.8732 Validation Loss : 3.0503 Learning Late: 0.0010
Epoch 24: 100%|██████████| 391/391 [00:16<00:00, 23.82batch/s]
Avg Loss : 2.8718 Validation Loss : 3.0789 Learning Late: 0.0010
Epoch 25: 100%|██████████| 391/391 [00:16<00:00, 23.79batch/s]
Avg Loss : 2.9345 Validation Loss : 2.5633 Learning Late: 0.0010
Epoch 26: 100%|██████████| 391/391 [00:16<00:00, 23.80batch/s]
Avg Loss : 2.6997 Validation Loss : 2.9774 Learning Late: 0.0010
Epoch 27: 100%|██████████| 391/391 [00:16<00:00, 23.80batch/s]
Avg Loss : 2.8517 Validation Loss : 3.0745 Learning Late: 0.0010
Epoch 28: 100%|██████████| 391/391 [00:16<00:00, 23.98batch/s]
Avg Loss : 2.7897 Validation Loss : 3.1660 Learning Late: 0.0010
Epoch 29: 100%|██████████| 391/391 [00:16<00:00, 23.86batch/s]
Avg Loss : 2.7409 Validation Loss : 2.8886 Learning Late: 0.0010
Epoch 30: 100%|██████████| 391/391 [00:16<00:00, 23.91batch/s]
Avg Loss : 2.7208 Validation Loss : 3.2868 Learning Late: 0.0010
Epoch 31: 100%|██████████| 391/391 [00:16<00:00, 23.89batch/s]
Avg Loss : 2.6976 Validation Loss : 2.9223 Learning Late: 0.0010
Epoch 32: 100%|██████████| 391/391 [00:16<00:00, 23.92batch/s]
Avg Loss : 2.6739 Validation Loss : 2.6391 Learning Late: 0.0010
Epoch 33: 100%|██████████| 391/391 [00:16<00:00, 23.93batch/s]
Avg Loss : 2.7803 Validation Loss : 2.8457 Learning Late: 0.0010
Epoch 34: 100%|██████████| 391/391 [00:16<00:00, 23.94batch/s]
Avg Loss : 2.6545 Validation Loss : 2.7184 Learning Late: 0.0010
Epoch 35: 100%|██████████| 391/391 [00:16<00:00, 23.92batch/s]
Avg Loss : 2.7973 Validation Loss : 3.0090 Learning Late: 0.0010
Epoch 36: 100%|██████████| 391/391 [00:16<00:00, 23.89batch/s]
Avg Loss : 2.6674 Validation Loss : 2.9234 Learning Late: 0.0010
Epoch 37: 100%|██████████| 391/391 [00:16<00:00, 23.83batch/s]
Avg Loss : 2.7382 Validation Loss : 2.6341 Learning Late: 0.0010
Epoch 38: 100%|██████████| 391/391 [00:16<00:00, 23.76batch/s]
Avg Loss : 2.6275 Validation Loss : 2.5172 Learning Late: 0.0009
Epoch 39: 100%|██████████| 391/391 [00:16<00:00, 23.83batch/s]
Avg Loss : 2.7060 Validation Loss : 2.8750 Learning Late: 0.0009
Epoch 40: 100%|██████████| 391/391 [00:16<00:00, 23.98batch/s]
Avg Loss : 2.6931 Validation Loss : 2.9633 Learning Late: 0.0009
Epoch 41: 100%|██████████| 391/391 [00:16<00:00, 23.83batch/s]
Avg Loss : 2.6716 Validation Loss : 3.3290 Learning Late: 0.0009
Epoch 42: 100%|██████████| 391/391 [00:16<00:00, 23.83batch/s]
Avg Loss : 2.7170 Validation Loss : 2.9343 Learning Late: 0.0009
Epoch 43: 100%|██████████| 391/391 [00:16<00:00, 23.84batch/s]
Avg Loss : 2.7848 Validation Loss : 2.7817 Learning Late: 0.0009
Epoch 44: 100%|██████████| 391/391 [00:16<00:00, 23.82batch/s]
Avg Loss : 2.6318 Validation Loss : 3.1641 Learning Late: 0.0009
Epoch 45: 100%|██████████| 391/391 [00:17<00:00, 22.92batch/s]
Avg Loss : 2.5783 Validation Loss : 2.4745 Learning Late: 0.0009
Epoch 46: 100%|██████████| 391/391 [00:17<00:00, 22.72batch/s]
Avg Loss : 2.7023 Validation Loss : 3.0252 Learning Late: 0.0009
Epoch 47: 100%|██████████| 391/391 [00:16<00:00, 23.16batch/s]
Avg Loss : 2.6002 Validation Loss : 2.7212 Learning Late: 0.0009
Epoch 48: 100%|██████████| 391/391 [00:16<00:00, 23.22batch/s]
Avg Loss : 2.5996 Validation Loss : 2.8619 Learning Late: 0.0009
Epoch 49: 100%|██████████| 391/391 [00:16<00:00, 23.17batch/s]
Avg Loss : 2.6925 Validation Loss : 2.4351 Learning Late: 0.0009
Epoch 50: 100%|██████████| 391/391 [00:17<00:00, 22.88batch/s]
Avg Loss : 2.6178 Validation Loss : 2.6883 Learning Late: 0.0009
Epoch 51: 100%|██████████| 391/391 [00:16<00:00, 23.45batch/s]
Avg Loss : 2.4111 Validation Loss : 2.6890 Learning Late: 0.0009
Epoch 52: 100%|██████████| 391/391 [00:16<00:00, 23.42batch/s]
Avg Loss : 2.4887 Validation Loss : 2.7550 Learning Late: 0.0009
Epoch 53: 100%|██████████| 391/391 [00:16<00:00, 23.15batch/s]
Avg Loss : 2.5636 Validation Loss : 2.6791 Learning Late: 0.0009
Epoch 54: 100%|██████████| 391/391 [00:16<00:00, 23.18batch/s]
Avg Loss : 2.5893 Validation Loss : 2.3949 Learning Late: 0.0009
Epoch 55: 100%|██████████| 391/391 [00:16<00:00, 23.18batch/s]
Avg Loss : 2.5464 Validation Loss : 2.4681 Learning Late: 0.0009
Epoch 56: 100%|██████████| 391/391 [00:16<00:00, 23.18batch/s]
Avg Loss : 2.4456 Validation Loss : 2.4285 Learning Late: 0.0009
Epoch 57: 100%|██████████| 391/391 [00:16<00:00, 23.38batch/s]
Avg Loss : 2.5062 Validation Loss : 2.4712 Learning Late: 0.0009
Epoch 58: 100%|██████████| 391/391 [00:16<00:00, 23.17batch/s]
Avg Loss : 2.4409 Validation Loss : 2.8437 Learning Late: 0.0009
Epoch 59: 100%|██████████| 391/391 [00:16<00:00, 23.16batch/s]
Avg Loss : 2.6241 Validation Loss : 2.6202 Learning Late: 0.0008
Epoch 60: 100%|██████████| 391/391 [00:16<00:00, 23.15batch/s]
Avg Loss : 2.5094 Validation Loss : 2.4739 Learning Late: 0.0008
Epoch 61: 100%|██████████| 391/391 [00:16<00:00, 23.17batch/s]
Avg Loss : 2.5118 Validation Loss : 2.5961 Learning Late: 0.0008
Epoch 62: 100%|██████████| 391/391 [00:16<00:00, 23.15batch/s]
Avg Loss : 2.4629 Validation Loss : 2.6558 Learning Late: 0.0008
Epoch 63: 100%|██████████| 391/391 [00:16<00:00, 23.21batch/s]
Avg Loss : 2.5137 Validation Loss : 2.4229 Learning Late: 0.0008
Epoch 64: 100%|██████████| 391/391 [00:16<00:00, 23.38batch/s]
Avg Loss : 2.3578 Validation Loss : 2.5322 Learning Late: 0.0008
Epoch 65: 100%|██████████| 391/391 [00:17<00:00, 22.86batch/s]
Avg Loss : 2.4165 Validation Loss : 2.3348 Learning Late: 0.0008
Epoch 66: 100%|██████████| 391/391 [00:17<00:00, 22.89batch/s]
Avg Loss : 2.3666 Validation Loss : 2.9969 Learning Late: 0.0008
Epoch 67: 100%|██████████| 391/391 [00:16<00:00, 23.36batch/s]
Avg Loss : 2.4170 Validation Loss : 2.5138 Learning Late: 0.0008
Epoch 68: 100%|██████████| 391/391 [00:16<00:00, 23.18batch/s]
Avg Loss : 2.3656 Validation Loss : 2.3997 Learning Late: 0.0008
Epoch 69: 100%|██████████| 391/391 [00:16<00:00, 23.18batch/s]
Avg Loss : 2.3911 Validation Loss : 2.5551 Learning Late: 0.0008
Epoch 70: 100%|██████████| 391/391 [00:16<00:00, 23.14batch/s]
Avg Loss : 2.3100 Validation Loss : 2.6144 Learning Late: 0.0008
Epoch 71: 100%|██████████| 391/391 [00:16<00:00, 23.16batch/s]
Avg Loss : 2.3022 Validation Loss : 2.1182 Learning Late: 0.0008
Epoch 72: 100%|██████████| 391/391 [00:16<00:00, 23.43batch/s]
Avg Loss : 2.1951 Validation Loss : 2.5361 Learning Late: 0.0008
Epoch 73: 100%|██████████| 391/391 [00:16<00:00, 23.16batch/s]
Avg Loss : 2.2558 Validation Loss : 2.3424 Learning Late: 0.0008
Epoch 74: 100%|██████████| 391/391 [00:16<00:00, 23.18batch/s]
Avg Loss : 2.2648 Validation Loss : 2.0535 Learning Late: 0.0007
Epoch 75: 100%|██████████| 391/391 [00:16<00:00, 23.44batch/s]
Avg Loss : 2.3392 Validation Loss : 2.3742 Learning Late: 0.0007
Epoch 76: 100%|██████████| 391/391 [00:16<00:00, 23.19batch/s]
Avg Loss : 2.3237 Validation Loss : 2.6925 Learning Late: 0.0007
Epoch 77: 100%|██████████| 391/391 [00:16<00:00, 23.20batch/s]
Avg Loss : 2.2203 Validation Loss : 2.1321 Learning Late: 0.0007
Epoch 78: 100%|██████████| 391/391 [00:16<00:00, 23.17batch/s]
Avg Loss : 2.2195 Validation Loss : 2.3181 Learning Late: 0.0007
Epoch 79: 100%|██████████| 391/391 [00:16<00:00, 23.40batch/s]
Avg Loss : 2.2109 Validation Loss : 2.1280 Learning Late: 0.0007
Epoch 80: 100%|██████████| 391/391 [00:16<00:00, 23.16batch/s]
Avg Loss : 2.2056 Validation Loss : 2.4318 Learning Late: 0.0007
Epoch 81: 100%|██████████| 391/391 [00:16<00:00, 23.18batch/s]
Avg Loss : 2.2099 Validation Loss : 2.1621 Learning Late: 0.0007
Epoch 82: 100%|██████████| 391/391 [00:16<00:00, 23.19batch/s]
Avg Loss : 2.1893 Validation Loss : 2.0764 Learning Late: 0.0007
Epoch 83: 100%|██████████| 391/391 [00:16<00:00, 23.18batch/s]
Avg Loss : 2.1331 Validation Loss : 2.2880 Learning Late: 0.0007
Epoch 84: 100%|██████████| 391/391 [00:16<00:00, 23.19batch/s]
Avg Loss : 2.0899 Validation Loss : 2.4188 Learning Late: 0.0007
Epoch 85: 100%|██████████| 391/391 [00:16<00:00, 23.17batch/s]
Avg Loss : 2.0813 Validation Loss : 2.2427 Learning Late: 0.0007
Epoch 86: 100%|██████████| 391/391 [00:16<00:00, 23.40batch/s]
Avg Loss : 2.0757 Validation Loss : 2.1599 Learning Late: 0.0007
Epoch 87: 100%|██████████| 391/391 [00:16<00:00, 23.14batch/s]
Avg Loss : 2.0625 Validation Loss : 2.0120 Learning Late: 0.0006
Epoch 88: 100%|██████████| 391/391 [00:16<00:00, 23.18batch/s]
Avg Loss : 2.0478 Validation Loss : 1.9975 Learning Late: 0.0006
Epoch 89: 100%|██████████| 391/391 [00:16<00:00, 23.19batch/s]
Avg Loss : 2.0101 Validation Loss : 2.2304 Learning Late: 0.0006
Epoch 90: 100%|██████████| 391/391 [00:16<00:00, 23.09batch/s]
Avg Loss : 2.0776 Validation Loss : 2.0895 Learning Late: 0.0006
Epoch 91: 100%|██████████| 391/391 [00:16<00:00, 23.17batch/s]
Avg Loss : 2.0086 Validation Loss : 2.1783 Learning Late: 0.0006
Epoch 92: 100%|██████████| 391/391 [00:16<00:00, 23.14batch/s]
Avg Loss : 2.0078 Validation Loss : 2.0480 Learning Late: 0.0006
Epoch 93: 100%|██████████| 391/391 [00:16<00:00, 23.15batch/s]
Avg Loss : 2.0034 Validation Loss : 2.0808 Learning Late: 0.0006
Epoch 94: 100%|██████████| 391/391 [00:16<00:00, 23.17batch/s]
Avg Loss : 1.9516 Validation Loss : 1.9994 Learning Late: 0.0006
Epoch 95: 100%|██████████| 391/391 [00:16<00:00, 23.17batch/s]
Avg Loss : 2.0197 Validation Loss : 2.0219 Learning Late: 0.0006
Epoch 96: 100%|██████████| 391/391 [00:16<00:00, 23.18batch/s]
Avg Loss : 1.9181 Validation Loss : 2.1713 Learning Late: 0.0006
Epoch 97: 100%|██████████| 391/391 [00:16<00:00, 23.43batch/s]
Avg Loss : 1.9098 Validation Loss : 2.0840 Learning Late: 0.0006
Epoch 98: 100%|██████████| 391/391 [00:16<00:00, 23.18batch/s]
Avg Loss : 1.9591 Validation Loss : 2.2189 Learning Late: 0.0006
Epoch 99: 100%|██████████| 391/391 [00:16<00:00, 23.40batch/s]
Avg Loss : 1.9286 Validation Loss : 1.9157 Learning Late: 0.0005
Epoch 100: 100%|██████████| 391/391 [00:16<00:00, 23.39batch/s]
Avg Loss : 1.8630 Validation Loss : 1.9933 Learning Late: 0.0005
Epoch 101: 100%|██████████| 391/391 [00:16<00:00, 23.17batch/s]
Avg Loss : 1.8710 Validation Loss : 2.0370 Learning Late: 0.0005
Epoch 102: 100%|██████████| 391/391 [00:16<00:00, 23.20batch/s]
Avg Loss : 1.8485 Validation Loss : 1.8466 Learning Late: 0.0005
Epoch 103: 100%|██████████| 391/391 [00:16<00:00, 23.20batch/s]
Avg Loss : 1.8447 Validation Loss : 1.9671 Learning Late: 0.0005
Epoch 104: 100%|██████████| 391/391 [00:16<00:00, 23.19batch/s]
Avg Loss : 1.8397 Validation Loss : 1.7886 Learning Late: 0.0005
Epoch 105: 100%|██████████| 391/391 [00:16<00:00, 23.14batch/s]
Avg Loss : 1.7418 Validation Loss : 1.9157 Learning Late: 0.0005
Epoch 106: 100%|██████████| 391/391 [00:16<00:00, 23.16batch/s]
Avg Loss : 1.7954 Validation Loss : 1.8732 Learning Late: 0.0005
Epoch 107: 100%|██████████| 391/391 [00:16<00:00, 23.48batch/s]
Avg Loss : 1.7715 Validation Loss : 1.7804 Learning Late: 0.0005
Epoch 108: 100%|██████████| 391/391 [00:16<00:00, 24.26batch/s]
Avg Loss : 1.8115 Validation Loss : 1.8371 Learning Late: 0.0005
Epoch 109: 100%|██████████| 391/391 [00:16<00:00, 24.19batch/s]
Avg Loss : 1.7528 Validation Loss : 1.6653 Learning Late: 0.0005
Epoch 110: 100%|██████████| 391/391 [00:16<00:00, 24.18batch/s]
Avg Loss : 1.7125 Validation Loss : 1.7340 Learning Late: 0.0005
Epoch 111: 100%|██████████| 391/391 [00:16<00:00, 24.26batch/s]
Avg Loss : 1.7080 Validation Loss : 1.7650 Learning Late: 0.0005
Epoch 112: 100%|██████████| 391/391 [00:16<00:00, 24.28batch/s]
Avg Loss : 1.6591 Validation Loss : 1.7826 Learning Late: 0.0004
Epoch 113: 100%|██████████| 391/391 [00:16<00:00, 24.19batch/s]
Avg Loss : 1.6719 Validation Loss : 1.7654 Learning Late: 0.0004
Epoch 114: 100%|██████████| 391/391 [00:16<00:00, 24.21batch/s]
Avg Loss : 1.6400 Validation Loss : 1.6550 Learning Late: 0.0004
Epoch 115: 100%|██████████| 391/391 [00:16<00:00, 24.16batch/s]
Avg Loss : 1.6489 Validation Loss : 1.7644 Learning Late: 0.0004
Epoch 116: 100%|██████████| 391/391 [00:16<00:00, 24.20batch/s]
Avg Loss : 1.6613 Validation Loss : 1.7622 Learning Late: 0.0004
Epoch 117: 100%|██████████| 391/391 [00:16<00:00, 24.21batch/s]
Avg Loss : 1.6431 Validation Loss : 1.7485 Learning Late: 0.0004
Epoch 118: 100%|██████████| 391/391 [00:16<00:00, 24.20batch/s]
Avg Loss : 1.5901 Validation Loss : 1.6941 Learning Late: 0.0004
Epoch 119: 100%|██████████| 391/391 [00:16<00:00, 24.24batch/s]
Avg Loss : 1.5876 Validation Loss : 1.6830 Learning Late: 0.0004
Epoch 120: 100%|██████████| 391/391 [00:16<00:00, 24.19batch/s]
Avg Loss : 1.5820 Validation Loss : 1.7258 Learning Late: 0.0004
Epoch 121: 100%|██████████| 391/391 [00:16<00:00, 23.81batch/s]
Avg Loss : 1.5809 Validation Loss : 1.7874 Learning Late: 0.0004
Epoch 122: 100%|██████████| 391/391 [00:16<00:00, 24.01batch/s]
Avg Loss : 1.5704 Validation Loss : 1.6723 Learning Late: 0.0004
Epoch 123: 100%|██████████| 391/391 [00:16<00:00, 24.25batch/s]
Avg Loss : 1.5720 Validation Loss : 1.5624 Learning Late: 0.0004
Epoch 124: 100%|██████████| 391/391 [00:16<00:00, 23.83batch/s]
Avg Loss : 1.5415 Validation Loss : 1.5661 Learning Late: 0.0003
Epoch 125: 100%|██████████| 391/391 [00:16<00:00, 24.01batch/s]
Avg Loss : 1.5173 Validation Loss : 1.5050 Learning Late: 0.0003
Epoch 126: 100%|██████████| 391/391 [00:16<00:00, 23.98batch/s]
Avg Loss : 1.5251 Validation Loss : 1.5613 Learning Late: 0.0003
Epoch 127: 100%|██████████| 391/391 [00:16<00:00, 24.00batch/s]
Avg Loss : 1.5051 Validation Loss : 1.5833 Learning Late: 0.0003
Epoch 128: 100%|██████████| 391/391 [00:16<00:00, 23.82batch/s]
Avg Loss : 1.4809 Validation Loss : 1.4592 Learning Late: 0.0003
Epoch 129: 100%|██████████| 391/391 [00:16<00:00, 23.83batch/s]
Avg Loss : 1.4826 Validation Loss : 1.6971 Learning Late: 0.0003
Epoch 130: 100%|██████████| 391/391 [00:16<00:00, 24.06batch/s]
Avg Loss : 1.4603 Validation Loss : 1.4830 Learning Late: 0.0003
Epoch 131: 100%|██████████| 391/391 [00:16<00:00, 23.99batch/s]
Avg Loss : 1.4584 Validation Loss : 1.5377 Learning Late: 0.0003
Epoch 132: 100%|██████████| 391/391 [00:16<00:00, 23.76batch/s]
Avg Loss : 1.4474 Validation Loss : 1.6970 Learning Late: 0.0003
Epoch 133: 100%|██████████| 391/391 [00:16<00:00, 23.83batch/s]
Avg Loss : 1.4393 Validation Loss : 1.7145 Learning Late: 0.0003
Epoch 134: 100%|██████████| 391/391 [00:16<00:00, 23.74batch/s]
Avg Loss : 1.4378 Validation Loss : 1.4774 Learning Late: 0.0003
Epoch 135: 100%|██████████| 391/391 [00:16<00:00, 23.84batch/s]
Avg Loss : 1.4259 Validation Loss : 1.4627 Learning Late: 0.0003
Epoch 136: 100%|██████████| 391/391 [00:16<00:00, 23.83batch/s]
Avg Loss : 1.3989 Validation Loss : 1.4253 Learning Late: 0.0003
Epoch 137: 100%|██████████| 391/391 [00:16<00:00, 23.83batch/s]
Avg Loss : 1.4338 Validation Loss : 1.4678 Learning Late: 0.0002
Epoch 138: 100%|██████████| 391/391 [00:16<00:00, 23.82batch/s]
Avg Loss : 1.3794 Validation Loss : 1.4217 Learning Late: 0.0002
Epoch 139: 100%|██████████| 391/391 [00:16<00:00, 23.82batch/s]
Avg Loss : 1.3693 Validation Loss : 1.4034 Learning Late: 0.0002
Epoch 140: 100%|██████████| 391/391 [00:16<00:00, 23.82batch/s]
Avg Loss : 1.3562 Validation Loss : 1.4089 Learning Late: 0.0002
Epoch 141: 100%|██████████| 391/391 [00:16<00:00, 23.86batch/s]
Avg Loss : 1.3513 Validation Loss : 1.3797 Learning Late: 0.0002
Epoch 142: 100%|██████████| 391/391 [00:16<00:00, 23.85batch/s]
Avg Loss : 1.3361 Validation Loss : 1.3776 Learning Late: 0.0002
Epoch 143: 100%|██████████| 391/391 [00:16<00:00, 23.85batch/s]
Avg Loss : 1.3378 Validation Loss : 1.4026 Learning Late: 0.0002
Epoch 144: 100%|██████████| 391/391 [00:16<00:00, 24.01batch/s]
Avg Loss : 1.3506 Validation Loss : 1.3307 Learning Late: 0.0002
Epoch 145: 100%|██████████| 391/391 [00:16<00:00, 23.91batch/s]
Avg Loss : 1.3182 Validation Loss : 1.3636 Learning Late: 0.0002
Epoch 146: 100%|██████████| 391/391 [00:16<00:00, 23.88batch/s]
Avg Loss : 1.3149 Validation Loss : 1.4262 Learning Late: 0.0002
Epoch 147: 100%|██████████| 391/391 [00:16<00:00, 23.83batch/s]
Avg Loss : 1.2988 Validation Loss : 1.3627 Learning Late: 0.0002
Epoch 148: 100%|██████████| 391/391 [00:16<00:00, 24.01batch/s]
Avg Loss : 1.2842 Validation Loss : 1.3707 Learning Late: 0.0002
Epoch 149: 100%|██████████| 391/391 [00:16<00:00, 23.95batch/s]
Avg Loss : 1.2844 Validation Loss : 1.3273 Learning Late: 0.0002
Epoch 150: 100%|██████████| 391/391 [00:16<00:00, 23.95batch/s]
Avg Loss : 1.2814 Validation Loss : 1.4201 Learning Late: 0.0002
Epoch 151: 100%|██████████| 391/391 [00:16<00:00, 23.91batch/s]
Avg Loss : 1.2707 Validation Loss : 1.2960 Learning Late: 0.0002
Epoch 152: 100%|██████████| 391/391 [00:16<00:00, 23.93batch/s]
Avg Loss : 1.2598 Validation Loss : 1.2979 Learning Late: 0.0001
Epoch 153: 100%|██████████| 391/391 [00:16<00:00, 24.00batch/s]
Avg Loss : 1.2520 Validation Loss : 1.3808 Learning Late: 0.0001
Epoch 154: 100%|██████████| 391/391 [00:16<00:00, 23.76batch/s]
Avg Loss : 1.2368 Validation Loss : 1.2624 Learning Late: 0.0001
Epoch 155: 100%|██████████| 391/391 [00:16<00:00, 23.79batch/s]
Avg Loss : 1.2263 Validation Loss : 1.2727 Learning Late: 0.0001
Epoch 156: 100%|██████████| 391/391 [00:16<00:00, 23.82batch/s]
Avg Loss : 1.2361 Validation Loss : 1.3178 Learning Late: 0.0001
Epoch 157: 100%|██████████| 391/391 [00:16<00:00, 23.80batch/s]
Avg Loss : 1.2214 Validation Loss : 1.2634 Learning Late: 0.0001
Epoch 158: 100%|██████████| 391/391 [00:16<00:00, 23.83batch/s]
Avg Loss : 1.2288 Validation Loss : 1.2884 Learning Late: 0.0001
Epoch 159: 100%|██████████| 391/391 [00:16<00:00, 24.03batch/s]
Avg Loss : 1.2132 Validation Loss : 1.3257 Learning Late: 0.0001
Epoch 160: 100%|██████████| 391/391 [00:16<00:00, 23.84batch/s]
Avg Loss : 1.1979 Validation Loss : 1.2653 Learning Late: 0.0001
Epoch 161: 100%|██████████| 391/391 [00:16<00:00, 23.92batch/s]
Avg Loss : 1.1995 Validation Loss : 1.2540 Learning Late: 0.0001
Epoch 162: 100%|██████████| 391/391 [00:16<00:00, 23.72batch/s]
Avg Loss : 1.1875 Validation Loss : 1.2733 Learning Late: 0.0001
Epoch 163: 100%|██████████| 391/391 [00:16<00:00, 23.79batch/s]
Avg Loss : 1.1878 Validation Loss : 1.2469 Learning Late: 0.0001
Epoch 164: 100%|██████████| 391/391 [00:16<00:00, 23.72batch/s]
Avg Loss : 1.1745 Validation Loss : 1.2283 Learning Late: 0.0001
Epoch 165: 100%|██████████| 391/391 [00:16<00:00, 23.49batch/s]
Avg Loss : 1.1709 Validation Loss : 1.2355 Learning Late: 0.0001
Epoch 166: 100%|██████████| 391/391 [00:16<00:00, 23.17batch/s]
Avg Loss : 1.1662 Validation Loss : 1.2356 Learning Late: 0.0001
Epoch 167: 100%|██████████| 391/391 [00:16<00:00, 23.41batch/s]
Avg Loss : 1.1611 Validation Loss : 1.2206 Learning Late: 0.0001
Epoch 168: 100%|██████████| 391/391 [00:16<00:00, 23.41batch/s]
Avg Loss : 1.1542 Validation Loss : 1.2581 Learning Late: 0.0001
Epoch 169: 100%|██████████| 391/391 [00:16<00:00, 23.44batch/s]
Avg Loss : 1.1496 Validation Loss : 1.2128 Learning Late: 0.0001
Epoch 170: 100%|██████████| 391/391 [00:16<00:00, 23.20batch/s]
Avg Loss : 1.1446 Validation Loss : 1.1915 Learning Late: 0.0001
Epoch 171: 100%|██████████| 391/391 [00:16<00:00, 23.17batch/s]
Avg Loss : 1.1399 Validation Loss : 1.2032 Learning Late: 0.0001
Epoch 172: 100%|██████████| 391/391 [00:16<00:00, 23.21batch/s]
Avg Loss : 1.1314 Validation Loss : 1.2208 Learning Late: 0.0001
Epoch 173: 100%|██████████| 391/391 [00:16<00:00, 23.18batch/s]
Avg Loss : 1.1308 Validation Loss : 1.2024 Learning Late: 0.0000
Epoch 174: 100%|██████████| 391/391 [00:16<00:00, 23.15batch/s]
Avg Loss : 1.1270 Validation Loss : 1.2012 Learning Late: 0.0000
Epoch 175: 100%|██████████| 391/391 [00:16<00:00, 23.40batch/s]
Avg Loss : 1.1225 Validation Loss : 1.2031 Learning Late: 0.0000
Epoch 176: 100%|██████████| 391/391 [00:16<00:00, 23.42batch/s]
Avg Loss : 1.1160 Validation Loss : 1.1823 Learning Late: 0.0000
Epoch 177: 100%|██████████| 391/391 [00:16<00:00, 23.42batch/s]
Avg Loss : 1.1115 Validation Loss : 1.2127 Learning Late: 0.0000
Epoch 178: 100%|██████████| 391/391 [00:16<00:00, 23.16batch/s]
Avg Loss : 1.1074 Validation Loss : 1.1902 Learning Late: 0.0000
Epoch 179: 100%|██████████| 391/391 [00:16<00:00, 23.18batch/s]
Avg Loss : 1.1048 Validation Loss : 1.1896 Learning Late: 0.0000
Epoch 180: 100%|██████████| 391/391 [00:16<00:00, 23.16batch/s]
Avg Loss : 1.1012 Validation Loss : 1.1898 Learning Late: 0.0000
Epoch 181: 100%|██████████| 391/391 [00:16<00:00, 23.40batch/s]
Avg Loss : 1.0975 Validation Loss : 1.1834 Learning Late: 0.0000
Epoch 182: 100%|██████████| 391/391 [00:16<00:00, 23.17batch/s]
Avg Loss : 1.0943 Validation Loss : 1.1591 Learning Late: 0.0000
Epoch 183: 100%|██████████| 391/391 [00:16<00:00, 23.39batch/s]
Avg Loss : 1.0920 Validation Loss : 1.1779 Learning Late: 0.0000
Epoch 184: 100%|██████████| 391/391 [00:16<00:00, 23.42batch/s]
Avg Loss : 1.0879 Validation Loss : 1.1722 Learning Late: 0.0000
Epoch 185: 100%|██████████| 391/391 [00:16<00:00, 23.41batch/s]
Avg Loss : 1.0850 Validation Loss : 1.1610 Learning Late: 0.0000
Epoch 186: 100%|██████████| 391/391 [00:16<00:00, 23.18batch/s]
Avg Loss : 1.0817 Validation Loss : 1.1576 Learning Late: 0.0000
Epoch 187: 100%|██████████| 391/391 [00:16<00:00, 23.58batch/s]
Avg Loss : 1.0794 Validation Loss : 1.1684 Learning Late: 0.0000
Epoch 188: 100%|██████████| 391/391 [00:16<00:00, 23.16batch/s]
Avg Loss : 1.0769 Validation Loss : 1.1584 Learning Late: 0.0000
Epoch 189: 100%|██████████| 391/391 [00:16<00:00, 23.30batch/s]
Avg Loss : 1.0749 Validation Loss : 1.1612 Learning Late: 0.0000
Epoch 190: 100%|██████████| 391/391 [00:18<00:00, 21.70batch/s]
Avg Loss : 1.0722 Validation Loss : 1.1573 Learning Late: 0.0000
Epoch 191: 100%|██████████| 391/391 [00:17<00:00, 22.38batch/s]
Avg Loss : 1.0699 Validation Loss : 1.1493 Learning Late: 0.0000
Epoch 192: 100%|██████████| 391/391 [00:17<00:00, 21.99batch/s]
Avg Loss : 1.0682 Validation Loss : 1.1526 Learning Late: 0.0000
Epoch 193: 100%|██████████| 391/391 [00:17<00:00, 22.50batch/s]
Avg Loss : 1.0658 Validation Loss : 1.1514 Learning Late: 0.0000
Epoch 194: 100%|██████████| 391/391 [00:17<00:00, 22.57batch/s]
Avg Loss : 1.0646 Validation Loss : 1.1567 Learning Late: 0.0000
Epoch 195: 100%|██████████| 391/391 [00:17<00:00, 22.33batch/s]
Avg Loss : 1.0634 Validation Loss : 1.1541 Learning Late: 0.0000
Epoch 196: 100%|██████████| 391/391 [00:17<00:00, 22.31batch/s]
Avg Loss : 1.0631 Validation Loss : 1.1459 Learning Late: 0.0000
Epoch 197: 100%|██████████| 391/391 [00:17<00:00, 22.32batch/s]
Avg Loss : 1.0616 Validation Loss : 1.1451 Learning Late: 0.0000
Epoch 198: 100%|██████████| 391/391 [00:17<00:00, 22.41batch/s]
Avg Loss : 1.0610 Validation Loss : 1.1525 Learning Late: 0.0000
Epoch 199: 100%|██████████| 391/391 [00:17<00:00, 22.29batch/s]
Avg Loss : 1.0606 Validation Loss : 1.1471 Learning Late: 0.0000
Epoch 200: 100%|██████████| 391/391 [00:17<00:00, 22.32batch/s]
Avg Loss : 1.0607 Validation Loss : 1.1543 Learning Late: 0.0000
실제 test
100%|██████████| 79/79 [00:09<00:00,  8.65batch/s]
총 개수 : 10000
top-1 맞춘 개수 : 6008
 정확도: 60.08
top-5 맞춘 개수 : 9572
 정확도: 95.72

종료 코드 0(으)로 완료된 프로세스
