Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz
100%|██████████| 170498071/170498071 [00:08<00:00, 19634522.95it/s]
Extracting ./data/cifar-10-python.tar.gz to ./data
Files already downloaded and verified
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Epoch 1: 100%|██████████| 98/98 [01:49<00:00,  1.12s/batch]
Avg Loss : 6.4070 Validation Loss : 6.2078 Learning Late: 1.6971
Epoch 2: 100%|██████████| 98/98 [01:46<00:00,  1.08s/batch]
Avg Loss : 6.3345 Validation Loss : 6.1937 Learning Late: 1.6971
Epoch 3: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 6.2002 Validation Loss : 6.2940 Learning Late: 1.6971
Epoch 4: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 6.2492 Validation Loss : 6.0941 Learning Late: 1.6971
Epoch 5: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 6.1850 Validation Loss : 6.1830 Learning Late: 1.6971
Epoch 6: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 6.1097 Validation Loss : 6.0700 Learning Late: 1.6971
Epoch 7: 100%|██████████| 98/98 [01:48<00:00,  1.11s/batch]
Avg Loss : 5.7211 Validation Loss : 5.5123 Learning Late: 1.6971
Epoch 8: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 5.6544 Validation Loss : 5.6119 Learning Late: 1.6971
Epoch 9: 100%|██████████| 98/98 [01:47<00:00,  1.10s/batch]
Avg Loss : 5.4708 Validation Loss : 5.6487 Learning Late: 1.6971
Epoch 10: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 5.4557 Validation Loss : 5.4339 Learning Late: 1.6971
Epoch 11: 100%|██████████| 98/98 [01:47<00:00,  1.10s/batch]
Avg Loss : 5.3815 Validation Loss : 5.2715 Learning Late: 1.6965
Epoch 12: 100%|██████████| 98/98 [01:46<00:00,  1.08s/batch]
Avg Loss : 5.2196 Validation Loss : 5.1981 Learning Late: 1.6950
Epoch 13: 100%|██████████| 98/98 [01:47<00:00,  1.09s/batch]
Avg Loss : 5.2063 Validation Loss : 4.9548 Learning Late: 1.6924
Epoch 14: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 4.8411 Validation Loss : 4.9404 Learning Late: 1.6888
Epoch 15: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 4.8497 Validation Loss : 4.8434 Learning Late: 1.6842
Epoch 16: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 4.9561 Validation Loss : 4.7700 Learning Late: 1.6785
Epoch 17: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 4.8585 Validation Loss : 4.8157 Learning Late: 1.6719
Epoch 18: 100%|██████████| 98/98 [01:47<00:00,  1.10s/batch]
Avg Loss : 4.9283 Validation Loss : 4.6984 Learning Late: 1.6642
Epoch 19: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 4.7037 Validation Loss : 4.5384 Learning Late: 1.6555
Epoch 20: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 4.5278 Validation Loss : 4.3548 Learning Late: 1.6459
Epoch 21: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 4.2002 Validation Loss : 4.1284 Learning Late: 1.6353
Epoch 22: 100%|██████████| 98/98 [01:46<00:00,  1.08s/batch]
Avg Loss : 3.7853 Validation Loss : 3.4186 Learning Late: 1.6237
Epoch 23: 100%|██████████| 98/98 [01:47<00:00,  1.09s/batch]
Avg Loss : 3.2939 Validation Loss : 3.8167 Learning Late: 1.6112
Epoch 24: 100%|██████████| 98/98 [01:46<00:00,  1.08s/batch]
Avg Loss : 3.3163 Validation Loss : 2.9919 Learning Late: 1.5977
Epoch 25: 100%|██████████| 98/98 [01:47<00:00,  1.09s/batch]
Avg Loss : 2.9456 Validation Loss : 2.6110 Learning Late: 1.5834
Epoch 26: 100%|██████████| 98/98 [01:46<00:00,  1.08s/batch]
Avg Loss : 2.5406 Validation Loss : 2.3966 Learning Late: 1.5681
Epoch 27: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 2.3598 Validation Loss : 2.0526 Learning Late: 1.5520
Epoch 28: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 2.1852 Validation Loss : 1.7309 Learning Late: 1.5350
Epoch 29: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 1.9526 Validation Loss : 2.0490 Learning Late: 1.5172
Epoch 30: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 1.8219 Validation Loss : 1.8555 Learning Late: 1.4985
Epoch 31: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 1.4994 Validation Loss : 1.3220 Learning Late: 1.4791
Epoch 32: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 1.5513 Validation Loss : 1.6603 Learning Late: 1.4589
Epoch 33: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 1.3958 Validation Loss : 1.3973 Learning Late: 1.4380
Epoch 34: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 1.4251 Validation Loss : 1.2339 Learning Late: 1.4163
Epoch 35: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 1.4944 Validation Loss : 1.2777 Learning Late: 1.3940
Epoch 36: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 1.3353 Validation Loss : 1.2507 Learning Late: 1.3709
Epoch 37: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 1.1885 Validation Loss : 1.0681 Learning Late: 1.3473
Epoch 38: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 1.0602 Validation Loss : 1.0858 Learning Late: 1.3230
Epoch 39: 100%|██████████| 98/98 [01:46<00:00,  1.08s/batch]
Avg Loss : 1.1078 Validation Loss : 0.9685 Learning Late: 1.2982
Epoch 40: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 1.0071 Validation Loss : 1.0436 Learning Late: 1.2728
Epoch 41: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 0.9768 Validation Loss : 0.9840 Learning Late: 1.2469
Epoch 42: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 1.0018 Validation Loss : 0.8236 Learning Late: 1.2205
Epoch 43: 100%|██████████| 98/98 [01:46<00:00,  1.08s/batch]
Avg Loss : 0.9601 Validation Loss : 0.8194 Learning Late: 1.1937
Epoch 44: 100%|██████████| 98/98 [01:45<00:00,  1.08s/batch]
Avg Loss : 1.1392 Validation Loss : 1.3594 Learning Late: 1.1664
Epoch 45: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 1.0298 Validation Loss : 0.9924 Learning Late: 1.1387
Epoch 46: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 0.8940 Validation Loss : 0.8993 Learning Late: 1.1107
Epoch 47: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 0.8640 Validation Loss : 0.9347 Learning Late: 1.0824
Epoch 48: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 0.8035 Validation Loss : 0.7931 Learning Late: 1.0538
Epoch 49: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 0.7068 Validation Loss : 0.7958 Learning Late: 1.0249
Epoch 50: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 0.7746 Validation Loss : 0.6953 Learning Late: 0.9959
Epoch 51: 100%|██████████| 98/98 [01:46<00:00,  1.08s/batch]
Avg Loss : 0.7387 Validation Loss : 0.9291 Learning Late: 0.9666
Epoch 52: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 0.7067 Validation Loss : 0.6841 Learning Late: 0.9372
Epoch 53: 100%|██████████| 98/98 [01:45<00:00,  1.08s/batch]
Avg Loss : 0.7416 Validation Loss : 0.6172 Learning Late: 0.9077
Epoch 54: 100%|██████████| 98/98 [01:45<00:00,  1.08s/batch]
Avg Loss : 0.6333 Validation Loss : 0.5857 Learning Late: 0.8781
Epoch 55: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 0.6569 Validation Loss : 0.6967 Learning Late: 0.8485
Epoch 56: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 0.7163 Validation Loss : 0.4977 Learning Late: 0.8189
Epoch 57: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 0.6759 Validation Loss : 0.6576 Learning Late: 0.7893
Epoch 58: 100%|██████████| 98/98 [01:46<00:00,  1.08s/batch]
Avg Loss : 0.6617 Validation Loss : 0.6965 Learning Late: 0.7598
Epoch 59: 100%|██████████| 98/98 [01:45<00:00,  1.08s/batch]
Avg Loss : 0.5772 Validation Loss : 0.5539 Learning Late: 0.7304
Epoch 60: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 0.5845 Validation Loss : 0.6534 Learning Late: 0.7012
Epoch 61: 100%|██████████| 98/98 [01:45<00:00,  1.08s/batch]
Avg Loss : 0.6325 Validation Loss : 0.5835 Learning Late: 0.6721
Epoch 62: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 0.6323 Validation Loss : 0.5272 Learning Late: 0.6433
Epoch 63: 100%|██████████| 98/98 [01:46<00:00,  1.08s/batch]
Avg Loss : 0.4991 Validation Loss : 0.6127 Learning Late: 0.6146
Epoch 64: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 0.5425 Validation Loss : 0.5653 Learning Late: 0.5863
Epoch 65: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 0.6350 Validation Loss : 0.5269 Learning Late: 0.5583
Epoch 66: 100%|██████████| 98/98 [01:47<00:00,  1.09s/batch]
Avg Loss : 0.5460 Validation Loss : 0.6556 Learning Late: 0.5307
Epoch 67: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 0.5618 Validation Loss : 0.7310 Learning Late: 0.5034
Epoch 68: 100%|██████████| 98/98 [01:47<00:00,  1.10s/batch]
Avg Loss : 0.5877 Validation Loss : 0.6586 Learning Late: 0.4766
Epoch 69: 100%|██████████| 98/98 [01:45<00:00,  1.08s/batch]
Avg Loss : 0.5292 Validation Loss : 0.5648 Learning Late: 0.4502
Epoch 70: 100%|██████████| 98/98 [01:47<00:00,  1.09s/batch]
Avg Loss : 0.5584 Validation Loss : 0.4543 Learning Late: 0.4243
Epoch 71: 100%|██████████| 98/98 [01:46<00:00,  1.08s/batch]
Avg Loss : 0.4929 Validation Loss : 0.4438 Learning Late: 0.3989
Epoch 72: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 0.4738 Validation Loss : 0.3619 Learning Late: 0.3740
Epoch 73: 100%|██████████| 98/98 [01:46<00:00,  1.08s/batch]
Avg Loss : 0.5437 Validation Loss : 0.3522 Learning Late: 0.3498
Epoch 74: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 0.4904 Validation Loss : 0.4045 Learning Late: 0.3261
Epoch 75: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 0.4536 Validation Loss : 0.3769 Learning Late: 0.3031
Epoch 76: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 0.5191 Validation Loss : 0.4435 Learning Late: 0.2808
Epoch 77: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 0.4658 Validation Loss : 0.5048 Learning Late: 0.2591
Epoch 78: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 0.4560 Validation Loss : 0.4394 Learning Late: 0.2381
Epoch 79: 100%|██████████| 98/98 [01:46<00:00,  1.08s/batch]
Avg Loss : 0.4724 Validation Loss : 0.4534 Learning Late: 0.2179
Epoch 80: 100%|██████████| 98/98 [01:47<00:00,  1.09s/batch]
Avg Loss : 0.4299 Validation Loss : 0.4473 Learning Late: 0.1985
Epoch 81: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 0.4603 Validation Loss : 0.5277 Learning Late: 0.1799
Epoch 82: 100%|██████████| 98/98 [01:46<00:00,  1.08s/batch]
Avg Loss : 0.4575 Validation Loss : 0.4648 Learning Late: 0.1621
Epoch 83: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 0.4540 Validation Loss : 0.5791 Learning Late: 0.1451
Epoch 84: 100%|██████████| 98/98 [01:46<00:00,  1.08s/batch]
Avg Loss : 0.4411 Validation Loss : 0.5363 Learning Late: 0.1289
Epoch 85: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 0.3928 Validation Loss : 0.4574 Learning Late: 0.1137
Epoch 86: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 0.4841 Validation Loss : 0.4499 Learning Late: 0.0993
Epoch 87: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 0.4034 Validation Loss : 0.4767 Learning Late: 0.0859
Epoch 88: 100%|██████████| 98/98 [01:45<00:00,  1.08s/batch]
Avg Loss : 0.4375 Validation Loss : 0.5753 Learning Late: 0.0734
Epoch 89: 100%|██████████| 98/98 [01:45<00:00,  1.08s/batch]
Avg Loss : 0.4436 Validation Loss : 0.5054 Learning Late: 0.0618
Epoch 90: 100%|██████████| 98/98 [01:45<00:00,  1.08s/batch]
Avg Loss : 0.4617 Validation Loss : 0.3489 Learning Late: 0.0512
Epoch 91: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 0.3950 Validation Loss : 0.4103 Learning Late: 0.0415
Epoch 92: 100%|██████████| 98/98 [01:46<00:00,  1.08s/batch]
Avg Loss : 0.4130 Validation Loss : 0.3330 Learning Late: 0.0329
Epoch 93: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 0.4152 Validation Loss : 0.5085 Learning Late: 0.0252
Epoch 94: 100%|██████████| 98/98 [01:46<00:00,  1.08s/batch]
Avg Loss : 0.4011 Validation Loss : 0.4234 Learning Late: 0.0185
Epoch 95: 100%|██████████| 98/98 [01:46<00:00,  1.08s/batch]
Avg Loss : 0.4783 Validation Loss : 0.4592 Learning Late: 0.0129
Epoch 96: 100%|██████████| 98/98 [01:46<00:00,  1.08s/batch]
Avg Loss : 0.3960 Validation Loss : 0.4134 Learning Late: 0.0083
Epoch 97: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 0.4018 Validation Loss : 0.3382 Learning Late: 0.0046
Epoch 98: 100%|██████████| 98/98 [01:45<00:00,  1.08s/batch]
Avg Loss : 0.4352 Validation Loss : 0.4400 Learning Late: 0.0021
Epoch 99: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 0.4403 Validation Loss : 0.4235 Learning Late: 0.0005
Epoch 100: 100%|██████████| 98/98 [01:46<00:00,  1.09s/batch]
Avg Loss : 0.3649 Validation Loss : 0.4173 Learning Late: 0.0000
FG 학습 완료. 이제 F의 output을 실제 dataset의 label과 연결.
Files already downloaded and verified
Files already downloaded and verified
Epoch 1: 100%|██████████| 391/391 [00:13<00:00, 28.57batch/s]
Avg Loss : 10.1521 Validation Loss : 6.0566 Learning Late: 0.0010
Epoch 2: 100%|██████████| 391/391 [00:13<00:00, 29.49batch/s]
Avg Loss : 4.9336 Validation Loss : 4.3397 Learning Late: 0.0010
Epoch 3: 100%|██████████| 391/391 [00:13<00:00, 29.25batch/s]
Avg Loss : 4.1552 Validation Loss : 3.8332 Learning Late: 0.0010
Epoch 4: 100%|██████████| 391/391 [00:13<00:00, 30.05batch/s]
Avg Loss : 3.8569 Validation Loss : 3.8122 Learning Late: 0.0010
Epoch 5: 100%|██████████| 391/391 [00:13<00:00, 29.83batch/s]
Avg Loss : 3.6282 Validation Loss : 3.3032 Learning Late: 0.0010
Epoch 6: 100%|██████████| 391/391 [00:12<00:00, 30.12batch/s]
Avg Loss : 3.6861 Validation Loss : 3.5011 Learning Late: 0.0010
Epoch 7: 100%|██████████| 391/391 [00:13<00:00, 29.74batch/s]
Avg Loss : 3.5087 Validation Loss : 4.0119 Learning Late: 0.0010
Epoch 8: 100%|██████████| 391/391 [00:12<00:00, 30.28batch/s]
Avg Loss : 3.4203 Validation Loss : 2.8806 Learning Late: 0.0010
Epoch 9: 100%|██████████| 391/391 [00:12<00:00, 30.20batch/s]
Avg Loss : 3.4201 Validation Loss : 3.2295 Learning Late: 0.0010
Epoch 10: 100%|██████████| 391/391 [00:12<00:00, 30.31batch/s]
Avg Loss : 3.3088 Validation Loss : 4.0340 Learning Late: 0.0010
Epoch 11: 100%|██████████| 391/391 [00:12<00:00, 30.92batch/s]
Avg Loss : 3.2144 Validation Loss : 2.8066 Learning Late: 0.0010
Epoch 12: 100%|██████████| 391/391 [00:12<00:00, 32.20batch/s]
Avg Loss : 3.1527 Validation Loss : 3.3275 Learning Late: 0.0010
Epoch 13: 100%|██████████| 391/391 [00:14<00:00, 26.54batch/s]
Avg Loss : 3.2229 Validation Loss : 3.2795 Learning Late: 0.0010
Epoch 14: 100%|██████████| 391/391 [00:12<00:00, 31.02batch/s]
Avg Loss : 3.3649 Validation Loss : 3.2549 Learning Late: 0.0010
Epoch 15: 100%|██████████| 391/391 [00:12<00:00, 30.69batch/s]
Avg Loss : 3.0973 Validation Loss : 3.1592 Learning Late: 0.0010
Epoch 16: 100%|██████████| 391/391 [00:12<00:00, 31.91batch/s]
Avg Loss : 3.2655 Validation Loss : 4.1000 Learning Late: 0.0010
Epoch 17: 100%|██████████| 391/391 [00:12<00:00, 31.60batch/s]
Avg Loss : 3.3314 Validation Loss : 3.6260 Learning Late: 0.0010
Epoch 18: 100%|██████████| 391/391 [00:12<00:00, 30.81batch/s]
Avg Loss : 3.0948 Validation Loss : 3.7639 Learning Late: 0.0010
Epoch 19: 100%|██████████| 391/391 [00:12<00:00, 30.71batch/s]
Avg Loss : 3.2621 Validation Loss : 3.1080 Learning Late: 0.0010
Epoch 20: 100%|██████████| 391/391 [00:12<00:00, 31.93batch/s]
Avg Loss : 3.2033 Validation Loss : 2.9057 Learning Late: 0.0010
Epoch 21: 100%|██████████| 391/391 [00:12<00:00, 31.43batch/s]
Avg Loss : 3.2294 Validation Loss : 3.3093 Learning Late: 0.0010
Epoch 22: 100%|██████████| 391/391 [00:12<00:00, 32.04batch/s]
Avg Loss : 3.2443 Validation Loss : 3.5682 Learning Late: 0.0010
Epoch 23: 100%|██████████| 391/391 [00:12<00:00, 31.47batch/s]
Avg Loss : 3.2565 Validation Loss : 3.5284 Learning Late: 0.0010
Epoch 24: 100%|██████████| 391/391 [00:12<00:00, 31.89batch/s]
Avg Loss : 3.1858 Validation Loss : 3.7691 Learning Late: 0.0010
Epoch 25: 100%|██████████| 391/391 [00:12<00:00, 32.40batch/s]
Avg Loss : 3.2232 Validation Loss : 2.9800 Learning Late: 0.0010
Epoch 26: 100%|██████████| 391/391 [00:11<00:00, 33.48batch/s]
Avg Loss : 3.3167 Validation Loss : 3.2576 Learning Late: 0.0010
Epoch 27: 100%|██████████| 391/391 [00:11<00:00, 33.05batch/s]
Avg Loss : 3.2408 Validation Loss : 4.3079 Learning Late: 0.0010
Epoch 28: 100%|██████████| 391/391 [00:12<00:00, 32.51batch/s]
Avg Loss : 3.1970 Validation Loss : 3.0645 Learning Late: 0.0010
Epoch 29: 100%|██████████| 391/391 [00:11<00:00, 32.80batch/s]
Avg Loss : 3.0739 Validation Loss : 3.0674 Learning Late: 0.0010
Epoch 30: 100%|██████████| 391/391 [00:11<00:00, 33.24batch/s]
Avg Loss : 3.2495 Validation Loss : 3.1739 Learning Late: 0.0010
Epoch 31: 100%|██████████| 391/391 [00:12<00:00, 31.89batch/s]
Avg Loss : 3.1225 Validation Loss : 3.6180 Learning Late: 0.0010
Epoch 32: 100%|██████████| 391/391 [00:12<00:00, 31.69batch/s]
Avg Loss : 3.1504 Validation Loss : 3.6335 Learning Late: 0.0010
Epoch 33: 100%|██████████| 391/391 [00:14<00:00, 27.69batch/s]
Avg Loss : 3.0875 Validation Loss : 4.1392 Learning Late: 0.0010
Epoch 34: 100%|██████████| 391/391 [00:12<00:00, 32.21batch/s]
Avg Loss : 3.2934 Validation Loss : 2.8134 Learning Late: 0.0010
Epoch 35: 100%|██████████| 391/391 [00:12<00:00, 31.53batch/s]
Avg Loss : 3.0424 Validation Loss : 3.8005 Learning Late: 0.0010
Epoch 36: 100%|██████████| 391/391 [00:12<00:00, 31.74batch/s]
Avg Loss : 3.0781 Validation Loss : 2.8809 Learning Late: 0.0010
Epoch 37: 100%|██████████| 391/391 [00:12<00:00, 31.17batch/s]
Avg Loss : 3.1483 Validation Loss : 3.8820 Learning Late: 0.0010
Epoch 38: 100%|██████████| 391/391 [00:12<00:00, 31.48batch/s]
Avg Loss : 3.1813 Validation Loss : 2.9226 Learning Late: 0.0009
Epoch 39: 100%|██████████| 391/391 [00:12<00:00, 31.14batch/s]
Avg Loss : 3.0318 Validation Loss : 3.4849 Learning Late: 0.0009
Epoch 40: 100%|██████████| 391/391 [00:12<00:00, 31.38batch/s]
Avg Loss : 2.9263 Validation Loss : 3.0070 Learning Late: 0.0009
Epoch 41: 100%|██████████| 391/391 [00:12<00:00, 30.74batch/s]
Avg Loss : 2.9775 Validation Loss : 3.3476 Learning Late: 0.0009
Epoch 42: 100%|██████████| 391/391 [00:12<00:00, 31.28batch/s]
Avg Loss : 3.1751 Validation Loss : 3.4270 Learning Late: 0.0009
Epoch 43: 100%|██████████| 391/391 [00:12<00:00, 30.91batch/s]
Avg Loss : 2.9834 Validation Loss : 3.3345 Learning Late: 0.0009
Epoch 44: 100%|██████████| 391/391 [00:12<00:00, 31.74batch/s]
Avg Loss : 3.0594 Validation Loss : 3.3014 Learning Late: 0.0009
Epoch 45: 100%|██████████| 391/391 [00:12<00:00, 30.90batch/s]
Avg Loss : 2.9612 Validation Loss : 2.7431 Learning Late: 0.0009
Epoch 46: 100%|██████████| 391/391 [00:12<00:00, 30.21batch/s]
Avg Loss : 3.1628 Validation Loss : 2.8892 Learning Late: 0.0009
Epoch 47: 100%|██████████| 391/391 [00:12<00:00, 30.72batch/s]
Avg Loss : 3.0791 Validation Loss : 4.0904 Learning Late: 0.0009
Epoch 48: 100%|██████████| 391/391 [00:12<00:00, 30.95batch/s]
Avg Loss : 3.0690 Validation Loss : 3.2800 Learning Late: 0.0009
Epoch 49: 100%|██████████| 391/391 [00:12<00:00, 31.43batch/s]
Avg Loss : 2.8464 Validation Loss : 3.1141 Learning Late: 0.0009
Epoch 50: 100%|██████████| 391/391 [00:12<00:00, 31.23batch/s]
Avg Loss : 2.8642 Validation Loss : 3.8103 Learning Late: 0.0009
Epoch 51: 100%|██████████| 391/391 [00:12<00:00, 31.42batch/s]
Avg Loss : 2.9344 Validation Loss : 2.9036 Learning Late: 0.0009
Epoch 52: 100%|██████████| 391/391 [00:12<00:00, 30.75batch/s]
Avg Loss : 2.8871 Validation Loss : 2.9989 Learning Late: 0.0009
Epoch 53: 100%|██████████| 391/391 [00:14<00:00, 26.51batch/s]
Avg Loss : 2.8362 Validation Loss : 3.2107 Learning Late: 0.0009
Epoch 54: 100%|██████████| 391/391 [00:12<00:00, 30.19batch/s]
Avg Loss : 3.0300 Validation Loss : 3.1960 Learning Late: 0.0009
Epoch 55: 100%|██████████| 391/391 [00:12<00:00, 30.70batch/s]
Avg Loss : 2.8247 Validation Loss : 3.1998 Learning Late: 0.0009
Epoch 56: 100%|██████████| 391/391 [00:12<00:00, 30.95batch/s]
Avg Loss : 2.8327 Validation Loss : 3.2870 Learning Late: 0.0009
Epoch 57: 100%|██████████| 391/391 [00:12<00:00, 30.72batch/s]
Avg Loss : 2.8209 Validation Loss : 3.3884 Learning Late: 0.0009
Epoch 58: 100%|██████████| 391/391 [00:12<00:00, 30.40batch/s]
Avg Loss : 2.7992 Validation Loss : 2.5977 Learning Late: 0.0009
Epoch 59: 100%|██████████| 391/391 [00:13<00:00, 29.97batch/s]
Avg Loss : 2.8350 Validation Loss : 3.1465 Learning Late: 0.0008
Epoch 60: 100%|██████████| 391/391 [00:12<00:00, 30.14batch/s]
Avg Loss : 2.7745 Validation Loss : 2.5612 Learning Late: 0.0008
Epoch 61: 100%|██████████| 391/391 [00:12<00:00, 30.09batch/s]
Avg Loss : 2.8894 Validation Loss : 3.1252 Learning Late: 0.0008
Epoch 62: 100%|██████████| 391/391 [00:13<00:00, 30.02batch/s]
Avg Loss : 2.8453 Validation Loss : 2.9192 Learning Late: 0.0008
Epoch 63: 100%|██████████| 391/391 [00:12<00:00, 30.55batch/s]
Avg Loss : 2.8290 Validation Loss : 2.8988 Learning Late: 0.0008
Epoch 64: 100%|██████████| 391/391 [00:12<00:00, 31.04batch/s]
Avg Loss : 2.6968 Validation Loss : 2.6481 Learning Late: 0.0008
Epoch 65: 100%|██████████| 391/391 [00:12<00:00, 30.75batch/s]
Avg Loss : 2.7039 Validation Loss : 3.6441 Learning Late: 0.0008
Epoch 66: 100%|██████████| 391/391 [00:12<00:00, 30.48batch/s]
Avg Loss : 2.6914 Validation Loss : 2.5883 Learning Late: 0.0008
Epoch 67: 100%|██████████| 391/391 [00:12<00:00, 31.05batch/s]
Avg Loss : 2.6679 Validation Loss : 2.5881 Learning Late: 0.0008
Epoch 68: 100%|██████████| 391/391 [00:12<00:00, 30.27batch/s]
Avg Loss : 2.5708 Validation Loss : 3.0671 Learning Late: 0.0008
Epoch 69: 100%|██████████| 391/391 [00:12<00:00, 30.68batch/s]
Avg Loss : 2.6608 Validation Loss : 2.8451 Learning Late: 0.0008
Epoch 70: 100%|██████████| 391/391 [00:12<00:00, 30.24batch/s]
Avg Loss : 2.5425 Validation Loss : 2.8275 Learning Late: 0.0008
Epoch 71: 100%|██████████| 391/391 [00:12<00:00, 30.29batch/s]
Avg Loss : 2.6386 Validation Loss : 2.5245 Learning Late: 0.0008
Epoch 72: 100%|██████████| 391/391 [00:13<00:00, 29.87batch/s]
Avg Loss : 2.5913 Validation Loss : 2.9992 Learning Late: 0.0008
Epoch 73: 100%|██████████| 391/391 [00:15<00:00, 24.93batch/s]
Avg Loss : 2.5368 Validation Loss : 2.9973 Learning Late: 0.0008
Epoch 74: 100%|██████████| 391/391 [00:13<00:00, 28.89batch/s]
Avg Loss : 2.5230 Validation Loss : 2.8022 Learning Late: 0.0007
Epoch 75: 100%|██████████| 391/391 [00:13<00:00, 28.50batch/s]
Avg Loss : 2.4309 Validation Loss : 2.4797 Learning Late: 0.0007
Epoch 76: 100%|██████████| 391/391 [00:13<00:00, 29.00batch/s]
Avg Loss : 2.5599 Validation Loss : 2.7836 Learning Late: 0.0007
Epoch 77: 100%|██████████| 391/391 [00:13<00:00, 29.35batch/s]
Avg Loss : 2.4839 Validation Loss : 3.4773 Learning Late: 0.0007
Epoch 78: 100%|██████████| 391/391 [00:13<00:00, 29.38batch/s]
Avg Loss : 2.5337 Validation Loss : 2.8963 Learning Late: 0.0007
Epoch 79: 100%|██████████| 391/391 [00:13<00:00, 29.51batch/s]
Avg Loss : 2.4446 Validation Loss : 2.1077 Learning Late: 0.0007
Epoch 80: 100%|██████████| 391/391 [00:13<00:00, 29.72batch/s]
Avg Loss : 2.4740 Validation Loss : 2.4957 Learning Late: 0.0007
Epoch 81: 100%|██████████| 391/391 [00:13<00:00, 29.06batch/s]
Avg Loss : 2.3670 Validation Loss : 3.0920 Learning Late: 0.0007
Epoch 82: 100%|██████████| 391/391 [00:13<00:00, 28.96batch/s]
Avg Loss : 2.3789 Validation Loss : 2.1288 Learning Late: 0.0007
Epoch 83: 100%|██████████| 391/391 [00:13<00:00, 29.49batch/s]
Avg Loss : 2.3008 Validation Loss : 2.4386 Learning Late: 0.0007
Epoch 84: 100%|██████████| 391/391 [00:13<00:00, 29.86batch/s]
Avg Loss : 2.3632 Validation Loss : 2.8019 Learning Late: 0.0007
Epoch 85: 100%|██████████| 391/391 [00:12<00:00, 30.22batch/s]
Avg Loss : 2.3466 Validation Loss : 2.1569 Learning Late: 0.0007
Epoch 86: 100%|██████████| 391/391 [00:12<00:00, 31.02batch/s]
Avg Loss : 2.3059 Validation Loss : 2.4895 Learning Late: 0.0007
Epoch 87: 100%|██████████| 391/391 [00:12<00:00, 30.42batch/s]
Avg Loss : 2.2819 Validation Loss : 2.3679 Learning Late: 0.0006
Epoch 88: 100%|██████████| 391/391 [00:13<00:00, 30.06batch/s]
Avg Loss : 2.2356 Validation Loss : 2.1205 Learning Late: 0.0006
Epoch 89: 100%|██████████| 391/391 [00:13<00:00, 30.06batch/s]
Avg Loss : 2.1747 Validation Loss : 3.0397 Learning Late: 0.0006
Epoch 90: 100%|██████████| 391/391 [00:12<00:00, 30.54batch/s]
Avg Loss : 2.2818 Validation Loss : 2.3701 Learning Late: 0.0006
Epoch 91: 100%|██████████| 391/391 [00:12<00:00, 30.85batch/s]
Avg Loss : 2.1519 Validation Loss : 2.6404 Learning Late: 0.0006
Epoch 92: 100%|██████████| 391/391 [00:13<00:00, 30.03batch/s]
Avg Loss : 2.2472 Validation Loss : 2.1579 Learning Late: 0.0006
Epoch 93: 100%|██████████| 391/391 [00:14<00:00, 26.68batch/s]
Avg Loss : 2.1400 Validation Loss : 2.3297 Learning Late: 0.0006
Epoch 94: 100%|██████████| 391/391 [00:13<00:00, 29.30batch/s]
Avg Loss : 2.2429 Validation Loss : 2.3858 Learning Late: 0.0006
Epoch 95: 100%|██████████| 391/391 [00:13<00:00, 29.07batch/s]
Avg Loss : 2.1132 Validation Loss : 2.2740 Learning Late: 0.0006
Epoch 96: 100%|██████████| 391/391 [00:13<00:00, 29.30batch/s]
Avg Loss : 2.0309 Validation Loss : 2.5217 Learning Late: 0.0006
Epoch 97: 100%|██████████| 391/391 [00:13<00:00, 29.94batch/s]
Avg Loss : 2.2059 Validation Loss : 2.2139 Learning Late: 0.0006
Epoch 98: 100%|██████████| 391/391 [00:13<00:00, 29.65batch/s]
Avg Loss : 2.0603 Validation Loss : 1.8630 Learning Late: 0.0006
Epoch 99: 100%|██████████| 391/391 [00:12<00:00, 30.08batch/s]
Avg Loss : 2.0491 Validation Loss : 1.9582 Learning Late: 0.0005
Epoch 100: 100%|██████████| 391/391 [00:13<00:00, 29.68batch/s]
Avg Loss : 2.0129 Validation Loss : 1.9936 Learning Late: 0.0005
Epoch 101: 100%|██████████| 391/391 [00:12<00:00, 30.41batch/s]
Avg Loss : 2.0159 Validation Loss : 1.8214 Learning Late: 0.0005
Epoch 102: 100%|██████████| 391/391 [00:12<00:00, 31.00batch/s]
Avg Loss : 1.9339 Validation Loss : 1.9293 Learning Late: 0.0005
Epoch 103: 100%|██████████| 391/391 [00:12<00:00, 31.66batch/s]
Avg Loss : 1.8824 Validation Loss : 2.3330 Learning Late: 0.0005
Epoch 104: 100%|██████████| 391/391 [00:12<00:00, 31.36batch/s]
Avg Loss : 1.9386 Validation Loss : 1.9528 Learning Late: 0.0005
Epoch 105: 100%|██████████| 391/391 [00:12<00:00, 31.54batch/s]
Avg Loss : 1.9463 Validation Loss : 2.3374 Learning Late: 0.0005
Epoch 106: 100%|██████████| 391/391 [00:12<00:00, 30.82batch/s]
Avg Loss : 1.9027 Validation Loss : 2.0061 Learning Late: 0.0005
Epoch 107: 100%|██████████| 391/391 [00:12<00:00, 31.43batch/s]
Avg Loss : 1.8676 Validation Loss : 1.8532 Learning Late: 0.0005
Epoch 108: 100%|██████████| 391/391 [00:12<00:00, 30.63batch/s]
Avg Loss : 1.8717 Validation Loss : 1.8548 Learning Late: 0.0005
Epoch 109: 100%|██████████| 391/391 [00:12<00:00, 30.94batch/s]
Avg Loss : 1.8579 Validation Loss : 1.9303 Learning Late: 0.0005
Epoch 110: 100%|██████████| 391/391 [00:12<00:00, 30.80batch/s]
Avg Loss : 1.9097 Validation Loss : 2.0430 Learning Late: 0.0005
Epoch 111: 100%|██████████| 391/391 [00:12<00:00, 30.91batch/s]
Avg Loss : 1.8188 Validation Loss : 1.7838 Learning Late: 0.0005
Epoch 112: 100%|██████████| 391/391 [00:13<00:00, 30.06batch/s]
Avg Loss : 1.7760 Validation Loss : 1.8144 Learning Late: 0.0004
Epoch 113: 100%|██████████| 391/391 [00:15<00:00, 25.49batch/s]
Avg Loss : 1.7916 Validation Loss : 1.9534 Learning Late: 0.0004
Epoch 114: 100%|██████████| 391/391 [00:13<00:00, 29.49batch/s]
Avg Loss : 1.7327 Validation Loss : 1.8076 Learning Late: 0.0004
Epoch 115: 100%|██████████| 391/391 [00:12<00:00, 30.28batch/s]
Avg Loss : 1.7612 Validation Loss : 1.8152 Learning Late: 0.0004
Epoch 116: 100%|██████████| 391/391 [00:13<00:00, 29.72batch/s]
Avg Loss : 1.7396 Validation Loss : 1.8927 Learning Late: 0.0004
Epoch 117: 100%|██████████| 391/391 [00:13<00:00, 29.85batch/s]
Avg Loss : 1.6821 Validation Loss : 1.6484 Learning Late: 0.0004
Epoch 118: 100%|██████████| 391/391 [00:12<00:00, 30.34batch/s]
Avg Loss : 1.6834 Validation Loss : 1.9540 Learning Late: 0.0004
Epoch 119: 100%|██████████| 391/391 [00:12<00:00, 31.40batch/s]
Avg Loss : 1.6522 Validation Loss : 1.9109 Learning Late: 0.0004
Epoch 120: 100%|██████████| 391/391 [00:12<00:00, 32.07batch/s]
Avg Loss : 1.6609 Validation Loss : 1.5260 Learning Late: 0.0004
Epoch 121: 100%|██████████| 391/391 [00:12<00:00, 31.39batch/s]
Avg Loss : 1.6408 Validation Loss : 1.7338 Learning Late: 0.0004
Epoch 122: 100%|██████████| 391/391 [00:12<00:00, 31.98batch/s]
Avg Loss : 1.6537 Validation Loss : 1.7362 Learning Late: 0.0004
Epoch 123: 100%|██████████| 391/391 [00:12<00:00, 31.57batch/s]
Avg Loss : 1.5804 Validation Loss : 1.6851 Learning Late: 0.0004
Epoch 124: 100%|██████████| 391/391 [00:12<00:00, 31.41batch/s]
Avg Loss : 1.5761 Validation Loss : 1.7255 Learning Late: 0.0003
Epoch 125: 100%|██████████| 391/391 [00:12<00:00, 31.41batch/s]
Avg Loss : 1.5697 Validation Loss : 1.5325 Learning Late: 0.0003
Epoch 126: 100%|██████████| 391/391 [00:12<00:00, 32.00batch/s]
Avg Loss : 1.5377 Validation Loss : 1.5913 Learning Late: 0.0003
Epoch 127: 100%|██████████| 391/391 [00:12<00:00, 32.32batch/s]
Avg Loss : 1.5403 Validation Loss : 1.5257 Learning Late: 0.0003
Epoch 128: 100%|██████████| 391/391 [00:12<00:00, 30.90batch/s]
Avg Loss : 1.5190 Validation Loss : 1.6972 Learning Late: 0.0003
Epoch 129: 100%|██████████| 391/391 [00:12<00:00, 31.33batch/s]
Avg Loss : 1.5578 Validation Loss : 1.8084 Learning Late: 0.0003
Epoch 130: 100%|██████████| 391/391 [00:12<00:00, 31.24batch/s]
Avg Loss : 1.4968 Validation Loss : 1.7111 Learning Late: 0.0003
Epoch 131: 100%|██████████| 391/391 [00:12<00:00, 31.52batch/s]
Avg Loss : 1.4666 Validation Loss : 1.5331 Learning Late: 0.0003
Epoch 132: 100%|██████████| 391/391 [00:12<00:00, 30.72batch/s]
Avg Loss : 1.4783 Validation Loss : 1.5204 Learning Late: 0.0003
Epoch 133: 100%|██████████| 391/391 [00:12<00:00, 30.26batch/s]
Avg Loss : 1.4422 Validation Loss : 1.5667 Learning Late: 0.0003
Epoch 134: 100%|██████████| 391/391 [00:14<00:00, 27.86batch/s]
Avg Loss : 1.4576 Validation Loss : 1.6786 Learning Late: 0.0003
Epoch 135: 100%|██████████| 391/391 [00:13<00:00, 29.50batch/s]
Avg Loss : 1.4277 Validation Loss : 1.4956 Learning Late: 0.0003
Epoch 136: 100%|██████████| 391/391 [00:12<00:00, 30.38batch/s]
Avg Loss : 1.4118 Validation Loss : 1.3962 Learning Late: 0.0003
Epoch 137: 100%|██████████| 391/391 [00:12<00:00, 30.21batch/s]
Avg Loss : 1.4297 Validation Loss : 1.6175 Learning Late: 0.0002
Epoch 138: 100%|██████████| 391/391 [00:12<00:00, 30.78batch/s]
Avg Loss : 1.3490 Validation Loss : 1.5073 Learning Late: 0.0002
Epoch 139: 100%|██████████| 391/391 [00:12<00:00, 30.34batch/s]
Avg Loss : 1.3722 Validation Loss : 1.6463 Learning Late: 0.0002
Epoch 140: 100%|██████████| 391/391 [00:12<00:00, 31.20batch/s]
Avg Loss : 1.3567 Validation Loss : 1.3333 Learning Late: 0.0002
Epoch 141: 100%|██████████| 391/391 [00:12<00:00, 30.73batch/s]
Avg Loss : 1.3477 Validation Loss : 1.4808 Learning Late: 0.0002
Epoch 142: 100%|██████████| 391/391 [00:12<00:00, 31.49batch/s]
Avg Loss : 1.3189 Validation Loss : 1.4273 Learning Late: 0.0002
Epoch 143: 100%|██████████| 391/391 [00:12<00:00, 31.83batch/s]
Avg Loss : 1.3201 Validation Loss : 1.5495 Learning Late: 0.0002
Epoch 144: 100%|██████████| 391/391 [00:12<00:00, 31.03batch/s]
Avg Loss : 1.3601 Validation Loss : 1.4854 Learning Late: 0.0002
Epoch 145: 100%|██████████| 391/391 [00:12<00:00, 30.48batch/s]
Avg Loss : 1.3012 Validation Loss : 1.3275 Learning Late: 0.0002
Epoch 146: 100%|██████████| 391/391 [00:12<00:00, 30.94batch/s]
Avg Loss : 1.2924 Validation Loss : 1.2802 Learning Late: 0.0002
Epoch 147: 100%|██████████| 391/391 [00:12<00:00, 30.58batch/s]
Avg Loss : 1.2821 Validation Loss : 1.3012 Learning Late: 0.0002
Epoch 148: 100%|██████████| 391/391 [00:12<00:00, 30.91batch/s]
Avg Loss : 1.2729 Validation Loss : 1.3595 Learning Late: 0.0002
Epoch 149: 100%|██████████| 391/391 [00:13<00:00, 29.51batch/s]
Avg Loss : 1.2542 Validation Loss : 1.3209 Learning Late: 0.0002
Epoch 150: 100%|██████████| 391/391 [00:13<00:00, 29.25batch/s]
Avg Loss : 1.2537 Validation Loss : 1.4315 Learning Late: 0.0002
Epoch 151: 100%|██████████| 391/391 [00:13<00:00, 28.58batch/s]
Avg Loss : 1.2315 Validation Loss : 1.2965 Learning Late: 0.0002
Epoch 152: 100%|██████████| 391/391 [00:12<00:00, 30.35batch/s]
Avg Loss : 1.2500 Validation Loss : 1.2902 Learning Late: 0.0001
Epoch 153: 100%|██████████| 391/391 [00:13<00:00, 29.84batch/s]
Avg Loss : 1.2057 Validation Loss : 1.2036 Learning Late: 0.0001
Epoch 154: 100%|██████████| 391/391 [00:13<00:00, 29.98batch/s]
Avg Loss : 1.2017 Validation Loss : 1.4187 Learning Late: 0.0001
Epoch 155: 100%|██████████| 391/391 [00:12<00:00, 31.78batch/s]
Avg Loss : 1.2051 Validation Loss : 1.3050 Learning Late: 0.0001
Epoch 156: 100%|██████████| 391/391 [00:13<00:00, 29.74batch/s]
Avg Loss : 1.2025 Validation Loss : 1.3766 Learning Late: 0.0001
Epoch 157: 100%|██████████| 391/391 [00:13<00:00, 30.07batch/s]
Avg Loss : 1.1814 Validation Loss : 1.2436 Learning Late: 0.0001
Epoch 158: 100%|██████████| 391/391 [00:13<00:00, 29.77batch/s]
Avg Loss : 1.1833 Validation Loss : 1.2047 Learning Late: 0.0001
Epoch 159: 100%|██████████| 391/391 [00:12<00:00, 30.53batch/s]
Avg Loss : 1.1674 Validation Loss : 1.2540 Learning Late: 0.0001
Epoch 160: 100%|██████████| 391/391 [00:13<00:00, 29.82batch/s]
Avg Loss : 1.1565 Validation Loss : 1.2369 Learning Late: 0.0001
Epoch 161: 100%|██████████| 391/391 [00:12<00:00, 30.27batch/s]
Avg Loss : 1.1449 Validation Loss : 1.1618 Learning Late: 0.0001
Epoch 162: 100%|██████████| 391/391 [00:13<00:00, 29.78batch/s]
Avg Loss : 1.1414 Validation Loss : 1.2646 Learning Late: 0.0001
Epoch 163: 100%|██████████| 391/391 [00:13<00:00, 29.91batch/s]
Avg Loss : 1.1370 Validation Loss : 1.2466 Learning Late: 0.0001
Epoch 164: 100%|██████████| 391/391 [00:13<00:00, 28.70batch/s]
Avg Loss : 1.1280 Validation Loss : 1.2364 Learning Late: 0.0001
Epoch 165: 100%|██████████| 391/391 [00:13<00:00, 28.92batch/s]
Avg Loss : 1.1235 Validation Loss : 1.2507 Learning Late: 0.0001
Epoch 166: 100%|██████████| 391/391 [00:13<00:00, 28.84batch/s]
Avg Loss : 1.1238 Validation Loss : 1.2009 Learning Late: 0.0001
Epoch 167: 100%|██████████| 391/391 [00:13<00:00, 29.75batch/s]
Avg Loss : 1.1033 Validation Loss : 1.1865 Learning Late: 0.0001
Epoch 168: 100%|██████████| 391/391 [00:13<00:00, 29.05batch/s]
Avg Loss : 1.1036 Validation Loss : 1.1840 Learning Late: 0.0001
Epoch 169: 100%|██████████| 391/391 [00:13<00:00, 30.03batch/s]
Avg Loss : 1.0966 Validation Loss : 1.1457 Learning Late: 0.0001
Epoch 170: 100%|██████████| 391/391 [00:12<00:00, 30.20batch/s]
Avg Loss : 1.0884 Validation Loss : 1.1838 Learning Late: 0.0001
Epoch 171: 100%|██████████| 391/391 [00:12<00:00, 30.55batch/s]
Avg Loss : 1.0857 Validation Loss : 1.1917 Learning Late: 0.0001
Epoch 172: 100%|██████████| 391/391 [00:13<00:00, 29.64batch/s]
Avg Loss : 1.0815 Validation Loss : 1.1533 Learning Late: 0.0001
Epoch 173: 100%|██████████| 391/391 [00:15<00:00, 25.60batch/s]
Avg Loss : 1.0777 Validation Loss : 1.2066 Learning Late: 0.0000
Epoch 174: 100%|██████████| 391/391 [00:13<00:00, 30.00batch/s]
Avg Loss : 1.0708 Validation Loss : 1.1599 Learning Late: 0.0000
Epoch 175: 100%|██████████| 391/391 [00:13<00:00, 29.78batch/s]
Avg Loss : 1.0603 Validation Loss : 1.1470 Learning Late: 0.0000
Epoch 176: 100%|██████████| 391/391 [00:13<00:00, 29.59batch/s]
Avg Loss : 1.0565 Validation Loss : 1.1386 Learning Late: 0.0000
Epoch 177: 100%|██████████| 391/391 [00:13<00:00, 29.41batch/s]
Avg Loss : 1.0524 Validation Loss : 1.1819 Learning Late: 0.0000
Epoch 178: 100%|██████████| 391/391 [00:13<00:00, 29.85batch/s]
Avg Loss : 1.0518 Validation Loss : 1.1334 Learning Late: 0.0000
Epoch 179: 100%|██████████| 391/391 [00:13<00:00, 29.78batch/s]
Avg Loss : 1.0427 Validation Loss : 1.1353 Learning Late: 0.0000
Epoch 180: 100%|██████████| 391/391 [00:13<00:00, 29.93batch/s]
Avg Loss : 1.0375 Validation Loss : 1.1227 Learning Late: 0.0000
Epoch 181: 100%|██████████| 391/391 [00:12<00:00, 30.34batch/s]
Avg Loss : 1.0343 Validation Loss : 1.1359 Learning Late: 0.0000
Epoch 182: 100%|██████████| 391/391 [00:13<00:00, 29.63batch/s]
Avg Loss : 1.0291 Validation Loss : 1.1104 Learning Late: 0.0000
Epoch 183: 100%|██████████| 391/391 [00:13<00:00, 29.52batch/s]
Avg Loss : 1.0275 Validation Loss : 1.1211 Learning Late: 0.0000
Epoch 184: 100%|██████████| 391/391 [00:13<00:00, 29.31batch/s]
Avg Loss : 1.0232 Validation Loss : 1.1025 Learning Late: 0.0000
Epoch 185: 100%|██████████| 391/391 [00:13<00:00, 28.91batch/s]
Avg Loss : 1.0205 Validation Loss : 1.1037 Learning Late: 0.0000
Epoch 186: 100%|██████████| 391/391 [00:13<00:00, 29.94batch/s]
Avg Loss : 1.0161 Validation Loss : 1.1051 Learning Late: 0.0000
Epoch 187: 100%|██████████| 391/391 [00:13<00:00, 28.95batch/s]
Avg Loss : 1.0139 Validation Loss : 1.1052 Learning Late: 0.0000
Epoch 188: 100%|██████████| 391/391 [00:13<00:00, 28.70batch/s]
Avg Loss : 1.0112 Validation Loss : 1.1022 Learning Late: 0.0000
Epoch 189: 100%|██████████| 391/391 [00:13<00:00, 28.38batch/s]
Avg Loss : 1.0082 Validation Loss : 1.0984 Learning Late: 0.0000
Epoch 190: 100%|██████████| 391/391 [00:13<00:00, 28.18batch/s]
Avg Loss : 1.0049 Validation Loss : 1.1005 Learning Late: 0.0000
Epoch 191: 100%|██████████| 391/391 [00:13<00:00, 28.58batch/s]
Avg Loss : 1.0023 Validation Loss : 1.0858 Learning Late: 0.0000
Epoch 192: 100%|██████████| 391/391 [00:13<00:00, 28.25batch/s]
Avg Loss : 1.0007 Validation Loss : 1.0965 Learning Late: 0.0000
Epoch 193: 100%|██████████| 391/391 [00:13<00:00, 29.02batch/s]
Avg Loss : 0.9986 Validation Loss : 1.1008 Learning Late: 0.0000
Epoch 194: 100%|██████████| 391/391 [00:12<00:00, 30.13batch/s]
Avg Loss : 0.9970 Validation Loss : 1.0865 Learning Late: 0.0000
Epoch 195: 100%|██████████| 391/391 [00:13<00:00, 29.25batch/s]
Avg Loss : 0.9957 Validation Loss : 1.0843 Learning Late: 0.0000
Epoch 196: 100%|██████████| 391/391 [00:13<00:00, 29.17batch/s]
Avg Loss : 0.9941 Validation Loss : 1.0917 Learning Late: 0.0000
Epoch 197: 100%|██████████| 391/391 [00:13<00:00, 29.82batch/s]
Avg Loss : 0.9935 Validation Loss : 1.0887 Learning Late: 0.0000
Epoch 198: 100%|██████████| 391/391 [00:13<00:00, 29.65batch/s]
Avg Loss : 0.9924 Validation Loss : 1.0839 Learning Late: 0.0000
Epoch 199: 100%|██████████| 391/391 [00:13<00:00, 29.75batch/s]
Avg Loss : 0.9920 Validation Loss : 1.0872 Learning Late: 0.0000
Epoch 200: 100%|██████████| 391/391 [00:12<00:00, 30.20batch/s]
Avg Loss : 0.9921 Validation Loss : 1.0826 Learning Late: 0.0000

실제 test
100%|██████████| 79/79 [00:02<00:00, 36.29batch/s]총 개수 : 10000
top-1 맞춘 개수 : 6199
 정확도: 61.99
top-5 맞춘 개수 : 9635
 정확도: 96.35
